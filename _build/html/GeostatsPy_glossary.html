

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Geostatistics Glossary &#8212; GeostatsPy Well-documented Demonstration Geostatistical Workflows</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/myfile.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'GeostatsPy_glossary';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="References" href="references.html" />
    <link rel="prev" title="e-Book Conclusions" href="conclusions.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/AppliedGeostats.jpg" class="logo__image only-light" alt="GeostatsPy Well-documented Demonstration Geostatistical Workflows - Home"/>
    <script>document.write(`<img src="_static/AppliedGeostats.jpg" class="logo__image only-dark" alt="GeostatsPy Well-documented Demonstration Geostatistical Workflows - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Applied Geostatistics in Python: a Hands-on Guide with GeostatsPy
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="GeostatsPy_concepts.html">Geostatistical Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="GeostatsPy_probability.html">Probability Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="GeostatsPy_coordinate_transformations.html">Coordinate Transformations</a></li>
<li class="toctree-l1"><a class="reference internal" href="GeostatsPy_univariate_distributions.html">Univariate Distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="GeostatsPy_transformations.html">Distribution Transformations</a></li>
<li class="toctree-l1"><a class="reference internal" href="GeostatsPy_bivariate.html">Bivariate Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="GeostatsPy_QQ.html">QQ-Plots</a></li>
<li class="toctree-l1"><a class="reference internal" href="GeostatsPy_linear_regression.html">Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="GeostatsPy_plotting_spatial_data_models.html">Plotting Spatial Data and Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="GeostatsPy_bootstrap.html">Bootstrap for Uncertainty Modeling</a></li>
<li class="toctree-l1"><a class="reference internal" href="GeostatsPy_declustering.html">Declustering to Correct Sampling Bias</a></li>
<li class="toctree-l1"><a class="reference internal" href="GeostatsPy_declustering_all_methods.html">Advanced Declustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="GeostatsPy_variogram_calculation.html">Variogram Calculation</a></li>
<li class="toctree-l1"><a class="reference internal" href="GeostatsPy_variogram_models.html">Variogram Positive Definite Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="GeostatsPy_variogram_models_simulation.html">Variogram Models, Simulation Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="GeostatsPy_variogram_calculation_and_modeling.html">Variogram Calculation and Modeling</a></li>
<li class="toctree-l1"><a class="reference internal" href="GeostatsPy_variogram_from_image.html">Variogram Calculation from an Image</a></li>
<li class="toctree-l1"><a class="reference internal" href="GeostatsPy_trends.html">Trend Modeling</a></li>
<li class="toctree-l1"><a class="reference internal" href="GeostatsPy_2D1D_trend.html">Spatial Trend Modeling, 1D + 2D</a></li>
<li class="toctree-l1"><a class="reference internal" href="GeostatsPy_inv_distance.html">Inverse Distance</a></li>
<li class="toctree-l1"><a class="reference internal" href="GeostatsPy_kriging.html">Simple and Ordinary Kriging</a></li>
<li class="toctree-l1"><a class="reference internal" href="GeostatsPy_categorical_indictor_kriging.html">Indicator Kriging</a></li>
<li class="toctree-l1"><a class="reference internal" href="GeostatsPy_simulation.html">Stochastic Simulation</a></li>
<li class="toctree-l1"><a class="reference internal" href="GeostatsPy_kriging_vs_simulation_1D.html">Kriging vs. Simulation, 1D</a></li>
<li class="toctree-l1"><a class="reference internal" href="GeostatsPy_kriging_vs_simulation_maps.html">Kriging vs. Simulation, 2D Maps</a></li>
<li class="toctree-l1"><a class="reference internal" href="GeostatsPy_categorical_indicator_simulation.html">Indicator Simulation</a></li>
<li class="toctree-l1"><a class="reference internal" href="GeostatsPy_cosimulation.html">Cosimulation</a></li>
<li class="toctree-l1"><a class="reference internal" href="GeostatsPy_ergodic_fluctuations.html">Ergodic Fluctuations</a></li>
<li class="toctree-l1"><a class="reference internal" href="GeostatsPy_simulation_postsim.html">Simulation Post-processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="GeostatsPy_model_checking.html">Model Checking</a></li>
<li class="toctree-l1"><a class="reference internal" href="GeostatsPy_volume_variance.html">Volume Variance</a></li>
<li class="toctree-l1"><a class="reference internal" href="conclusions.html">Conclusions</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html">References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/GeostatsPyDemos_Book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/GeostatsPyDemos_Book/issues/new?title=Issue%20on%20page%20%2FGeostatsPy_glossary.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/GeostatsPy_glossary.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Geostatistics Glossary</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#motivation-for-geostatistics-concepts">Motivation for Geostatistics Concepts</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#addition-rule-probability"><strong>Addition Rule</strong> (probability)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#affine-correction"><strong>Affine Correction</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#anisotropic-or-directional-variogram"><strong>Anisotropic or Directional</strong> (variogram)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#azimuth-tolerance-variogram"><strong>Azimuth Tolerance</strong> (variogram)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bandwidth-variogram"><strong>Bandwidth</strong> (variogram)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-probability"><strong>Bayesian Probability</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayes-theorem-probability"><strong>Bayes’ Theorem</strong> (probability)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#big-data"><strong>Big Data</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#big-data-analytics"><strong>Big Data Analytics</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bootstrap"><strong>Bootstrap</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#categorical-feature"><strong>Categorical Feature</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#categorical-nominal-feature"><strong>Categorical Nominal Feature</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#categorical-ordinal-feature"><strong>Categorical Ordinal Feature</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cell-based-declustering"><strong>Cell-based Declustering</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cloud-transform"><strong>Cloud Transform</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#continuous-feature"><strong>Continuous Feature</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#continuous-interval-feature"><strong>Continuous, Interval Feature</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#continuous-ratio-feature"><strong>Continuous, Ratio Feature</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cognitive-biases"><strong>Cognitive Biases</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cokriging"><strong>Cokriging</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#collocated-cokriging"><strong>Collocated Cokriging</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#complimentary-events-probability"><strong>Complimentary Events</strong> (probability)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-probability"><strong>Conditional Probability</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#core-data"><strong>Core Data</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#correlogram"><strong>Correlogram</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cosimulation"><strong>Cosimulation</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#covariance-function"><strong>Covariance Function</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cumulative-distribution-function-cdf"><strong>Cumulative Distribution Function (CDF)</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cyclicity-variogram-model"><strong>Cyclicity</strong> (variogram model)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-data-aspects"><strong>Data</strong> (data aspects)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-analytics"><strong>Data Analytics</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#debiasing-with-secondary-data"><strong>Debiasing with Secondary Data</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#decision-criteria"><strong>Decision Criteria</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#declustering"><strong>Declustering</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#declustering-statistics"><strong>Declustering</strong> (statistics)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deterministic-model"><strong>Deterministic Model</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#discrete-feature"><strong>Discrete Feature</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dispersion-variance"><strong>Dispersion Variance</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#distribution-transformations"><strong>Distribution Transformations</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ergodic-fluctuations"><strong>Ergodic Fluctuations</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimation"><strong>Estimation</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#facies"><strong>Facies</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#facies-simulation"><strong>Facies Simulation</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-also-variable"><strong>Feature</strong> (also variable)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#frequentist-probability"><strong>Frequentist Probability</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gamma-bar"><strong>Gamma Bar</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#geometric-anisotropy-variogram-interpretation"><strong>Geometric Anisotropy</strong> (variogram interpretation)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#geometric-anisotropy-variogram-model"><strong>Geometric Anisotropy</strong> (variogram model)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#geostatistics"><strong>Geostatistics</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#global-accuracy"><strong>Global Accuracy</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#global-measures"><strong>Global Measures</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hard-data"><strong>Hard Data</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#histogram"><strong>Histogram</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hybrid-model"><strong>Hybrid Model</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#independence-probability"><strong>Independence</strong> (probability)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#indicator-kriging"><strong>Indicator Kriging</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#indicator-transform"><strong>Indicator Transform</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#indicator-variogram"><strong>Indicator Variogram</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-inferential-statistics"><strong>Inference, Inferential Statistics</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#intersection-of-events-probability"><strong>Intersection of Events</strong> (probability)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#isotropic-or-omnidirectional-variogram"><strong>Isotropic or Omnidirectional</strong> (variogram)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#joint-probability"><strong>Joint Probability</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#local-accuracy"><strong>Local Accuracy</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#local-measures"><strong>Local Measures</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kriging"><strong>Kriging</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kriging-simple-vs-ordinary"><strong>Kriging</strong> (simple vs. ordinary)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kriging-variance"><strong>Kriging Variance</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kriging-based-declustering"><strong>Kriging-based Declustering</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kolmogorovs-3-probability-axioms"><strong>Kolmogorov’s 3 Probability Axioms</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lag-variogram"><strong>Lag</strong> (variogram)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lag-distance-variogram"><strong>Lag Distance</strong> (variogram)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lag-distance-tolerance-variogram"><strong>Lag Distance Tolerance</strong> (variogram)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#location-map"><strong>Location Map</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#major-direction-variogram"><strong>Major Direction</strong> (variogram)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#marginal-probability"><strong>Marginal Probability</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#minor-direction-variogram"><strong>Minor Direction</strong> (variogram)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-checking"><strong>Model Checking</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#monte-carlo-simulation-mcs"><strong>Monte Carlo Simulation (MCS)</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#monte-carlo-simulation-workflow"><strong>Monte Carlo Simulation Workflow</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multiplication-rule-probability"><strong>Multiplication Rule</strong> (probability)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mutually-exclusive-events-probability"><strong>Mutually Exclusive Events</strong> (probability)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#normalized-histogram"><strong>Normalized Histogram</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nugget-effect-variogram"><strong>Nugget Effect</strong> (variogram)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#order-relations-correction-indicator-kriging">Order Relations Correction** (indicator kriging)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#parameters-statistics"><strong>Parameters</strong> (statistics)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#parameters-machine-learning"><strong>Parameters</strong> (machine learning)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#polygonal-declustering"><strong>Polygonal Declustering</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#population"><strong>Population</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#power-law-averaging"><strong>Power Law Averaging</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prediction-predictive-statistics"><strong>Prediction, Predictive Statistics</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#predictor-feature"><strong>Predictor Feature</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#primary-data"><strong>Primary Data</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probability-density-function-pdf"><strong>Probability Density Function (PDF)</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probability-non-negativity-normalization">Probability Non-negativity, Normalization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probability-operators"><strong>Probability Operators</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probability-perspectives"><strong>Probability Perspectives</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#production-data"><strong>Production Data</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#qualitative-features"><strong>Qualitative Features</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quantitative-features"><strong>Quantitative Features</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#random-function"><strong>Random Function</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#random-variable"><strong>Random Variable</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#range-variogram"><strong>Range</strong> (variogram)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#realization"><strong>Realization</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#realizations-uncertainty"><strong>Realizations</strong> (uncertainty)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reservoir-modeling-workflow"><strong>Reservoir Modeling Workflow</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#response-feature"><strong>Response Feature</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sample"><strong>Sample</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#scenarios-uncertainty"><strong>Scenarios</strong> (uncertainty)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#secondary-data"><strong>Secondary Data</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#seismic-data"><strong>Seismic Data</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sequential-gaussian-simulation"><strong>Sequential Gaussian Simulation</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sequential-indicator-simulation"><strong>Sequential Indicator Simulation</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sill-variogram"><strong>Sill</strong> (variogram)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simulation"><strong>Simulation</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simulation-post-processing"><strong>Simulation Post-processing</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#soft-data"><strong>Soft Data</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spatial-estimation"><strong>Spatial Estimation</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spatial-continuity"><strong>Spatial Continuity</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spatial-sampling-biased"><strong>Spatial Sampling</strong> (biased)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spatial-sampling-clustered"><strong>Spatial Sampling</strong> (clustered)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spatial-sampling-common-practice"><strong>Spatial Sampling</strong> (common practice)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spatial-sampling-representative"><strong>Spatial Sampling</strong> (representative)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stationarity"><strong>Stationarity</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stochastic-model"><strong>Stochastic Model</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#statistics-practice"><strong>Statistics</strong> (practice)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#statistics-measurement"><strong>Statistics</strong> (measurement)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#statistical-distribution"><strong>Statistical Distribution</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#transfer-function-reservoir-modeling-workflow"><strong>Transfer Function</strong> (reservoir modeling workflow)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#trend-data"><strong>Trend</strong> (data)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#trend-model"><strong>Trend</strong> (model)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#trend-variogram-model"><strong>Trend</strong> (variogram model)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#trend-modeling"><strong>Trend Modeling</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#uncertainty-modeling"><strong>Uncertainty Modeling</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#union-of-events-probability"><strong>Union of Events</strong> (probability)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#unit-lag-distance-variogram"><strong>Unit Lag Distance</strong> (variogram)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#univariate-parameters"><strong>Univariate Parameters</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#univariate-statistics"><strong>Univariate Statistics</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#variable-also-feature"><strong>Variable</strong> (also feature)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#variogram"><strong>Variogram</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#variogram-map"><strong>Variogram Map</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#variogram-model"><strong>Variogram Model</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#variance-reduction-factor"><strong>Variance Reduction Factor</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#volume-variance-relations"><strong>Volume-Variance Relations</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#venn-diagrams"><strong>Venn Diagrams</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#well-log-data"><strong>Well Log Data</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#well-log-data-image-logs"><strong>Well Log Data, Image Logs</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zonal-anisotropy-variogram-model"><strong>Zonal Anisotropy</strong> (variogram model)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#comments">Comments</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-author">The Author:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#want-to-work-together">Want to Work Together?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#more-resources-available-at-twitter-github-website-googlescholar-geostatistics-book-youtube-applied-geostats-in-python-e-book-applied-machine-learning-in-python-e-book-linkedin">More Resources Available at: Twitter | GitHub | Website | GoogleScholar | Geostatistics Book | YouTube  | Applied Geostats in Python e-book | Applied Machine Learning in Python e-book | LinkedIn</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="geostatistics-glossary">
<h1>Geostatistics Glossary<a class="headerlink" href="#geostatistics-glossary" title="Permalink to this heading">#</a></h1>
<p>Michael J. Pyrcz, Professor, The University of Texas at Austin</p>
<p><a class="reference external" href="https://twitter.com/geostatsguy">Twitter</a> | <a class="reference external" href="https://github.com/GeostatsGuy">GitHub</a> | <a class="reference external" href="http://michaelpyrcz.com">Website</a> | <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en&amp;oi=ao">GoogleScholar</a> | <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Book</a> | <a class="reference external" href="https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig">YouTube</a>  | <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostats in Python e-book</a> | <a class="reference external" href="https://www.linkedin.com/in/michael-pyrcz-61a648a1">LinkedIn</a></p>
<p>Chapter of e-book “Applied Geostatistics in Python: a Hands-on Guide with GeostatsPy”.</p>
<div class="remove-from-content-only admonition">
<p class="admonition-title">Cite this e-Book as:</p>
<p>Pyrcz, M.J., 2024, Applied Geostatistics in Python: a Hands-on Guide with GeostatsPy, <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book">https://geostatsguy.github.io/GeostatsPyDemos_Book</a>.</p>
</div>
<p>The workflows in this book and more are available here:</p>
<div class="remove-from-content-only admonition">
<p class="admonition-title">Cite the GeostatsPyDemos GitHub Repository as:</p>
<p>Pyrcz, M.J., 2024, GeostatsPyDemos: GeostatsPy Python Package for Spatial Data Analytics and Geostatistics Demonstration Workflows Repository (0.0.1). Zenodo. <a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.12667035">https://zenodo.org/doi/10.5281/zenodo.12667035</a></p>
<p><a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.12667035"><img alt="DOI" src="https://zenodo.org/badge/777871341.svg" /></a></p>
</div>
<p>By Michael J. Pyrcz <br />
© Copyright 2024.</p>
<p>This chapter is a summary of essential <strong>Geostatistics Terminology</strong>.</p>
<section id="motivation-for-geostatistics-concepts">
<h2>Motivation for Geostatistics Concepts<a class="headerlink" href="#motivation-for-geostatistics-concepts" title="Permalink to this heading">#</a></h2>
<p>Firstly, why do this? I have received the request for a course glossary from the students in my <strong>Data Analytics and Geostatistics</strong> undergraduate course. While I usually dedicated a definition slide in the lecture slide decks for salient terms, some of my students have requested course glossary, list of terminology in their course review. The e-book provides a great vehicle and motivation for this.</p>
<p>Let me begin with a confession. There is a <a class="reference external" href="https://www.amazon.com/Geostatistical-Multilingual-International-Association-Mathematical/dp/0195066898">Geostatistical Glossary and Multilingual Dictionary</a> written by my good friend <a class="reference external" href="https://www.usgs.gov/staff-profiles/ricardo-a-olea">Dr. Ricardo A. Olea</a> an excellent geologist and statistician from the <a class="reference external" href="https://www.usgs.gov/">USGS</a>. For those seeking the in depth, comprehensive list of geostatistical terms please use this book!</p>
<ul class="simple">
<li><p>By writing my own I can limit the scope and descriptions to course content. I fear that many students would be overwhelmed by the size and mathematical notation of a standard geostatistics glossary.</p></li>
<li><p>Also, by including a glossary in the e-book I can link from glossary entries to the chapters in the e-book for convenience. I will eventual populate all the chapters with hyperlinks to the glossary to enable moving back and forth between the chapters and the glossary.</p></li>
</ul>
<p>Finally, like the rest of the book, I want the glossary to be a evergreen living document.</p>
</section>
<section id="addition-rule-probability">
<h2><strong>Addition Rule</strong> (probability)<a class="headerlink" href="#addition-rule-probability" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_probability.html"><span class="doc std std-doc">Probability Concepts</span></a>: when we add probabilities (the union of outcomes), the probability of <span class="math notranslate nohighlight">\(A\)</span> or <span class="math notranslate nohighlight">\(B\)</span> is calculated with the probability addition rule,</p>
<div class="math notranslate nohighlight">
\[
P(A \cup B) = P(A) + P(B) - P(A,B)
\]</div>
<p>given mutually exclusive events we can generalize the addition rule as,</p>
<div class="math notranslate nohighlight">
\[
P\left( \bigcup_{i=1}^k A_i \right) = \sum_{i=1}^k P(A_i)
\]</div>
</section>
<section id="affine-correction">
<h2><strong>Affine Correction</strong><a class="headerlink" href="#affine-correction" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_transformations.html"><span class="doc std std-doc">Distribution Transformations</span></a>: a distribution rescaling that can be thought of as shifting, and stretching or squeezing of a univariate distribution (e.g., <em>histogram</em>). For the case of affine correction of <span class="math notranslate nohighlight">\(X\)</span> to <span class="math notranslate nohighlight">\(Y\)</span>,</p>
<div class="math notranslate nohighlight">
\[
y_i = \frac{\sigma_y}{\sigma_x}(x_i - \overline{x}) + \overline{y}, \quad \forall \quad i, \ldots, n
\]</div>
<p>where <span class="math notranslate nohighlight">\(\overline{x}\)</span> and <span class="math notranslate nohighlight">\(\sigma_x\)</span> are the original mean and variance, and <span class="math notranslate nohighlight">\(\overline{y}\)</span> and <span class="math notranslate nohighlight">\(\sigma_y\)</span> are the new mean and variance.</p>
<p>We can see above that the affine correlation method first centers the distribution (by subtracting the original mean), then rescales the dispersion (distribution spread) by the ratio of the new standard deviation to the original standard deviation and then shifts the distribution to centered on the new mean.</p>
<ul class="simple">
<li><p>there is no shape change for affine correction. For shape change consider <em>Distribution Transformation</em> like <em>Gaussian Anamorphosis</em>.</p></li>
</ul>
</section>
<section id="anisotropic-or-directional-variogram">
<h2><strong>Anisotropic or Directional</strong> (variogram)<a class="headerlink" href="#anisotropic-or-directional-variogram" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_variogram_calculation.html"><span class="doc std std-doc">Variogram Calculation</span></a>: variogram calculated or modelled such that direction (azimuth) is considered,</p>
<ul class="simple">
<li><p>for an anisotropic experimental variogram set the azimuth tolerance less than 90 degrees, then the experimental variogram is sensitive to direction</p></li>
<li><p>for an anisotropic variogram model set the major range greater than the minor range, then the variogram model is sensitive to direction</p></li>
</ul>
</section>
<section id="azimuth-tolerance-variogram">
<h2><strong>Azimuth Tolerance</strong> (variogram)<a class="headerlink" href="#azimuth-tolerance-variogram" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_variogram_calculation.html"><span class="doc std std-doc">Variogram Calculation</span></a>: for calculating directional experimental variograms, the tolerance <span class="math notranslate nohighlight">\(+/-\Delta\)</span> in azimuth applied to identify data pairs for that specific azimuth.</p>
<ul class="simple">
<li><p>for example, given an azimuth of 90 degrees (along the positive x axis in map view), we could assign an azimuth tolerance of 20 degrees and then all pairs with azimuths between 70 degrees and 110 degrees will be pooled to calculate the experimental variogram for this azimuth</p></li>
</ul>
<p>Some general observations for setting azimuth tolerance,</p>
<ul class="simple">
<li><p>it is common practice for directional experimental variograms to use a azimuth tolerance of 22.5 degrees, this result in a 45 degrees angle inscribed in the search window. This is seen as a good balance to provide smooth, interpretable experimental variograms without mixing spatial continuity information over too many directions</p></li>
<li><p>may be increased to smooth the experimental variogram for improved interpretability</p></li>
<li><p>for isotropic (also called omnidirectional) experimental variograms (not sensitive to direction) use an azimuth tolerance of 90.0, resulting in 180.0 degrees angle inscribed in the search window to remove the influence of direction</p></li>
</ul>
</section>
<section id="bandwidth-variogram">
<h2><strong>Bandwidth</strong> (variogram)<a class="headerlink" href="#bandwidth-variogram" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_variogram_calculation.html"><span class="doc std std-doc">Variogram Calculation</span></a>: the maximum orthogonal deviation from the lag vector when identifying data pairs to calculate an experimental variogram.</p>
<p>What is the motivation for using bandwidth?</p>
<ul class="simple">
<li><p>when working with a cross section (axes, y is vertical and x is horizontal) at large lag distances, <span class="math notranslate nohighlight">\(\bf{h}\)</span>, azimuth (dip) tolerance may result in including data from adjacent (mixing between) stratigraphic units.</p></li>
<li><p>bandwidth is typically applied to the vertical direction to reduce the potential for mixing between adjacent units</p></li>
</ul>
<p>When not to use bandwidth?</p>
<ul class="simple">
<li><p>bandwidth should not be used to calculate isotropic (also called omnidirectional) experimental variograms</p></li>
<li><p>bandwidth is rarely used to calculate horizontal experimental variograms</p></li>
<li><p>bandwidth is removed by setting it very large relative to the model extent</p></li>
</ul>
</section>
<section id="bayesian-probability">
<h2><strong>Bayesian Probability</strong><a class="headerlink" href="#bayesian-probability" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_probability.html"><span class="doc std std-doc">Probability Concepts</span></a>: probabilities based on a degree of belief (expert judgement and experience) in the likelihood of an event. The general approach,</p>
<ul class="simple">
<li><p>start with prior probability, prior to the collection of new information</p></li>
<li><p>formulate a likelihood probability, based on new information alone</p></li>
<li><p>update prior with likelihood to calculate the updated posterior probability</p></li>
<li><p>continue to update as new information is available</p></li>
<li><p>solve probability problems that we cannot use simple frequencies, i.e., <em>frequentist probability</em> approach</p></li>
<li><p>Bayesian updating is modeled with <em>Bayes’ Theorem</em></p></li>
</ul>
</section>
<section id="bayes-theorem-probability">
<h2><strong>Bayes’ Theorem</strong> (probability)<a class="headerlink" href="#bayes-theorem-probability" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_probability.html"><span class="doc std std-doc">Probability Concepts</span></a>: the mathematical model central to Bayesian probability for the Bayesian updating from prior probability, with likelihood probability from new information to posterior probability.</p>
<div class="math notranslate nohighlight">
\[
P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}
\]</div>
<p>where <span class="math notranslate nohighlight">\(P(A)\)</span> is the prior, <span class="math notranslate nohighlight">\(P(B|A)\)</span> is the likelihood, <span class="math notranslate nohighlight">\(P(B)\)</span> is the evidence term and <span class="math notranslate nohighlight">\(P(A|B)\)</span> is the posterior. If is convenient to substitute more descriptive labels for <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> to better conceptualize this approach,</p>
<div class="math notranslate nohighlight">
\[
P(\text{Model} | \text{New Data}) = \frac{P(\text{New Data} | \text{Model}) \cdot P(\text{Model})}{P(\text{New Data})}
\]</div>
<p>demonstrating that we are updating our model with new data</p>
</section>
<section id="big-data">
<h2><strong>Big Data</strong><a class="headerlink" href="#big-data" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: you have big data if your data has a combination of these criteria:</p>
<ol class="arabic simple">
<li><p><em>Data Volume</em> - many data samples and features, difficult to store, transmit and visualize</p></li>
<li><p><em>Data Velocity</em> - high-rate collection, continuous data collection relative to decision making cycles, challenges keeping up with the new data while updating the models</p></li>
<li><p><em>Data Variety</em> - data form various sources, with various types of data, types of information, and scales</p></li>
<li><p><em>Data Variability</em> - data acquisition changes during the project, even for a single feature there may be multiple vintages of data with different scales, distributions, and veracity</p></li>
<li><p><em>Data Veracity</em> - data has various levels of accuracy, the data is not certain</p></li>
</ol>
<p>For common subsurface applications most, if not all, of these criteria are met. Subsurface engineering and geoscience are often working with big data!</p>
</section>
<section id="big-data-analytics">
<h2><strong>Big Data Analytics</strong><a class="headerlink" href="#big-data-analytics" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: the process of examining large and varied data (<em>big data</em>) sets to discover patterns and make decisions, the application of statistics to big data.</p>
</section>
<section id="bootstrap">
<h2><strong>Bootstrap</strong><a class="headerlink" href="#bootstrap" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_transformations.html"><span class="doc std std-doc">Distribution Transformations</span></a>: a statistical resampling procedure to calculate uncertainty in a calculated statistic from the sample data itself. Some general comments,</p>
<ul class="simple">
<li><p><em>sampling with replacement</em> - <span class="math notranslate nohighlight">\(n\)</span> (number of data samples) <em>Monte Carlo simulation</em>s from the dataset <em>cumulative distribution function</em>, this results in a new realization of the data</p></li>
<li><p><em>simulates the data collection process</em> - the fundamental idea is to simulate the original data collection process. Instead of actually collecting new sample sets, we randomly select from the data to get data realizations</p></li>
<li><p><em>bootstrap any statistic</em> - this approach is very flexible as we can calculate realizations of any statistics from the data realizations</p></li>
<li><p><em>computationally cheap</em> - repeat this approach to get realizations of the statistic to build a complete distribution of uncertainty. Use a large number of realizations, <span class="math notranslate nohighlight">\(L\)</span>, for a reliable uncertainty model.</p></li>
<li><p><em>calculates the entire distribution of uncertainty</em>* for any statistic, you calculate any summary statistic for the uncertainty model, e.g., mean, P10 and P90 of the uncertainty in the mean</p></li>
<li><p><em>bagging for machine learning</em> is the application fo bootstrap to obtain data realizations to train predictive model realizations to aggregate predictions over ensembles of prediction models to reduce model variance</p></li>
</ul>
<p>What are the limitations of bootstrap?</p>
<ul class="simple">
<li><p>biased sample data will likely result in a biased bootstrapped uncertainty model, you must first debias the samples, e.g., <em>declustering</em></p></li>
<li><p>you must have a sufficient sample size</p></li>
<li><p>integrates uncertainty due to sparse samples in space only</p></li>
<li><p>does not account for the spatial context of the data, i.e., sample data locations, volume of interest nor the spatial continuity. There is a variant of bootstrap called <a class="reference external" href="https://github.com/GeostatsGuy/DataScienceInteractivePython/blob/main/Interactive_Spatial_Bootstrap.ipynb">spatial bootstrap</a>.</p></li>
</ul>
</section>
<section id="categorical-feature">
<h2><strong>Categorical Feature</strong><a class="headerlink" href="#categorical-feature" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: a feature that can only take one of a limited, and usually fixed, number of possible values</p>
</section>
<section id="categorical-nominal-feature">
<h2><strong>Categorical Nominal Feature</strong><a class="headerlink" href="#categorical-nominal-feature" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: a <em>categorical</em> feature without any natural ordering, for example,</p>
<ul class="simple">
<li><p>facies = {boundstone, wackystone, packstone, brecia}</p></li>
<li><p>minerals = {quartz, feldspar, calcite}</p></li>
</ul>
</section>
<section id="categorical-ordinal-feature">
<h2><strong>Categorical Ordinal Feature</strong><a class="headerlink" href="#categorical-ordinal-feature" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: a <em>categorical</em> feature with a natural ordering, for example,</p>
<ul class="simple">
<li><p>geologic age = {Miocene, Pliocene, Pleistocene} - ordered from older to younger rock</p></li>
<li><p>Mohs hardness = <span class="math notranslate nohighlight">\(\{1, 2, \ldots, 10\}\)</span> - ordered from softer to harder rock</p></li>
</ul>
</section>
<section id="cell-based-declustering">
<h2><strong>Cell-based Declustering</strong><a class="headerlink" href="#cell-based-declustering" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_declustering.html"><span class="doc std std-doc">Declustering to Correct Sampling Bias</span></a>: a declustering method to assign weights to spatial samples based on local sampling density, such that the weighted statistics are likely more representative of the population. Data weights are assigned such that,</p>
<ul class="simple">
<li><p>samples in densely sampled areas receive less weight</p></li>
<li><p>samples in sparsely sampled areas receive more weight</p></li>
</ul>
<p>The goal of declustering is for the sample statistics to be independent of sample locations, e.g., infill drilling or blast hole samples should not change the statistics for the area of interest due to increased local sample density.</p>
<p>Cell-based declustering proceeds as follows:</p>
<ol class="arabic simple">
<li><p>a cell mesh is placed over the spatial data and weights are set as proportional to the inverse of the number of samples in the cell</p></li>
<li><p>the cell mesh size is varied, and the cell size that minimizes the declustered mean (in the sample mean is biased high) or maximizes the declustered mean (if the sample mean is biased low) is selected</p></li>
<li><p>to remove the impact of cell mesh position, the cell mesh is randomly moved several times and the resulting declustering weights are averaged for each datum</p></li>
</ol>
<p>The weights are calculated as:</p>
<div class="math notranslate nohighlight">
\[
w(\bf{u}_j) = \frac{1}{n_l} \cdot \frac{n}{L_o}
\]</div>
<p>where <span class="math notranslate nohighlight">\(n_l\)</span> is the number of data in the current cell, <span class="math notranslate nohighlight">\(L_o\)</span> is the number of cells with data, and <span class="math notranslate nohighlight">\(n\)</span> is the total number of data.</p>
<p>Here are some highlights for cell-based declustering,</p>
<ul class="simple">
<li><p>expert judgement to assign cell size based on the nominal sample spacing (e.g., data spacing before infill drilling) will improve the performance over the automated method for cell size selection based on minimum or maximum declustered mean (mentioned above)</p></li>
<li><p>cell-based declustering is not aware of the boundaries of the area of interest; therefore, data near the boundary of the area of interest may appear to be more sparsely sampled and receive more weight</p></li>
<li><p>cell-based was developed by Professor Andre Journel in 1983, <span id="id1">[<a class="reference internal" href="references.html#id10" title="A.G. Journel. Non-parametric Estimation of Spatial Distributions. Math Geology, 1983.">Jou83</a>]</span></p></li>
</ul>
</section>
<section id="cloud-transform">
<h2><strong>Cloud Transform</strong><a class="headerlink" href="#cloud-transform" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_cosimulation.html"><span class="doc std std-doc">Cosimulation</span></a>: a cosimulation approach that is based on the bivariate relationship (scatter plot) between the primary and secondary features to simulated realizations of the primary feature, <span class="math notranslate nohighlight">\(z\)</span>, paired with a previously simulated realization of the secondary feature, <span class="math notranslate nohighlight">\(y\)</span></p>
<p>For all locations in the model, <span class="math notranslate nohighlight">\(\alpha = 1, \ldots, nx \cdot ny\)</span>, <span class="math notranslate nohighlight">\(\bf{u}_{\alpha}\)</span>,</p>
<ol class="arabic simple">
<li><p>find the collocated secondary value, <span class="math notranslate nohighlight">\(y(\bf{u}_{\alpha})\)</span></p></li>
<li><p>calculate the conditional distribution, <span class="math notranslate nohighlight">\(f_{(z|y = y(\bf{u}_{\alpha})}(z)\)</span>, from the scatter plot-based joint distribution function, <span class="math notranslate nohighlight">\(f_{y,z}\)</span>, and the collocated secondary value, <span class="math notranslate nohighlight">\(y(\bf{u}_{\alpha})\)</span></p></li>
<li><p>draw from <span class="math notranslate nohighlight">\(f_{(z|y = y(\bf{u}_{\alpha})}(z)\)</span> with a field of correlated p-values (known as a p-field)</p></li>
</ol>
<p>Some comments about cloud transform,</p>
<ul class="simple">
<li><p>prioritizes reproduction of the cloud, the bivariate relationship (scatter plot) between the primary and secondary features</p></li>
<li><p>may not well reproduce the primary feature spatial continuity and distribution</p></li>
<li><p>cloud transform is very commonly used in practice to simulate permeability with secondary porosity realizations. Why? Permeability samples are quite sparsely sampled and as a result the permeability distribution and variogram are not often well-known, but the bivariate relationship often has recognizable forms and the porosity variogram and distribution are more reliable.</p></li>
<li><p>the general approach of calculating simulated realizations by applying p-fields to local uncertainty distributions is called p-field simulation. It is often applied to simplify information integration through the separation of local conditioning and imposing spatial correlation, and as a faster simulation method to scale up to large models. More about <a class="reference external" href="https://link.springer.com/article/10.1023/A:1010993113807">p-field simulation</a>.</p></li>
</ul>
</section>
<section id="continuous-feature">
<h2><strong>Continuous Feature</strong><a class="headerlink" href="#continuous-feature" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: a feature that can take any value between a lower and upper bound. For example,</p>
<ul class="simple">
<li><p>porosity = <span class="math notranslate nohighlight">\(\{13.01\%, 5.23\%, 24.62\%\}\)</span></p></li>
<li><p>gold grade = <span class="math notranslate nohighlight">\(\{4.56 \text{ g/t}, 8.72 \text{ g/t}, 12.45 \text{ g/t} \}\)</span></p></li>
</ul>
</section>
<section id="continuous-interval-feature">
<h2><strong>Continuous, Interval Feature</strong><a class="headerlink" href="#continuous-interval-feature" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: a <em>continuous feature</em> where the intervals between numbers are equal, for example, the difference between 1.50 and 2.50 is the same as the difference between 2.50 and 3.50, but the actual values do not have an objective, physical reality (exist on an arbitrary scale), i.e., do not have a true zero point, for example,</p>
<ul class="simple">
<li><p>Celsius scale of temperature (an arbitrary scale based on water freezing at 0 and boiling at 100)</p></li>
<li><p>calendar year (there is no true zero year)</p></li>
</ul>
<p>We can use addition and substraction operations to compare continuous, interval features.</p>
</section>
<section id="continuous-ratio-feature">
<h2><strong>Continuous, Ratio Feature</strong><a class="headerlink" href="#continuous-ratio-feature" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: a <em>continuous feature</em> where the intervals between numbers are equal, for example, the difference between 1.50 and 2.50 is the same as the difference between 2.50 and 3.50, but the values do have an objective reality (measure an actual physical phenomenon), i.e., do have true zero point, for example,</p>
<ul class="simple">
<li><p>Kelvin scale of temperature</p></li>
<li><p>porosity</p></li>
<li><p>permeability</p></li>
<li><p>saturation</p></li>
</ul>
<p>Since there is a true zero, continuous, ratio features can be compared with multiplication and division mathematical operations (in addition to addition and subtraction), e.g., twice as much porosity.</p>
</section>
<section id="cognitive-biases">
<h2><strong>Cognitive Biases</strong><a class="headerlink" href="#cognitive-biases" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: an automated (subconscious) thought process used by human brain to simplify information processing from large amount of personal experience and learned preferences. While these have been critical for our evolution and  survival on this planet, they can lead to the following issues in data science:</p>
<ol class="arabic simple">
<li><p><em>Anchoring Bias</em>, too much emphasis on the first piece of information. Studies have shown that the first piece of information could be irrelevant as we are beginning to learn about a topic, and often the earliest data in a project has the largest uncertainty. Address anchoring bias by currating all data, integrating uncertainty, fostering open discussion and debate on your project team.</p></li>
<li><p><em>Availability Heuristic</em>, overestimate importance of easily available information, for example, grandfather smoked 3 packs a day and lived to 100 years old, i.e., relying on anecdotes. Address availability heuristic by ensuring the project team documents all available information and applies quantitative analysis to move beyond anecdotes.</p></li>
<li><p><em>Bandwagon Effect</em>, assessed probability increases with the number of people holding the same belief. Watch out for everyone jumping on board or the loudest voice influencing all others on your project teams. Encouraging all members of the project team to contribute and even separate meetings may be helpful to address bandwagon effect.</p></li>
<li><p><em>Blind-spot Effect</em>, fail to see your own cognitive biases. This is the hardest cognitive bias of all. One possible solution is to invite arms length review of your project team’s methods, results and decisions.</p></li>
<li><p><em>Choice-supportive Bias</em>, probability increases after a commitment, i.e., a decision is made. For example, it was good that I bought that car supported by focusing on positive information about the car. This is a specific case of confirmation bias.</p></li>
<li><p><em>Clustering Illusion</em>, seeing patterns in random events. Yes, this heuristic helped us stay alive when large predictors hunted us, i.e., false positives are much better than false negatives! The solution is to model uncertainty confidence intervals and test all data and results against random effect.</p></li>
<li><p><em>Confirmation Bias</em>, only consider new information that supports current model. Choice-supportive bias is a specific case of confirmation bias. The solution to confirmation bias is to seek out people that you will likely disagree with and build skilled project teams that hold diverse technical opinions and have different expert experience. My approach is to get nervous if everyone in the room agrees with me!</p></li>
<li><p><em>Conservatism Bias</em>, favor old data to newly collected data. Data curation and quantiative analysis are helpful.</p></li>
<li><p><em>Recency Bias</em>, favor the most recently collected data. Ensure your team documents previous data and choices to enhance team memory. Just like conservative bias, data curation and quantitative analysis are our first line of defense.</p></li>
<li><p><em>Survivorship Bias</em>, focus on success cases only. Check for any possible pre-selection or filters on the data available to your team.</p></li>
</ol>
<p>Robust use of statistics / data analytics protects use from bias.</p>
</section>
<section id="cokriging">
<h2><strong>Cokriging</strong><a class="headerlink" href="#cokriging" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_cosimulation.html"><span class="doc std std-doc">Cosimulation</span></a>: the general simple kriging approach that accounts for primary and secondary features at the same time in order to build multivariate spatial models.</p>
<ul class="simple">
<li><p>like regular kriging, a spatial estimation approach that relies on linear weights that account for spatial continuity, data closeness and redundancy.</p></li>
<li><p>weights are unbiased and minimize the estimation variance</p></li>
</ul>
<p>The simple cokriging weights are calculated by solving a linear system of equations that may be represented with matrix notation as,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
C_z(\bf{u}_1,\bf{u}_1) &amp; C_z(\bf{u}_1,\bf{u}_2) &amp; \dots &amp; C_z(\bf{u}_1,\bf{u}_{n_z}) &amp; \textcolor{red}{C_{z,y}(\bf{u}_1,\bf{u}_1)} &amp; \textcolor{red}{C_{z,y}(\bf{u}_1,\bf{u}_2)} &amp; \dots &amp; \textcolor{red}{C_{z,y}(\bf{u}_1,\bf{u}_{n_y})} \\
C_z(\bf{u}_2,\bf{u}_1) &amp; C_z(\bf{u}_2,\bf{u}_2) &amp; \dots &amp; C_z(\bf{u}_2,\bf{u}_{n_z}) &amp; \textcolor{red}{C_{z,y}(\bf{u}_2,\bf{u}_1)} &amp; \textcolor{red}{C_{z,y}(\bf{u}_2,\bf{u}_2)} &amp; \dots &amp; \textcolor{red}{C_{z,y}(\bf{u}_2,\bf{u}_{n_y})} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
C_z(\bf{u}_{n_z},\bf{u}_1) &amp; C_z(\bf{u}_{n_z},\bf{u}_2) &amp; \dots &amp; C_z(\bf{u}_{n_z},\bf{u}_{n_z}) &amp; \textcolor{red}{C_{z,y}(\bf{u}_{n_z},\bf{u}_1)} &amp; \textcolor{red}{C_{y,z}(\bf{u}_{n_z},\bf{u}_2)} &amp; \dots &amp; \textcolor{red}{C_{y,z}(\bf{u}_{n_z},\bf{u}_{n_y})} \\
\textcolor{red}{C_{y,z}(\bf{u}_1,\bf{u}_1)} &amp; \textcolor{red}{C_{y,z}(\bf{u}_1,\bf{u}_2)} &amp; \dots &amp; \textcolor{red}{C_{y,z}(\bf{u}_1,\bf{u}_{n_z})} &amp; \textcolor{blue}{C_y(\bf{u}_1,\bf{u}_1)} &amp; \textcolor{blue}{C_y(\bf{u}_1,\bf{u}_2)} &amp; \dots &amp; \textcolor{blue}{C_y(\bf{u}_1,\bf{u}_{n_y})} \\
\textcolor{red}{C_{z,y}(\bf{u}_2,\bf{u}_1)} &amp; \textcolor{red}{C_{z,y}(\bf{u}_2,\bf{u}_2)} &amp; \dots &amp; \textcolor{red}{C_{y,z}(\bf{u}_2,\bf{u}_{n_z})} &amp; \textcolor{blue}{C_y(\bf{u}_2,\bf{u}_1)} &amp; \textcolor{blue}{C_y(\bf{u}_2,\bf{u}_2)} &amp; \dots &amp; \textcolor{blue}{C_y(\bf{u}_2,\bf{u}_{n_y})} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\textcolor{red}{C_{y,z}(\bf{u}_{n_y},\bf{u}_{1})} &amp; \textcolor{red}{C_{y,z}(\bf{u}_{n_y},\bf{u}_{2})} &amp; \dots &amp; \textcolor{red}{C_{y,z}(\bf{u}_{n_y},\bf{u}_{n_z})} &amp; \textcolor{blue}{C_y(\bf{u}_{n_y},\bf{u}_1)} &amp; \textcolor{blue}{C_y(\bf{u}_{n_y},\bf{u}_2)} &amp; \dots &amp; \textcolor{blue}{C_y(\bf{u}_{n_y},\bf{u}_{n_y})} \\
\end{bmatrix} \cdot 
\begin{bmatrix} 
\lambda_{z_1} \\ \lambda_{z_2} \\ \vdots \\ \lambda_{z_n} \\ \textcolor{blue}{\lambda_{y_1}} \\ \textcolor{blue}{\lambda_{y_2}} \\ \vdots \\ \textcolor{blue}{\lambda_{y_n}} \\
\end{bmatrix} = 
\begin{bmatrix} 
C_z(\bf{u}_1,\bf{u}) \\ C_z(\bf{u}_2,\bf{u})  \\ \vdots \\ C_z(\bf{u}_n,\bf{u}) \\ \textcolor{blue}{C_{z,y}(\bf{u}_1,\bf{u})} \\ \textcolor{blue}{C_{z,y}(\bf{u}_2,\bf{u})} \\ \vdots \\ \textcolor{blue}{C_{z,y}(\bf{u}_n,\bf{u})}
\end{bmatrix}
\end{split}\]</div>
<p>where we assume that there are <span class="math notranslate nohighlight">\(1, 2, \ldots, n_z\)</span> primary data <span class="math notranslate nohighlight">\(z\)</span>, and <span class="math notranslate nohighlight">\(1, 2, \ldots, n_y\)</span> secondary data <span class="math notranslate nohighlight">\(y\)</span>.</p>
<ul class="simple">
<li><p>note, I could be more rigorous with the notation and indicate the location <span class="math notranslate nohighlight">\(\bf{u}_{1}\)</span> for <span class="math notranslate nohighlight">\(z\)</span> and <span class="math notranslate nohighlight">\(y\)</span> may not be the same location, but the notation was already getting quite dense.</p></li>
</ul>
<p>This system integrates the,</p>
<ul class="simple">
<li><p><em>spatial continuity</em> - as quantified by the variogram (and covariance function to calculate the covariance, <span class="math notranslate nohighlight">\(C\)</span>, values)</p></li>
<li><p><em>redundancy</em> - the degree of spatial continuity between all of the available data with themselves, <span class="math notranslate nohighlight">\(C(\bf{u}_i,\bf{u}_j)\)</span></p></li>
<li><p><em>closeness</em> - the degree of spatial continuity between the available data and the estimation location, <span class="math notranslate nohighlight">\(C(\bf{u}_i,\bf{u})\)</span></p></li>
<li><p><em>relationship</em> - between the primary and secondary features over lag distance from the cross covariance terms, <span class="math notranslate nohighlight">\(C_{z,y}\)</span> and <span class="math notranslate nohighlight">\(C_{y,z}\)</span>.</p></li>
</ul>
<p>Once the weights are calculated from the above linear system of equations, the cokriging estimator is expressed as,</p>
<div class="math notranslate nohighlight">
\[
z^{*}_{COK}(\bf{u}) = \sum_{\alpha_z = 1}^{n_z} \lambda_{\alpha_z} \cdot z(\bf{u}_{\alpha_z}) + \sum_{\alpha_y = 1}^{n_y} \lambda_{\alpha_y} \cdot y(\bf{u}_{\alpha_{y}}) 
\]</div>
<p>assuming that each feature is detrended such that the mean is 0.0.</p>
<p>Some general comments about cokriging,</p>
<ul class="simple">
<li><p>the secondary data and primary data may be collocated, not collocated or even mixed with some collocated and some not</p></li>
<li><p>we must calculate and model the direct variograms, <span class="math notranslate nohighlight">\(\gamma_z\)</span> and <span class="math notranslate nohighlight">\(\gamma_y\)</span> and the cross variogram <span class="math notranslate nohighlight">\(\gamma_{z,y}\)</span>. For all direct and cross variograms to be jointly positive definite we must used the constraints from the linear model of corregionalization.</p></li>
<li><p>we could expand the model to consider any number of secondary features!</p></li>
</ul>
<p>Once again, cokriging is rarely used in practice, more often simplifying variants such as <em>collocated cokriging</em> or <em>cloud transform</em> are applied</p>
</section>
<section id="collocated-cokriging">
<h2><strong>Collocated Cokriging</strong><a class="headerlink" href="#collocated-cokriging" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_cosimulation.html"><span class="doc std std-doc">Cosimulation</span></a>: a variant of cokriging that introduces 2 assumptions to greatly simplify the method.</p>
<ol class="arabic simple">
<li><p><em>Markov screening</em> - only one (the collocated) secondary feature datum is considered, i.e., we only include the secondary datum at the location we are estimating the primary feature. We are assuming that the collocated secondary datum will screen all other secondary data at other locations away from the estimate.</p></li>
</ol>
<ul class="simple">
<li><p>as a result, we don’t need to calculate the secondary variogram, and we have a much smaller cokriging system.</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p><em>Bayesian updating</em> - the cross covariance <span class="math notranslate nohighlight">\(C_{z,y}(\bf{h})\)</span> is assumed to be a linear scaling of the direct covariance <span class="math notranslate nohighlight">\(C_z(\bf{h})\)</span>. The Bayesian formulation for <span class="math notranslate nohighlight">\(C_{z,y}(\bf{h})\)</span> is,</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
C_{z,y}(\bf{h}) =  C_z(\bf{h}) \cdot \rho_{z,y}
\]</div>
<p>where <span class="math notranslate nohighlight">\(\rho_{z,y}\)</span> is the prior, <span class="math notranslate nohighlight">\(C_z(\bf{h})\)</span> is the likelihood, and <span class="math notranslate nohighlight">\(C_{z,y}(\bf{h})\)</span> is the posterior.</p>
<ul class="simple">
<li><p>as a result, we do not need to calculate the cross variogram</p></li>
</ul>
<p>The collocated cokriging system of equations in matrix notation are,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
C_z(\bf{u}_1,\bf{u}_1) &amp; C_z(\bf{u}_1,\bf{u}_2) &amp; \dots &amp; C_z(\bf{u}_1,\bf{u}_{n_z}) &amp; \textcolor{red}{C_{z}(\bf{u}_1,\bf{u}) \cdot C_{z,y}(0)} \\
C_z(\bf{u}_2,\bf{u}_1) &amp; C_z(\bf{u}_2,\bf{u}_2) &amp; \dots &amp; C_z(\bf{u}_2,\bf{u}_{n_z}) &amp; \textcolor{red}{C_{z}(\bf{u}_2,\bf{u}) \cdot C_{z,y}(0)} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots \\
C_z(\bf{u}_{n_z},\bf{u}_1) &amp; C_z(\bf{u}_{n_z},\bf{u}_2) &amp; \dots &amp; C_z(\bf{u}_{n_z},\bf{u}_{n_z}) &amp; \textcolor{red}{C_{z}(\bf{u}_{n_z},\bf{u}) \cdot C_{z,y}(0)} \\
\textcolor{red}{C_{z}(\bf{u},\bf{u}_1) \cdot C_{z,y}(0)} &amp; \textcolor{red}{C_{z}(\bf{u},\bf{u}_2) \cdot C_{z,y}(0)} &amp; \dots &amp; \textcolor{red}{C_{z}(\bf{u},\bf{u}_{n_z}) \cdot C_{z,y}(0)} &amp; \textcolor{blue}{\sigma_y^2} \\
\end{bmatrix} \cdot 
\begin{bmatrix} 
\lambda_{z_1} \\ \lambda_{z_2} \\ \vdots \\ \lambda_{z_n} \\ \textcolor{blue}{\lambda_{y}} \\
\end{bmatrix} = 
\begin{bmatrix} 
C_z(\bf{u}_1,\bf{u}) \\ C_z(\bf{u}_2,\bf{u})  \\ \vdots \\ C_z(\bf{u}_n,\bf{u}) \\ \textcolor{blue}{C_{z,y}(0)} \\
\end{bmatrix}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(C_{z,y}(0)\)</span> is the cross covariance at lag distance <span class="math notranslate nohighlight">\(\bf{h} = 0\)</span>, for standardized features (variance of 1.0) this is the correlation coefficient, <span class="math notranslate nohighlight">\(C_{z,y}(0) = \rho_{z,y}\)</span>.</p>
</section>
<section id="complimentary-events-probability">
<h2><strong>Complimentary Events</strong> (probability)<a class="headerlink" href="#complimentary-events-probability" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_probability.html"><span class="doc std std-doc">Probability Concepts</span></a>: the NOT operator for probability, if we define A then A compliment, <span class="math notranslate nohighlight">\(A^c\)</span>, is not A and we have this resulting closure relationship,</p>
<div class="math notranslate nohighlight">
\[
P(A) + P(A^c) = 1.0
\]</div>
<p>complimentary events may be considered for beyond univariate problems, for example consider this bivariate closure,</p>
<div class="math notranslate nohighlight">
\[
P(A|B) + P(A^c|B) = 1.0
\]</div>
<p>Note, the given term must be the same.</p>
</section>
<section id="conditional-probability">
<h2><strong>Conditional Probability</strong><a class="headerlink" href="#conditional-probability" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_probability.html"><span class="doc std std-doc">Probability Concepts</span></a>: the probability of an event, given another event has occurred,</p>
<div class="math notranslate nohighlight">
\[
P(A|B) = \frac{P(A,B)}{P(A)}
\]</div>
<p>we read this as the probability of A given B has occurred as the joint divided by the marginal. We can extend conditional probabilities to any multivariate case by adding joints to either component. For example,</p>
<div class="math notranslate nohighlight">
\[
P(C|B,A) = \frac{P(A,B,C)}{P(B,C)}
\]</div>
</section>
<section id="core-data">
<h2><strong>Core Data</strong><a class="headerlink" href="#core-data" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: the primary sampling method for direct measure for subsurface resources (recovered drill cuttings are also direct measures with greater uncertainty and smaller, irregular scale). Comments on core data,</p>
<ul class="simple">
<li><p>expensive / time consuming to collect for oil and gas, interrupt drilling operations, sparse and selective (very biased) coverage</p></li>
<li><p>very common in mining (diamond drill holes) for grade control with regular patterns and tight spacing</p></li>
<li><p>gravity, piston, etc. coring are used to sample sediments in lakes and oceans</p></li>
</ul>
<p>What do we learn from core data?</p>
<ul class="simple">
<li><p>petrological features (sedimentary structures, mineral grades), petrophysical features (porosity, permeability), and mechanical features (elastic modulas, Poisson’s ratio)</p></li>
<li><p>stratigraphy and ore body geometry through interpolation betweeen wells and drill holes</p></li>
</ul>
<p>Core data are critical to support subsurface resource interpretations. They anchor the entire reservoir concept and  framework for prediction,</p>
<ul class="simple">
<li><p>for example, core data collocated with well log data are used to calibrate (ground truth) facies, porosity from well logs</p></li>
</ul>
</section>
<section id="correlogram">
<h2><strong>Correlogram</strong><a class="headerlink" href="#correlogram" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_variogram_calculation.html"><span class="doc std std-doc">Variogram Calculation</span></a>: a measure of similarity vs. distance. Calculated as the average product of values separated by a lag vector centered by the square of the mean standardize by the variance.</p>
<div class="math notranslate nohighlight">
\[
\rho_x(\bf{h}) = \frac{1}{n \cdot \sigma^2_x} \sum_{\alpha = 1}^{n} x(\bf{u}_{\alpha}) \cdot x(\bf{u}_{\alpha} + \bf{h}) 
\]</div>
<p>When the feature is standardized to have a variance of 1.0, the correlogram is equal to the covariance function.</p>
<div class="math notranslate nohighlight">
\[
\rho_x(\bf{h}) = C_x(\bf{h})
\]</div>
<p>and in that case the correlogram is the variogram upside down,</p>
<div class="math notranslate nohighlight">
\[
\rho_x(\bf{h}) = \sigma_x^2 - \gamma_x(\bf{h}), \quad \text{if} \quad \sigma^2_x = 1.0
\]</div>
<p>The correlogram is very easy to interprete since it is the correlation over the specified lag distance.</p>
</section>
<section id="cosimulation">
<h2><strong>Cosimulation</strong><a class="headerlink" href="#cosimulation" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_cosimulation.html"><span class="doc std std-doc">Cosimulation</span></a>: a set of methods for simulating a spatial realization of a primary feature conditional to a secondary feature realization. All of these methods attempt to capture the primary feature spatial continuity and conditioning to local data while honoring the relationship with the secondary feature.</p>
<p>Each cosimulation method will have a conditioning priority,</p>
<p><em>collocated cokriging</em> - prioritizes the primary feature histogram and variogram and may honor the correlation coefficient between the two primary and secondary features.</p>
<ul class="simple">
<li><p>the relationship with between the primary and secondary features is limited to a correlation coefficient (after Gaussian transform of both, i.e., in Gaussian space)</p></li>
<li><p>in the case of dense conditioning data the relationship observed at the data locations will override the correlation coefficient.</p></li>
</ul>
<p><em>cloud transform</em> - honors the specific form of the bivariate relationship (cloud) between the two features but may not honor the histogram nor the variogram.</p>
<ul class="simple">
<li><p>the precise scatter plot between the primary and secondary feature is prioritized</p></li>
</ul>
<p>These methods start with a completed realization of the secondary feature, for example,</p>
<ul class="simple">
<li><p>first simulate a copper realization and then cosimulate the zinc (primary feature) realization given the copper (secondary feature) realization with the collocated cokriging and the correlation coefficient between Gaussian transformed copper and zinc data</p></li>
<li><p>first simulate a poorsity realization and then cosimulate the permeability (primary feature) realization given the porosity (secondary feature) realization with cloud transform and the scatter plot of Gaussian transformed porosity and permeability</p></li>
</ul>
<p>With cosimulation there is a increasing likelihood that the multiple information sources are contradictory, when this occurs the lower priority information source is preferentially sacrificed</p>
<p>While the full cokriging approach for cosimulation is available, due to the inference burden of modeling all the variograms and cross variograms, it is typically not used in practice.</p>
</section>
<section id="covariance-function">
<h2><strong>Covariance Function</strong><a class="headerlink" href="#covariance-function" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_variogram_calculation.html"><span class="doc std std-doc">Variogram Calculation</span></a>: a measure of similarity vs. distance. Calculated as the average product of values separated by a lag vector centered by the square of the mean.</p>
<div class="math notranslate nohighlight">
\[
C_x(\bf{h}) = \frac{1}{n} \sum_{\alpha = 1}^{n} x(\bf{u}_{\alpha}) \cdot x(\bf{u}_{\alpha} + \bf{h}) - \overline{x}^2
\]</div>
<p>The covariance function is the variogram upside down,</p>
<div class="math notranslate nohighlight">
\[
C_z(\bf{h}) = \sigma_z^2 - \gamma_z(\bf{h})
\]</div>
<p>We model variograms, but inside the kriging and simulation methods they are converted to covariance values for numerical convenience, i.e., covariances result in diagonally dominant matrices that are more stable when inverted to calculate the kriging weights.</p>
</section>
<section id="cumulative-distribution-function-cdf">
<h2><strong>Cumulative Distribution Function (CDF)</strong><a class="headerlink" href="#cumulative-distribution-function-cdf" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_univariate_distributions.html"><span class="doc std std-doc">Univariate Distributions</span></a>: the sum of a discrete PDF or the integral of a continuous PDF. Here are the important concepts,</p>
<ul class="simple">
<li><p>the CDF is stated as <span class="math notranslate nohighlight">\(F_x(x)\)</span>, note the PDF is stated as <span class="math notranslate nohighlight">\(f_x(x)\)</span></p></li>
<li><p>is the probability that a random sample, <span class="math notranslate nohighlight">\(X\)</span>, is less than or equal to a specific value <span class="math notranslate nohighlight">\(x\)</span>; therefore, the y axis is cumulative probability</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
F_x(x) = P(X \le x) = \int_{-infty}^x f(u) du 
\]</div>
<ul class="simple">
<li><p>for CDFs there is no bin assumption; therefore, bins are at the resolution of the data.</p></li>
<li><p>monotonically non-decreasing function, because a negative slope would indicate negative probability over an interval.</p></li>
</ul>
<p>The requirements for a valid CDF include,</p>
<ol class="arabic simple">
<li><p>non-negativity constraint:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
F_x(x) = P(X \le x) \ge 0.0, \quad \forall x
\]</div>
<ol class="arabic simple" start="2">
<li><p>valid probability:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
0.0 \le F_x(x) \le 1.0, \quad \forall x
\]</div>
<ol class="arabic simple" start="3">
<li><p>cannot have negative slope:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
\frac{dF_x(x)}{dx} \ge 0.0, \quad \forall x
\]</div>
<ol class="arabic simple" start="4">
<li><p>minimum and maximum (ensuring probability closure) values:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
\text{min}(F_x(x)) = 0.0 \quad \text{max}(F_x(x)) = 1.0
\]</div>
</section>
<section id="cyclicity-variogram-model">
<h2><strong>Cyclicity</strong> (variogram model)<a class="headerlink" href="#cyclicity-variogram-model" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_variogram_calculation_and_modeling.html"><span class="doc std std-doc">Variogram Calculation and Modeling</span></a>: may be linked to underlying geological periodicity, cycles in the deposition that result in layers.</p>
<ul class="simple">
<li><p>sometimes noise in the experimental variogram due to too few data is mistaken as cyclicity</p></li>
<li><p>the wavelength of the cycles in the experimental variogram is the wavelength of the spatial cycles, i.e. the extent of the layers</p></li>
</ul>
</section>
<section id="data-data-aspects">
<h2><strong>Data</strong> (data aspects)<a class="headerlink" href="#data-data-aspects" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: when describing spatial dataset these are the fundamental aspects,</p>
<p><em>Data coverage</em> - what proportion of the population has been sampled for this?</p>
<p>In general, hard data has high resolution (small scale, volume support), but with poor data coverage (measure only an extremely small proportion of the population, for example,</p>
<ul class="simple">
<li><p><em>Core coverage deepwater oil and gas</em> - well core only sample one five hundred millionth to one five billionth of a deepwater reservoir, assuming 3 inch diameter cores with 10% core coverage in vertical wells with 500 m to 1,500 m spacing</p></li>
<li><p><em>Core coverage mining grade control</em> - diamond drill hole cores sample one eight thousandth to one thirty thousandth of ore body, assuming HQ 63.5 mm diameter cores with 100% core coverage in vertical drill holes with 5 m to 10 m spacing</p></li>
</ul>
<p>Soft data tend to have excellent (often complete) coverage, but with low resolution,</p>
<ul class="simple">
<li><p><em>Seismic reflection surveys and gradiometric surveys</em> - data is generally available over the entire volume of interest, but resolution is low and generally decreasing with depth</p></li>
</ul>
<p><em>Data Scale</em> (support size) - What is the scale or volume sampled by the individual samples? For example,</p>
<ul class="simple">
<li><p>core tomography images corse samples at the pore scale, 1 - 50 <span class="math notranslate nohighlight">\(\mu m\)</span></p></li>
<li><p>gamma ray well log sampled at 0.3 m intervals with 1 m penetration away from the bore hole</p></li>
<li><p>ground-based gravity gradiometry map with 20 m x 20 m x 100 m resolution</p></li>
</ul>
<p><em>Data Information Type</em> - What does the data tell us about the subsurface? For example,</p>
<ul class="simple">
<li><p>grain size distribution that may be applied to calibrate permeability and saturations</p></li>
<li><p>fluid type to assess the location of the oil water contact</p></li>
<li><p>dip and continuity of important reservoir layers to access connectivity</p></li>
<li><p>mineral grade to map high, mid and low grade ore shells for mine planning</p></li>
</ul>
</section>
<section id="data-analytics">
<h2><strong>Data Analytics</strong><a class="headerlink" href="#data-analytics" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: the use of statistics with visualization to support decision making.</p>
<ul class="simple">
<li><p>Dr. Pyrcz says that data analytics is the same as statistics.</p></li>
</ul>
</section>
<section id="debiasing-with-secondary-data">
<h2><strong>Debiasing with Secondary Data</strong><a class="headerlink" href="#debiasing-with-secondary-data" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_declustering.html"><span class="doc std std-doc">Declustering to Correct Sampling Bias</span></a>: when the entire range of the feature of interest is not sampled we cannot use data weights to debias our statistics, instead we use,</p>
<ul class="simple">
<li><p>a secondary feature that is sampled over the entire area of interest</p></li>
<li><p>a relationship between the secondary feature and the primary feature</p></li>
</ul>
<p>to impute the missing part of the primary feature spatial distribution.</p>
<p>The relationship between the primary and secondary feature may be a statistical model with extrapolation to the missing part of the primary feature distribution or based on some other information such as a phyical model</p>
</section>
<section id="decision-criteria">
<h2><strong>Decision Criteria</strong><a class="headerlink" href="#decision-criteria" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: a feature that is calculated by applying the transfer function to the subsurface model(s) to support decision making. The decision criteria represents value, health, environment and safety. For example:</p>
<ul class="simple">
<li><p>contaminant recovery rate to support design of a pump and treat soil remediation project</p></li>
<li><p>oil-in-place resources to determine if a reservoir should be developed</p></li>
<li><p>Lorenz coefficient heterogeneity measure to classify a reservoir and determine mature analogs</p></li>
<li><p>recovery factor or production rate to schedule production and determine optimum facilities</p></li>
<li><p>recovered mineral grade and tonnage to determine economic ultimate pit shell</p></li>
</ul>
</section>
<section id="declustering">
<h2><strong>Declustering</strong><a class="headerlink" href="#declustering" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_declustering.html"><span class="doc std std-doc">Declustering to Correct Sampling Bias</span></a>: various methods that assign weights to spatial samples based on local sampling density, such that the weighted statistics are likely more representative of the population. Data weights are assigned so that,</p>
<ul class="simple">
<li><p>samples in densely sampled areas receive less weight</p></li>
<li><p>samples in sparsely sampled areas receive more weight</p></li>
</ul>
<p>There are various declustering methods:</p>
<ul class="simple">
<li><p><em>cell-based declustering</em></p></li>
<li><p><em>polygonal declustering</em></p></li>
<li><p><em>kriging-based declustering</em></p></li>
</ul>
<p>It is important to note that no declustering method can prove that for every data set the resulting weighted statistics will improve the prediction of the population parameters, but in expectation these methods tend to reduce the bias.</p>
</section>
<section id="declustering-statistics">
<h2><strong>Declustering</strong> (statistics)<a class="headerlink" href="#declustering-statistics" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_declustering.html"><span class="doc std std-doc">Declustering to Correct Sampling Bias</span></a>: once declustering weights are calculated for a spatial dataset, then declustered statistics are applied as input for only subsequent analysis or modeling. For example,</p>
<ul class="simple">
<li><p>the declustered mean is assigned as the stationary, global mean for simple kriging</p></li>
<li><p>the weighted CDF from all the data with weights are applied to sequential Gaussian simulation to ensure the back-transformed realizations approach the declustered distribution</p></li>
</ul>
<p>Any statistic can be weighted, including the entire CDF! Here are some examples of weighted statistics, given declustering weights, <span class="math notranslate nohighlight">\(w(\bf{u}_j)\)</span>, for all data <span class="math notranslate nohighlight">\(j=1,\ldots,n\)</span>.</p>
<ul class="simple">
<li><p>weighted sample mean,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\overline{x}_{wt} = \frac{\sum_{i=1}^n w(\bf{u}_j) \cdot z(\bf{u}_j)}{\sum_{i=1}^n w(\bf{u}_j)} 
\]</div>
<p>where <span class="math notranslate nohighlight">\(n\)</span> is the number of data.</p>
<ul class="simple">
<li><p>weighted sample variance,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
s^2_{x_{wt}} = \frac{1}{\sum_{i=1}^n w(\bf{u}_j) - 1} \cdot \sum_{i=1}^n w(\bf{u}_j) \cdot \left( x(\bf{u}_j) - \overline{x}_{wt} \right)^2 
\]</div>
<p>where <span class="math notranslate nohighlight">\(\overline{x}_{wt}\)</span> is the declustered mean.</p>
<ul class="simple">
<li><p>weighted covariance,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
C_{x,y_{wt}} = \frac{1}{\sum_{i=1}^n w(\bf{u}_j) } \cdot \sum_{i=1}^n w(\bf{u}_j) \cdot \left( x(\bf{u}_j) - \overline{x}_{wt} \right) \cdot \left( y(\bf{u}_j) - \overline{y}_{wt} \right)
\]</div>
<p>where <span class="math notranslate nohighlight">\(\overline{x}_{wt}\)</span> and <span class="math notranslate nohighlight">\(\overline{y}_{wt}\)</span> are the declustered means for features <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>.</p>
<ul class="simple">
<li><p>the entire CDF,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
F_z(z) \approx \sum_{j=1}^{n(Z&lt;z)} w(\bf{u}_j)
\]</div>
<p>where <span class="math notranslate nohighlight">\(n(Z&lt;z)\)</span> is the number of sorted ascending data less than threshold <span class="math notranslate nohighlight">\(z\)</span>. We show this as approximative as this is simplified and at data resolution and without an interpolation model.</p>
<p>It is important to note that no declustering method can prove that for every data set the resulting weighted statistics will improve the prediction of the population parameters, but in expectation these methods tend to reduce the bias.</p>
</section>
<section id="deterministic-model">
<h2><strong>Deterministic Model</strong><a class="headerlink" href="#deterministic-model" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: a model that assumes the system or process that is completely predictable</p>
<ul class="simple">
<li><p>often-based on engineering and geoscience physics and expert judgement</p></li>
<li><p>for example, numerical flow simulation or stratigraphic bounding surfaces interpreted from seismic</p></li>
<li><p>for this course we also state that data-driven estimation models like</p></li>
</ul>
<p>Advantages:</p>
<ul class="simple">
<li><p>integration of physics and expert knowledge</p></li>
<li><p>integration of various information sources</p></li>
</ul>
<p>Disadvantages:</p>
<ul class="simple">
<li><p>often quite time consuming</p></li>
<li><p>often no assessment of uncertainty, focus on building one model</p></li>
</ul>
</section>
<section id="discrete-feature">
<h2><strong>Discrete Feature</strong><a class="headerlink" href="#discrete-feature" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: a <em>categorical feature</em> or a <em>continuous feature</em> that is binned or grouped, for example,</p>
<ul class="simple">
<li><p>porosity between 0 and 20% assigned to 10 bins = {0 - 2%, 2% - 4%, \ldots ,20%}</p></li>
<li><p>Mohs hardness = <span class="math notranslate nohighlight">\(\{1, 2, \ldots, 10\}\)</span> (same at <em>categorical feature</em>)</p></li>
</ul>
</section>
<section id="dispersion-variance">
<h2><strong>Dispersion Variance</strong><a class="headerlink" href="#dispersion-variance" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_volume_variance.html"><span class="doc std std-doc">Volume Variance</span></a>: a generalized form of variance that accounts for the volume support of the samples, <span class="math notranslate nohighlight">\(\cdot\)</span>, or model, <span class="math notranslate nohighlight">\(v\)</span>, and the area of interest, <span class="math notranslate nohighlight">\(V\)</span> represented for data support size as,</p>
<div class="math notranslate nohighlight">
\[
D^2(\cdot, V) 
\]</div>
<p>and for model support size as,</p>
<div class="math notranslate nohighlight">
\[
D^2(v, V) 
\]</div>
<p>for the case of data support size over the volume of interest (including all the spatial data samples) this simplifies to the variance,</p>
<div class="math notranslate nohighlight">
\[
\sigma^2 = D^2(\cdot,V)
\]</div>
<p>therefore, the well-known variance is a special case of dispersion variance. Dispersion variance under the assumption of stationary mean, variance and variogram can be calculated through this equation,</p>
<div class="math notranslate nohighlight">
\[
D^2(v,V) = \overline{\gamma}_{V,V} - \overline{\gamma}_{v,v} 
\]</div>
<p>where <span class="math notranslate nohighlight">\(\overline{\gamma}_{V,V}\)</span> and <span class="math notranslate nohighlight">\(\overline{\gamma}_{v,v}\)</span> are variogram models integrated over volume <span class="math notranslate nohighlight">\(V\)</span> and <span class="math notranslate nohighlight">\(v\)</span> respectively.</p>
</section>
<section id="distribution-transformations">
<h2><strong>Distribution Transformations</strong><a class="headerlink" href="#distribution-transformations" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_transformations.html"><span class="doc std std-doc">Distribution Transformations</span></a>: a mapping from one distribution to another distribution through percentile values, resulting in a new histogram, PDF, and CDF. We perform distribution transformations in geostatistical methods and workflows because,</p>
<ul class="simple">
<li><p><em>inference</em> - to correct a feature distribution to an expected shape, for example, correcting for too few or biased data</p></li>
<li><p><em>theory</em> - a specific distribution assumption is required for a workflow step, for example, Gaussian distribution with mean of 0.0 and variance of 1.0 is required for sequential Gaussian simulation</p></li>
<li><p><em>data preparation or cleaning</em> - to correct for outliers, the transformation will map the outlier into the target distribution no longer as an outlier</p></li>
</ul>
<p>How do we perform distribution transformations?</p>
<p>We transform the values from the cumulative distribution function (CDF), <span class="math notranslate nohighlight">\(F_{X}\)</span>, to a new CDF , <span class="math notranslate nohighlight">\(G_{Y}\)</span>. This can be generalized with the quantile - quantile transformation applied to all the sample data:</p>
<ul class="simple">
<li><p>The forward transform:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
Y = G_{Y}^{-1}(F_{X}(X))
\]</div>
<ul class="simple">
<li><p>The reverse transform:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
X = F_{X}^{-1}(G_{Y}(Y))
\]</div>
<p>This may be applied to any data, including parametric or nonparametric distributions. We just need to be able to map from one distribution to another through percentiles, so it is a:</p>
<ul class="simple">
<li><p>rank preserving transform, for example, P25 remains P25 after distribution transformation</p></li>
</ul>
</section>
<section id="ergodic-fluctuations">
<h2><strong>Ergodic Fluctuations</strong><a class="headerlink" href="#ergodic-fluctuations" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: statistical fluctuations in the input statistics observed over multiple simulated realizations. Here are some general concepts,</p>
<ul class="simple">
<li><p>the magnitude of the fluctuations are a function of the ratio of spatial continuity to the size of the model</p></li>
<li><p>if model is large relative to spatial continuity range then fluctuations should minimal</p></li>
<li><p>if model is small relative to spatial continuity range then fluctuations may be extreme</p></li>
</ul>
<p>When we check out simulated realizations, we should expect some fluctuations in the reproduction of the histogram, variogram and correlation coefficients.</p>
<ul class="simple">
<li><p>best practice is to check the expectation in these statistics vs. the inputs</p></li>
</ul>
</section>
<section id="estimation">
<h2><strong>Estimation</strong><a class="headerlink" href="#estimation" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: is process of obtaining the single best value to represent a feature at an unsampled location, or time. Some additional concepts,</p>
<ul class="simple">
<li><p>local accuracy takes precedence over global spatial variability</p></li>
<li><p>too smooth, not appropriate for any transform function that is sensitive to heterogeneity</p></li>
<li><p>for example, inverse distance and kriging</p></li>
<li><p>many predictive machine learning models focus on estimation (e.g., k-nearest neighbours, decision tree, random forest, etc.)</p></li>
</ul>
</section>
<section id="facies">
<h2><strong>Facies</strong><a class="headerlink" href="#facies" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_categorical_indicator_simulation.html"><span class="doc std std-doc">Indicator Simulation</span></a>: grouping rock into discrete groups, a new categorical feature. A method to group, categorize rock in a useful manner that improves,</p>
<ul class="simple">
<li><p>characterization through statistics, e.g., distributions and variograms</p></li>
<li><p>prediction of features, e.g., porosity and permeability away from wells</p></li>
</ul>
<p>For oil and gas the term is facies, but for mining the terms rock types and zones are commonly used. Also, in oil and gas there are multiple types of facies used,</p>
<ul class="simple">
<li><p><strong>lithofacies</strong> - based on rock-related features only, usually small-scale porosity and permeability clusters and sedimentary structures, for example, shale, sandstone, dolomite, limestone, laminated sandstone, hummocky cross-stratification, etc.</p></li>
<li><p><strong>depofacies</strong> - usually include multiple lithofacies while integrating the concept of geometry, while integrating reservoir significant scale that impacts reservoir flow, well connectivity, for example, channel axis, outer sheet, etc.</p></li>
<li><p><strong>seismic facies</strong> - large-scale distinct acoustic and elastic property and seismic geomorphological expressions, integrated as the large-scale reservoir framework, parallel continuous high amplitude, chaotic amplitudes, mounded discontinuous low amplitudes, truncation, onlap, offlap, etc.</p></li>
</ul>
<p>Here are some important considerations for determining facies,</p>
<ul class="simple">
<li><p>facies / rock type is an important decision for subsurface modeling. Facies or rock type determination should remain a collaborative decision integrating expertise from the entire project team (Geologists, Reservoir Modelers, Reservoir Engineers, Petro- and Geophysicists).</p></li>
<li><p>facies or rock types must improve subsurface prediction away from the data or they do not add value</p></li>
<li><p>number of facies is a balancing act between accuracy of geological concepts and statistical inference, and modeling effort</p></li>
<li><p>reservoir modeling is often hierarchical, for example, elements contain multiple depofacies, depofacies contain multiple lithofacies, lithofacies have specific porosity and permeability distributions</p></li>
<li><p>often 80-90% of reservoir heterogeneity is captured in the facies models</p></li>
</ul>
<p>Here is a summary of criteria for facies, rock types, or any discrete grouping for a subsurface model,</p>
<ol class="arabic simple">
<li><p><strong>separation of rock properties</strong> - facies must be separable over the features of interest that impact subsurface environmental and economic performance, for example, grade, porosity and permeability, etc.</p></li>
<li><p><strong>identifiable in data</strong> - facies must be identifiable with the most common data available, for example, facies identifiable only in cores are not useful if most wells have only logs</p></li>
<li><p><strong>map-able away from data</strong> - facies must be easier to predict away from data than the rock properties of interest directly, facies improve prediction</p></li>
<li><p><strong>sufficient sampling</strong> - there must be enough data to allow for inference of reliable statistics for feature within each facies, i.e., by-facies statistics</p></li>
</ol>
</section>
<section id="facies-simulation">
<h2><strong>Facies Simulation</strong><a class="headerlink" href="#facies-simulation" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_categorical_indicator_simulation.html"><span class="doc std std-doc">Indicator Simulation</span></a>: algorithms to calculate simulated realizations of categorical features, commonly realizations of facies or rock types for mining. There are 4 common methods for simulating facies,</p>
<ul class="simple">
<li><p><strong>sequential indicator simulation</strong> - based on indicator variograms for each facies category and indicator kriging to calculate the local cumulative distribution function within the sequential simulation approach</p></li>
<li><p><strong>multiple point simulation</strong> - image reproduction method based on categorical training images to calculate the local cumulative distribution function with sequential simulation approach</p></li>
<li><p><strong>object-based simulation</strong> - marked point process based on Monte Carlo simulation of geometric parameters and sequential, stochastic placement of the geometry in the volume of interest</p></li>
<li><p><strong>generative AI</strong> - trained deep learning generators to calculate categorical realizations</p></li>
</ul>
</section>
<section id="feature-also-variable">
<h2><strong>Feature</strong> (also variable)<a class="headerlink" href="#feature-also-variable" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: any property measured or observed in a study</p>
<ul class="simple">
<li><p>for example, porosity, permeability, mineral concentrations, saturations, contaminant concentration, etc.</p></li>
<li><p>in data mining / machine learning this is known as a feature, statisticians call these variables</p></li>
<li><p>measure often requires significant analysis, interpretation, etc.</p></li>
<li><p>when features are modified and combined to improve our models we call this feature engineering</p></li>
</ul>
</section>
<section id="frequentist-probability">
<h2><strong>Frequentist Probability</strong><a class="headerlink" href="#frequentist-probability" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_probability.html"><span class="doc std std-doc">Probability Concepts</span></a>: measure of the likelihood that an event will occur based on frequencies observed from an experiment. For random experiments and well-defined settings (such as coin tosses),</p>
<div class="math notranslate nohighlight">
\[
\text{Prob}(A) = P(A) = \lim_{n \to \infty} \frac{n(A)}{n}
\]</div>
<p>where:</p>
<p><span class="math notranslate nohighlight">\(n(A)\)</span> = number of times event <span class="math notranslate nohighlight">\(A\)</span> occurred
<span class="math notranslate nohighlight">\(n\)</span> = number of trails</p>
<p>For example, possibility of drilling a dry hole for the next well, encountering sandstone at a location (<span class="math notranslate nohighlight">\(\bf{u}_{\alpha}\)</span>), exceeding a rock porosity of <span class="math notranslate nohighlight">\(15 \%\)</span> at a location (<span class="math notranslate nohighlight">\(\bf{u}_{\alpha}\)</span>).</p>
</section>
<section id="gamma-bar">
<h2><strong>Gamma Bar</strong><a class="headerlink" href="#gamma-bar" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_volume_variance.html"><span class="doc std std-doc">Volume Variance</span></a>: volume integrated variogram where the tail and head are integrated over volumes <span class="math notranslate nohighlight">\(v\)</span> and <span class="math notranslate nohighlight">\(V\)</span> respectively.</p>
<div class="math notranslate nohighlight">
\[
\overline{\gamma}(v,V) 
\]</div>
<p>The gamma bar value is calculated by the integration,</p>
<div class="math notranslate nohighlight">
\[
\overline{\gamma}(v,V) = \int_{v} \int_{V} \gamma (\bf{u},\bf{u}^{\prime}) d\bf{u} d\bf{u}^{\prime}
\]</div>
<p>a practical approach to calculate gamma bar values is to discretize both volumes <span class="math notranslate nohighlight">\(v\)</span> and <span class="math notranslate nohighlight">\(V\)</span> and to average the variogram values  over the combinatorial,</p>
<div class="math notranslate nohighlight">
\[
\overline{\gamma}(v,V) = \frac{1}{n_v \cdot n_V} \sum_{iv=1}^{n_v} \sum_{iV=1}^{n_V} \gamma \left(v(\bf{u}_{\alpha}),V(\bf{u}_{\beta})\right)
\]</div>
<p>Gamma bar values are applied to calculate spatial continuity integrating volume support of data and model cells. Note, for kriging matrices the volume integrated covariance, known as “c bar”, <span class="math notranslate nohighlight">\(\overline{C}(v,V)\)</span>,</p>
<div class="math notranslate nohighlight">
\[
\overline{C}(v,V) = \sigma^2 - \overline{\gamma}(v,V)
\]</div>
</section>
<section id="geometric-anisotropy-variogram-interpretation">
<h2><strong>Geometric Anisotropy</strong> (variogram interpretation)<a class="headerlink" href="#geometric-anisotropy-variogram-interpretation" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_variogram_calculation.html"><span class="doc std std-doc">Variogram Calculation</span></a>: the same variogram structures are observed over all directions, but the range depends on the direction</p>
<ul class="simple">
<li><p>commonly, the vertical range of correlation is much less than the horizontal range due to the formation of ‘layering’ due to sedimentary processes. Walter’s Law in stratigraphy states that the vertical sequence occurs horizontally at difference scales</p></li>
<li><p>the ratio of the horizontal to vertical range, <span class="math notranslate nohighlight">\(a_{hori}:a_{vert}\)</span> is commonly known as the horizontal to vertical anisotropy ratio, for example, a fluvial setting may have a 10:1 horizontal to vertical anisotropy ratio.</p></li>
<li><p>geometric anisotropy is common for the horizontal directions also, the ratio of horizontal major direction: horizontal minor direction range, <span class="math notranslate nohighlight">\(a_{maj}:a_{min}\)</span>, is commonly known as the horizontal major to minor anisotropy ratio</p></li>
</ul>
</section>
<section id="geometric-anisotropy-variogram-model">
<h2><strong>Geometric Anisotropy</strong> (variogram model)<a class="headerlink" href="#geometric-anisotropy-variogram-model" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_variogram_calculation_and_modeling.html"><span class="doc std std-doc">Variogram Calculation and Modeling</span></a>: we assume geometric anisotropy to model 2D and 3D variogram over all directions from experimental variograms calculated only in primary directions.</p>
<ul class="simple">
<li><p>this model provides a valid interpolation of the variogram between the primary directions</p></li>
<li><p>the geometric anisotropy model is based on this lag distance,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
h = \sqrt{ \left( \frac{\bf{h}_{maj}}{a_{maj}} \right)^2 + \left( \frac{\bf{h}_{min}}{a_{min}} \right)^2 + \left( \frac{\bf{h}_{vert}}{a_{vert}} \right)^2 }
\]</div>
<p>where <span class="math notranslate nohighlight">\(a_{maj}, a_{maj}, a_{vert}\)</span> are the ranges in the major, minor and vertical directions and <span class="math notranslate nohighlight">\(\bf{h}_{maj}, \bf{h}_{maj}, \bf{h}_{vert}\)</span> are the lag distance components in the major, minor and vertical directions.</p>
</section>
<section id="geostatistics">
<h2><strong>Geostatistics</strong><a class="headerlink" href="#geostatistics" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: a branch of applied statistics that integrates:</p>
<ol class="arabic simple">
<li><p>the spatial (geological) context</p></li>
<li><p>the spatial relationship</p></li>
<li><p>volumetric support / scale</p></li>
<li><p>uncertainty</p></li>
</ol>
<p>I include all spatial statistics with geostatistics, some disagree with me on this. From my experience, any useful statistical method for modeling spatial phenomenon is adopted and added to the geostatistics toolkit! Geostatistics is an expanding and evolving field of study.</p>
</section>
<section id="global-accuracy">
<h2><strong>Global Accuracy</strong><a class="headerlink" href="#global-accuracy" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_simulation.html"><span class="doc std std-doc">Simulation</span></a>: we honor (match) global measures calculated over the entire volume of interest, for example, the mean, variance, entire <strong>cumulative distribution function</strong>, etc.</p>
</section>
<section id="global-measures">
<h2><strong>Global Measures</strong><a class="headerlink" href="#global-measures" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_simulation.html"><span class="doc std std-doc">Simulation</span></a>: statistical summaries over the entire volume of interest, for example, the mean, variance, entire <strong>cumulative distribution function</strong>, etc.</p>
</section>
<section id="hard-data">
<h2><strong>Hard Data</strong><a class="headerlink" href="#hard-data" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: data that has a high degree of certainty, usually from a direct measurement from the rock</p>
<ul class="simple">
<li><p>for example, well core-based and well log-based porosity and lithofacies</p></li>
</ul>
<p>In general, hard data has high resolution (small scale, volume support), but with poor coverage (measure only an extremely small proportion of the population, for example,</p>
<ul class="simple">
<li><p><strong>Core coverage deepwater oil and gas</strong> - well core only sample one five hundred millionth to one five billionth of a deepwater reservoir, assuming 3 inch diameter cores with 10% core coverage in vertical wells with 500 m to 1,500 m spacing</p></li>
<li><p><strong>Core coverage mining grade control</strong> - diamond drill hole cores sample one eight thousandth to one thirty thousandth of ore body, assuming HQ 63.5 mm diameter cores with 100% core coverage in vertical drill holes with 5 m to 10 m spacing</p></li>
</ul>
</section>
<section id="histogram">
<h2><strong>Histogram</strong><a class="headerlink" href="#histogram" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_univariate_distributions.html"><span class="doc std std-doc">Univariate Distributions</span></a>: a representation of the univariate statistical distribution with a plot of frequency over an exhaustive set of bins over the range of possible values. These are the steps to build a histogram,</p>
<ol class="arabic simple">
<li><p>Divide the continuous feature range of possible values into <span class="math notranslate nohighlight">\(K\)</span> equal size bins, <span class="math notranslate nohighlight">\(\delta x\)</span>:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
\Delta x = \left( \frac{x_{max} - x_{min}}{K} \right)
\]</div>
<p>or use available category labels for categorical features.</p>
<ol class="arabic simple" start="2">
<li><p>Count the number of samples (frequency) in each bin, <span class="math notranslate nohighlight">\(n_k\)</span>, \quad <span class="math notranslate nohighlight">\(\forall \quad k=1,\ldots,K\)</span>.</p></li>
<li><p>Plot the frequency vs. the bin label (use bin centroid if continuous)</p></li>
</ol>
<p>Note, histograms are typically plotted as a bar chart.</p>
</section>
<section id="hybrid-model">
<h2><strong>Hybrid Model</strong><a class="headerlink" href="#hybrid-model" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: system or process that includes a combination of both <em>deterministic model</em> and <em>stochastic model</em></p>
<ul class="simple">
<li><p>most geostatistical models are hybrid models</p></li>
<li><p>for example, additive deterministic trend models and stochastic residual models</p></li>
</ul>
</section>
<section id="independence-probability">
<h2><strong>Independence</strong> (probability)<a class="headerlink" href="#independence-probability" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_probability.html"><span class="doc std std-doc">Probability Concepts</span></a>: events <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> are independent if and only if the following relations are true,</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(P(A \cap B) = P(A) \cdot P(B)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(A|B) = P(A)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(B|A) = P(B)\)</span></p></li>
</ol>
<p>If any of these are violated we suspect that there exists some form of relationship.</p>
</section>
<section id="indicator-kriging">
<h2><strong>Indicator Kriging</strong><a class="headerlink" href="#indicator-kriging" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_categorical_indictor_kriging.html"><span class="doc std std-doc">Indicator Kriging</span></a>: the application of simple kriging to a set of <em>indicator transforms</em>, one for each threshold for a continuous features, or one for each category for cateogorical features, of the data to directly estimate the local uncertainty model <em>cumulative distribution function</em> at an unknown location, <span class="math notranslate nohighlight">\(\bf{u}\)</span>.</p>
<p>The indicator kriging estimator is defined as,</p>
<div class="math notranslate nohighlight">
\[
p^*_{IK}(\mathbf{u}; k) =
\sum_{\alpha=1}^n \lambda_\alpha(k) \cdot i(\mathbf{u}_\alpha; k) 
+ \left( 1 - \sum_{\alpha=1}^n \lambda_\alpha(k) \right) \cdot p(k)
\]</div>
<p>where <span class="math notranslate nohighlight">\(\lambda_\alpha(k)\)</span> is the indicator kriging weight for data <span class="math notranslate nohighlight">\(\alpha\)</span> and category or threshold <span class="math notranslate nohighlight">\(k\)</span>, <span class="math notranslate nohighlight">\(i(\mathbf{u}_\alpha; k)\)</span> is the <span class="math notranslate nohighlight">\(k\)</span> category or threshold indicator transform of the data at location <span class="math notranslate nohighlight">\(\mathbf{u}_\alpha\)</span> and <span class="math notranslate nohighlight">\(p(k)\)</span> is the global or local mean categorical probability (if a trend model is provided) or the continuous cumulative probability.</p>
<ul class="simple">
<li><p>by estimating probability <span class="math notranslate nohighlight">\(p^*_{IK}(\mathbf{u}; k)\)</span> for each threshold or category we are directly estimating the distribution of uncertainty at an unsampled location without any distribution assumption (i.e., no Gaussian assumption)</p></li>
</ul>
<p>The steps for indicator kriging are,</p>
<ol class="arabic simple">
<li><p>Establish a series of thresholds or categories:</p></li>
</ol>
<ul class="simple">
<li><p>for categorical features, the categories are given</p></li>
<li><p>for continuous features, the thresholds should cover the entire range of the feature with enough thresholds to represent the local distributions of uncertainty (so we can resolve the local <em>cumulative distribution function</em>’s)</p></li>
<li><p>for continuous features, the thresholds may be related to critical thresholds, e.g., environmental limits, economic thresholds.</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p>Apply indicator transformation to the data</p></li>
<li><p>Calculate the <em>indicator variogram</em> from the indicator transformation of the data for each threshold or category</p></li>
<li><p>Apply indicator kriging to estimate the cumulative probability for continuous features or probability for categorical features at an unsampled location, using the indicator variogram for each threshold or category</p></li>
<li><p>Correct the final cumulative distribution function to be valid, this is called the <em>order relations correction</em>.</p></li>
</ol>
<ul class="simple">
<li><p>since each threshold’s cumulative probability is estimated by indicator kriging separately, the resulting cumulative distribution function may not be valid, i.e., non-monotonic increasing</p></li>
<li><p>since each category’s probability is estimated by indictor kriging separately, the probabilities may not sum to one</p></li>
</ul>
<p>General comments,</p>
<ul class="simple">
<li><p>a variogram model is needed for each threshold or category; therefore, a more difficult inference problem, however, there is greater flexibility as spatial continuity may vary by value, for example, greater spatial continuity for upper tail of the feature distribution</p></li>
<li><p>more readily integrates data of different types through soft data encoding, for example, we could assign a <em>random variable</em> (distribution) at data locations instead of a single value</p></li>
</ul>
</section>
<section id="indicator-transform">
<h2><strong>Indicator Transform</strong><a class="headerlink" href="#indicator-transform" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_categorical_indictor_kriging.html"><span class="doc std std-doc">Indicator Kriging</span></a>: indicator coding a random variable to a probability relative to a category or a threshold.</p>
<p>If <span class="math notranslate nohighlight">\(i(\bf{u}:z_k)\)</span> is an indicator for a categorical variable,</p>
<ul class="simple">
<li><p>what is the probability of a realization equal to a category?</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
i(\bf{u}; z_k) =
\begin{cases} 
    1, &amp; \text{if } Z(\bf{u}) = z_k \\
    0, &amp; \text{if } Z(\bf{u}) \ne z_k 
\end{cases}
\end{split}\]</div>
<p>for example,</p>
<ul class="simple">
<li><p>given threshold, <span class="math notranslate nohighlight">\(z_2 = 2\)</span>, and data at <span class="math notranslate nohighlight">\(\bf{u}_1\)</span>, <span class="math notranslate nohighlight">\(z(\bf{u}_1) = 2\)</span>, then <span class="math notranslate nohighlight">\(i(bf{u}_1; z_2) = 1\)</span></p></li>
<li><p>given threshold, <span class="math notranslate nohighlight">\(z_1 = 1\)</span>, and a RV away from data, <span class="math notranslate nohighlight">\(Z(\bf{u}_2)\)</span> then is calculated as <span class="math notranslate nohighlight">\(F^{-1}_{\bf{u}_2}(z_1)\)</span> of the RV as <span class="math notranslate nohighlight">\(i(\bf{u}_2; z_1) = 0.23\)</span></p></li>
</ul>
<p>If <span class="math notranslate nohighlight">\(I\{{\bf{u}:z_k\}\)</span> is an indicator for a continuous variable,</p>
<ul class="simple">
<li><p>what is the probability of a realization less than or equal to a threshold?</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
i(\bf{u}; z_k) =
\begin{cases} 
    1, &amp; \text{if } Z(\bf{u}) \le z_k \\
    0, &amp; \text{if } Z(\bf{u}) &gt; z_k 
\end{cases}
\end{split}\]</div>
<p>for example,</p>
<ul class="simple">
<li><p>given threshold, <span class="math notranslate nohighlight">\(z_1 = 6\%\)</span>, and data at <span class="math notranslate nohighlight">\(\bf{u}_1\)</span>, <span class="math notranslate nohighlight">\(z(\bf{u}_1) = 8\%\)</span>, then <span class="math notranslate nohighlight">\(i(\bf{u}_1; z_1) = 0\)</span></p></li>
<li><p>given threshold, <span class="math notranslate nohighlight">\(z_4 = 18\%\)</span>, and a RV away from data, <span class="math notranslate nohighlight">\(Z(\bf{u}_2) = N\left[\mu = 16\%,\sigma = 3\%\right]\)</span> then <span class="math notranslate nohighlight">\(i(\bf{u}_2; z_4) = 0.75\)</span></p></li>
</ul>
<p>The indicator coding may be applied over an entire random function by indicator transform of all the random variables at each location.</p>
</section>
<section id="indicator-variogram">
<h2><strong>Indicator Variogram</strong><a class="headerlink" href="#indicator-variogram" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_categorical_indictor_kriging.html"><span class="doc std std-doc">Indicator Kriging</span></a>: varogram’s calculated and modelled from the <em>indicator transform</em> of spatial data and used for indicator kriging. The indicator variogram is,</p>
<div class="math notranslate nohighlight">
\[
\gamma_i(\mathbf{h}; z_k) = \frac{1}{2N(\mathbf{h})} 
\sum_{\alpha=1}^{N(\mathbf{h})} 
\left[ i(\mathbf{u}_\alpha; z_k) - i(\mathbf{u}_\alpha + \mathbf{h}; z_k) \right]^2
\]</div>
<p>where <span class="math notranslate nohighlight">\(i(\mathbf{u}_\alpha; z_k)\)</span> and <span class="math notranslate nohighlight">\(i(\mathbf{u}_\alpha + \mathbf{h}; z_k)\)</span> are the indicator transforms for the <span class="math notranslate nohighlight">\(z_k\)</span> threshold at the tail location <span class="math notranslate nohighlight">\(\mathbf{u}_\alpha\)</span> and head location <span class="math notranslate nohighlight">\(\mathbf{u}_\alpha + \mathbf{h}\)</span> respectively.</p>
<ul class="simple">
<li><p>for hard data the indicator transform <span class="math notranslate nohighlight">\(i(\bf{u},z_k)\)</span> is either 0 or 1, in which case the <span class="math notranslate nohighlight">\(\left[ i(\mathbf{u}_\alpha; z_k) - i(\mathbf{u}_\alpha + \mathbf{h}; z_k) \right]^2\)</span> is equal to 0 when the values at head and tail are both <span class="math notranslate nohighlight">\(\le z_k\)</span> (for continuous features) or <span class="math notranslate nohighlight">\(= z_k\)</span>  (for categorical features), the same relative to the threshold, or 1 when they are different.</p></li>
<li><p>therefore, the indicator variogram is <span class="math notranslate nohighlight">\(\frac{1}{2}\)</span> the proportion of pairs that change! The indicator variogram can be related to probability of change over a lag distance, <span class="math notranslate nohighlight">\(h\)</span>.</p></li>
<li><p>the sill of an indicator variogram is the indicator variance calculated as,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\sigma_i^2 = p \cdot (1 - p)
\]</div>
<p>where <span class="math notranslate nohighlight">\(p\)</span> is the proportion of 1’s (or zeros as the function is symmetric over proportion)</p>
</section>
<section id="inference-inferential-statistics">
<h2><strong>Inference, Inferential Statistics</strong><a class="headerlink" href="#inference-inferential-statistics" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: this is a big topic, but for the course I provide this simplified, functional definition, given a random sample from a population, describe the population, for example,</p>
<ul class="simple">
<li><p>given the well samples, describe the reservoir</p></li>
<li><p>given the drill hole samples, describe the ore body</p></li>
</ul>
</section>
<section id="intersection-of-events-probability">
<h2><strong>Intersection of Events</strong> (probability)<a class="headerlink" href="#intersection-of-events-probability" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_probability.html"><span class="doc std std-doc">Probability Concepts</span></a>: the intersection of outcomes, the probability of <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> is represented as,</p>
<div class="math notranslate nohighlight">
\[
P(A \cap B) = P(A,B)
\]</div>
<p>under the assumption of independence of <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> the probability of <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> is,</p>
<div class="math notranslate nohighlight">
\[
P(A,B) = P(A) \cdot P(B)
\]</div>
</section>
<section id="isotropic-or-omnidirectional-variogram">
<h2><strong>Isotropic or Omnidirectional</strong> (variogram)<a class="headerlink" href="#isotropic-or-omnidirectional-variogram" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_variogram_calculation.html"><span class="doc std std-doc">Variogram Calculation</span></a>: variogram calculated such that direction, azimuth in 2D horizontal or azimuth and dip in 3D, are not considered,</p>
<ul class="simple">
<li><p>for an isotropic experimental variogram set the azimuth tolerance as 90 degrees, then the experimental variogram is insensitive to direction.</p></li>
</ul>
<p>or variogram is modelled such that direction, azimuth in 2D horizontal or azimuth and dip in 3D, does not impact the model,</p>
<ul class="simple">
<li><p>for an isotropic variogram model set the major range equal to the minor range, then the variogram model is insensitive to direction</p></li>
</ul>
</section>
<section id="joint-probability">
<h2><strong>Joint Probability</strong><a class="headerlink" href="#joint-probability" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_probability.html"><span class="doc std std-doc">Probability Concepts</span></a>: probability that considers more than one event occurring together, the probability of <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> is represented as,</p>
<div class="math notranslate nohighlight">
\[
P(A \cap B) = P(A,B)
\]</div>
<p>or the probability of <span class="math notranslate nohighlight">\(A\)</span>, <span class="math notranslate nohighlight">\(B\)</span> and <span class="math notranslate nohighlight">\(C\)</span> is represented as,</p>
<div class="math notranslate nohighlight">
\[
P(A \cap B \cap C) = P(A,B,C)
\]</div>
<p>under the assumption of independence of <span class="math notranslate nohighlight">\(A\)</span>, <span class="math notranslate nohighlight">\(B\)</span> and <span class="math notranslate nohighlight">\(C\)</span> the joint probability may be calculated as,</p>
<div class="math notranslate nohighlight">
\[
P(A,B,C) = P(A) \cdot P(B) \cdot P(C)
\]</div>
</section>
<section id="local-accuracy">
<h2><strong>Local Accuracy</strong><a class="headerlink" href="#local-accuracy" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_simulation.html"><span class="doc std std-doc">Simulation</span></a>: estimates that minimizes the estimation variance. Local measures and local accuracy do not consider matching global measures like the entire histogram, including the global mean and variance.</p>
</section>
<section id="local-measures">
<h2><strong>Local Measures</strong><a class="headerlink" href="#local-measures" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_simulation.html"><span class="doc std std-doc">Simulation</span></a>: feature estimates at individual location. <em>Local accuracy</em> is estimates that minimizes the estimation variance at each location. Local measures and local accuracy do not consider matching global measures like the entire histogram, including the global mean and variance.</p>
</section>
<section id="kriging">
<h2><strong>Kriging</strong><a class="headerlink" href="#kriging" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_kriging.html"><span class="doc std std-doc">Simple and Ordinary Kriging</span></a>: spatial estimation approach that relies on linear weights that account for spatial continuity, data closeness and redundancy. The kriging estimate is,</p>
<div class="math notranslate nohighlight">
\[
z^*(\bf{u}) = \sum_{\alpha = 1}^{n} \lambda_{\alpha} \cdot z(\bf{u}_{\alpha}) + \left( 1.0 - \sum_{\alpha=1}^n \lambda_{\alpha} \right) \cdot m_z
\]</div>
<ul class="simple">
<li><p>the right term is the unbiasedness constraint, one minus the sum of the weights is applied to the global mean.</p></li>
</ul>
<p>In the case where the trend, <span class="math notranslate nohighlight">\(t(\bf{u})\)</span>, is removed, we now have a residual, <span class="math notranslate nohighlight">\(y(\bf{u})\)</span>,</p>
<div class="math notranslate nohighlight">
\[
y(\bf{u}) = z(\bf{u}) - t(\bf{u}) 
\]</div>
<p>the residual mean is zero so we can simplfy our kriging estimate as,</p>
<div class="math notranslate nohighlight">
\[
y^*(\bf{u}) = \sum_{\alpha = 1}^{n} \lambda_{\alpha} \cdot y(\bf{u}_{\alpha}) 
\]</div>
<p>The simple kriging weights are calculated by solving a linear system of equations,</p>
<div class="math notranslate nohighlight">
\[
\sum_{j=1}^n \lambda_j C(\bf{u}_i,\bf{u}_j) = C(\bf{u},\bf{u}_i), \quad i=1,\ldots,n
\]</div>
<p>that may be represented with matrix notation as,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
C(\bf{u}_1,\bf{u}_1) &amp; C(\bf{u}_1,\bf{u}_2) &amp; \dots &amp; C(\bf{u}_1,\bf{u}_n) \\
C(\bf{u}_2,\bf{u}_1) &amp; C(\bf{u}_2,\bf{u}_2) &amp; \dots &amp; C(\bf{u}_2,\bf{u}_n) \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
C(\bf{u}_n,\bf{u}_1) &amp; C(\bf{u}_n,\bf{u}_2) &amp; \dots &amp; C(\bf{u}_n,\bf{u}_n) \\
\end{bmatrix} \cdot 
\begin{bmatrix} 
\lambda_1 \\ \lambda_2 \\ \vdots \\ \lambda_n \\
\end{bmatrix} = 
\begin{bmatrix} 
C(\bf{u}_1,\bf{u}) \\ C(\bf{u}_2,\bf{u})  \\ \vdots \\ C(\bf{u}_n,\bf{u})  \\
\end{bmatrix}
\end{split}\]</div>
<p>This system may be derived by substituting the equation for kriging estimates into the equation for estimation variance, and then setting the partial derivative with respect to the weights to zero.</p>
<ul class="simple">
<li><p>we are optimizing the weights to minimize the estimation variance</p></li>
</ul>
<p>this system integrates the,</p>
<ul class="simple">
<li><p><em>spatial continuity</em> as quantified by the variogram (and covariance function to calculate the covariance, <span class="math notranslate nohighlight">\(C\)</span>, values)</p></li>
<li><p><em>redundancy</em> the degree of spatial continuity between all of the available data with themselves, <span class="math notranslate nohighlight">\(C(\bf{u}_i,\bf{u}_j)\)</span></p></li>
<li><p><em>closeness</em> the degree of spatial continuity between the available data and the estimation location, <span class="math notranslate nohighlight">\(C(\bf{u}_i,\bf{u})\)</span></p></li>
</ul>
<p>Kriging provides a measure of estimation accuracy known as kriging variance (a specific case of estimation variance).</p>
<div class="math notranslate nohighlight">
\[
\sigma^{2}_{E}(\bf{u}) = C(0) - \sum^{n}_{\alpha = 1} \lambda_{\alpha} C(\bf{u}_0 - \bf{u}_{\alpha})
\]</div>
<p>Kriging estimates are best in that they minimize the above estimation variance.</p>
<p>Properties of kriging estimates include,</p>
<ul class="simple">
<li><p><em>Exact interpolator</em> - kriging estimates with the data values at the data locations</p></li>
<li><p><em>Kriging variance</em> - a measure of uncertainty in a kriging estimate. Can be calculated before getting the sample information, as the kriging estimation variance is not dependent on the values of the data nor the kriging estimate, i.e. the kriging estimator is homoscedastic.</p></li>
<li><p><em>Spatial context</em> - kriging takes integrates spatial continuity, closeness and redundancy; therefore, kriging accounts for the configuration of the data and structural continuity of the feature being estimated.</p></li>
<li><p><em>Scale</em> - kriging by default assumes the estimate and data are at the same point support, i.e., mathematically represented as points in space with zero volume. Kriging may be generalized to account for the support volume of the data and estimate,</p></li>
<li><p><em>Multivariate</em> - kriging may be generalized to account for multiple secondary data in the spatial estimate with the cokriging system. We will cover this later.</p></li>
<li><p><em>Smoothing effect</em> - of kriging can be forecasted as the missing variance. The missing variance over local estimates is the kriging variance.</p></li>
</ul>
</section>
<section id="kriging-simple-vs-ordinary">
<h2><strong>Kriging</strong> (simple vs. ordinary)<a class="headerlink" href="#kriging-simple-vs-ordinary" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_kriging.html"><span class="doc std std-doc">Simple and Ordinary Kriging</span></a>: the difference between simple kriging and ordinary kriging is related to the assumption of stationarity in the mean.</p>
<p><em>Simple Kriging</em> - global stationary mean is an input provided by the user, i.e., the mean is assumed to be stationary.</p>
<div class="math notranslate nohighlight">
\[
z^*(\bf{u}) = \sum_{\alpha = 1}^{n} \lambda_{\alpha} \cdot z(\bf{u}_{\alpha}) + \left( 1.0 - \sum_{\alpha=1}^n \lambda_{\alpha} \right) \cdot m_z
\]</div>
<ul class="simple">
<li><p>for the kriging estimate, one minus the sum of the data weights is applied to the global stationary mean.</p></li>
<li><p>at data locations all weight is applied to the collocated datum, and beyond the variogram range from all data all weight is applied to the global mean.</p></li>
<li><p>the simple kriging weights, <span class="math notranslate nohighlight">\(\lambda_1, \lambda_2, \dots, \lambda_n\)</span>, are calculated by solving this system of equations represented in matrix notation as,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
C(\bf{u}_1,\bf{u}_1) &amp; C(\bf{u}_1,\bf{u}_2) &amp; \dots &amp; C(\bf{u}_1,\bf{u}_n) \\
C(\bf{u}_2,\bf{u}_1) &amp; C(\bf{u}_2,\bf{u}_2) &amp; \dots &amp; C(\bf{u}_2,\bf{u}_n) \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
C(\bf{u}_n,\bf{u}_1) &amp; C(\bf{u}_n,\bf{u}_2) &amp; \dots &amp; C(\bf{u}_n,\bf{u}_n) \\
\end{bmatrix} \cdot 
\begin{bmatrix} 
\lambda_1 \\ \lambda_2 \\ \vdots \\ \lambda_n \\
\end{bmatrix} = 
\begin{bmatrix} 
C(\bf{u}_1,\bf{u}) \\ C(\bf{u}_2,\bf{u})  \\ \vdots \\ C(\bf{u}_n,\bf{u})  \\
\end{bmatrix}
\end{split}\]</div>
<p><em>Ordinary Kriging</em> - local nonstationary mean calculated by the kriging system. The global mean is not an input, instead the local nonstationary mean is calculated by ordinary kriging. This relaxes the assumption of a stationary mean.</p>
<ul class="simple">
<li><p>this is accomplished with the addition of a data kriging weights must sum to one constraint in the kriging system, if the weights must sum to one this removes the right hand unbiasedness constraint from the kriging estimate with the global mean,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
z^*(\bf{u}) = \sum_{\alpha = 1}^{n} \lambda_{\alpha} \cdot z(\bf{u}_{\alpha})
\]</div>
<ul class="simple">
<li><p>at data locations all weight is applied to the collocated datum, and beyond the variogram range from all data, all weight is applied to the local mean calculated from local data</p></li>
<li><p>the ordinary kriging weights, <span class="math notranslate nohighlight">\(\lambda_1, \lambda_2, \dots, \lambda_n\)</span>, are calculated by solving this system of equations, the simple kriging system with the added constraint that the weight sum to 1.0 represented in matrix notation as,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
C(\bf{u}_1,\bf{u}_1) &amp; C(\bf{u}_1,\bf{u}_2) &amp; \dots &amp; C(\bf{u}_1,\bf{u}_n) &amp; 1 \\
C(\bf{u}_2,\bf{u}_1) &amp; C(\bf{u}_2,\bf{u}_2) &amp; \dots &amp; C(\bf{u}_2,\bf{u}_n) &amp; 1 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots \\
C(\bf{u}_n,\bf{u}_1) &amp; C(\bf{u}_n,\bf{u}_2) &amp; \dots &amp; C(\bf{u}_n,\bf{u}_n) &amp; 1 \\
1 &amp; 1 &amp; \dots &amp; 1 &amp; 0 \\
\end{bmatrix} \cdot 
\begin{bmatrix} 
\lambda_1 \\ \lambda_2 \\ \vdots \\ \lambda_n \\ \mu \\
\end{bmatrix} = 
\begin{bmatrix} 
C(\bf{u}_1,\bf{u}) \\ C(\bf{u}_2,\bf{u})  \\ \vdots \\ C(\bf{u}_n,\bf{u})  \\ 1 \\
\end{bmatrix}
\end{split}\]</div>
</section>
<section id="kriging-variance">
<h2><strong>Kriging Variance</strong><a class="headerlink" href="#kriging-variance" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_kriging.html"><span class="doc std std-doc">Simple and Ordinary Kriging</span></a>: a measure of uncertainty in a kriging estimate.</p>
<div class="math notranslate nohighlight">
\[
\sigma^{2}_{z}(\bf{u}) = C(0) - \sum^{n}_{\alpha = 1} \lambda_{\alpha} C(\bf{u}_0 - \bf{u}_{\alpha})
\]</div>
<p>Kriging variance is a specific case of estimation variance,</p>
<div class="math notranslate nohighlight">
\[
\sigma^{2}_{E}(\bf{u}) = E \left[ \left(z(\bf{u}) - z^{*}(\bf{u}) \right)^2 \right]
\]</div>
<p>Can be calculated before getting the sample information, as the kriging estimation variance is not dependent on the values of the data nor the kriging estimate, i.e. the kriging estimator is homoscedastic.</p>
</section>
<section id="kriging-based-declustering">
<h2><strong>Kriging-based Declustering</strong><a class="headerlink" href="#kriging-based-declustering" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_declustering.html"><span class="doc std std-doc">Declustering to Correct Sampling Bias</span></a>: a declustering method to assign weights to spatial samples based on local sampling density, such that the weighted statistics are likely more representative of the population. Data weights are assigned so that,</p>
<ul class="simple">
<li><p>samples in densely sampled areas receive less weight</p></li>
<li><p>samples in sparsely sampled areas receive more weight</p></li>
</ul>
<p>Kriging-based declustering proceeds as follows:</p>
<ol class="arabic simple">
<li><p>calculate and model the experimental variogram</p></li>
<li><p>apply kriging to calculate estimates over a high-resolution grid covering the area of interest</p></li>
<li><p>calculate the sum of the weights assigned to each data</p></li>
<li><p>assign data weights proportional to this sum of weights</p></li>
</ol>
<p>The weights are calculated as:</p>
<div class="math notranslate nohighlight">
\[
w(\bf{u}_j) =   n \cdot \frac{\sum_{iy}^{ny} \sum_{ix}^{nx} \lambda_j}{\sum_{i=1}^n \left[ \sum_{iy}^{ny} \sum_{ix}^{nx} \lambda_{j,ix,iy} \right]}
\]</div>
<p>where <span class="math notranslate nohighlight">\(nx\)</span> and <span class="math notranslate nohighlight">\(ny\)</span> are the number of cells in the grid, <span class="math notranslate nohighlight">\(n\)</span> is the number of data, and <span class="math notranslate nohighlight">\(\lambda_{j,ix,iy}\)</span> is the weight assigned to the <span class="math notranslate nohighlight">\(j\)</span> data at the <span class="math notranslate nohighlight">\(ix,iy\)</span> grid cell.</p>
<p>Here is an important point for kriging-based declustering,</p>
<ul class="simple">
<li><p>like polygonal declustering, kriging-based declustering is sensitive to the boundaries of the area of interest; therefore, the weights assigned to the data near the boundary of the area of interest may change radically as the area of interest is expanded or contracted</p></li>
</ul>
<p>Also, kriging-based declustering integrates the spatial continuity model from variogram model. Consider the following possible impacts of the variogram model on the declustering weights,</p>
<ul class="simple">
<li><p>if there is 100% relative nugget effect, there is no spatial continuity and therefore, all data receives equal weight. Note for the equation above this results in a divide by 0.0 error that must be checked for in the code.</p></li>
<li><p>geometric anisotropy may significantly impact the weights as data aligned over specific azimuths are assessed as closer or further in terms of covariance</p></li>
</ul>
</section>
<section id="kolmogorovs-3-probability-axioms">
<h2><strong>Kolmogorov’s 3 Probability Axioms</strong><a class="headerlink" href="#kolmogorovs-3-probability-axioms" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_probability.html"><span class="doc std std-doc">Probability Concepts</span></a>: these are Kolmogorov’s 3 axioms for valid probabilities,</p>
<ol class="arabic simple">
<li><p>Probability of an event is a non-negative number.</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
Prob(𝐴) \ge 0
\]</div>
<ol class="arabic simple" start="2">
<li><p>Probability of the entire sample space, all possible outcomes, <span class="math notranslate nohighlight">\(\Omega\)</span>, is one (unity), also known as probability closure.</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
Prob(\Omega) = 1
\]</div>
<ol class="arabic simple" start="3">
<li><p>Additivity of mutually exclusive events for unions.</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
Prob\left(⋃_{i=1}^{\infty} A_i\right) = \sum_{i=1}^{\infty} Prob(A_i)
\]</div>
<p>e.g., probability of <span class="math notranslate nohighlight">\(A_1\)</span> and <span class="math notranslate nohighlight">\(A_2\)</span> mutual exclusive events is, <span class="math notranslate nohighlight">\(Prob(A_1 + A_2) = Prob(A_1) + Prob(A_2)\)</span></p>
</section>
<section id="lag-variogram">
<h2><strong>Lag</strong> (variogram)<a class="headerlink" href="#lag-variogram" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_variogram_calculation.html"><span class="doc std std-doc">Variogram Calculation</span></a>: the separation between paired data described by a vector, <span class="math notranslate nohighlight">\(\bf{h}\)</span>.</p>
<ul class="simple">
<li><p>the experimental variogram characterizes spatial continuity over a variety of lags (with magnitude and orientations) and the variogram model is applied to calculate spatial continuity for all possible lags (all possible separation distances and orientation)</p></li>
</ul>
</section>
<section id="lag-distance-variogram">
<h2><strong>Lag Distance</strong> (variogram)<a class="headerlink" href="#lag-distance-variogram" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_variogram_calculation.html"><span class="doc std std-doc">Variogram Calculation</span></a>: the magnitude of the lag vector, <span class="math notranslate nohighlight">\(\bf{h}\)</span>, describing separation between paired data for variogram calculation and modeling</p>
<ul class="simple">
<li><p>the experimental variogram characterizes spatial continuity over a variety of lag distances and the variogram model is applied to calculate spatial continuity for all possible lag distances</p></li>
</ul>
</section>
<section id="lag-distance-tolerance-variogram">
<h2><strong>Lag Distance Tolerance</strong> (variogram)<a class="headerlink" href="#lag-distance-tolerance-variogram" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_variogram_calculation.html"><span class="doc std std-doc">Variogram Calculation</span></a>: for calculating experimental variograms, the tolerance <span class="math notranslate nohighlight">\(+/-\Delta\)</span> in <strong>lag distance</strong> applied to pool pairs of data for that specific lag distance.</p>
<ul class="simple">
<li><p>for example, given a lag distance of 300 m, we could assign a lag tolerance of 50 m and then all data pairs separated by 250 m - 350 m will be pooled to calculate the experimental variogram for this lag distance</p></li>
<li><p>it is common practice to use half the unit lag distance for lag tolerance. This may be increased to smooth the experimental variogram for improved interpretability</p></li>
</ul>
</section>
<section id="location-map">
<h2><strong>Location Map</strong><a class="headerlink" href="#location-map" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_univariate_distributions.html"><span class="doc std std-doc">Univariate Distributions</span></a>: a data plot where the 2 axes are locations, e.g., <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>, Easting and Northing, Latitude and Longitude, etc., to show the locations and magnitudes of the spatial data.</p>
<ul class="simple">
<li><p>often the data points are colored to represent the scale of feature to visualize the sampled feature over the area or volume of interest</p></li>
<li><p>advantage, visualize the data without any model that may bias our impression of the data</p></li>
<li><p>disadvantage, may be difficult to visualize large datasets and data in 3D</p></li>
</ul>
</section>
<section id="major-direction-variogram">
<h2><strong>Major Direction</strong> (variogram)<a class="headerlink" href="#major-direction-variogram" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_variogram_calculation.html"><span class="doc std std-doc">Variogram Calculation</span></a>: when calculating an experimental variogram, the direction with the largest variogram range, greatest spatial continuity</p>
<ul class="simple">
<li><p>commonly the major and minor directions describe spatial continuity for 2D phenomenon or in 3D the horizontal (or stratigraphically aligned) coordinates are augmented with a vertical (orthogonal to major and minor) direction</p></li>
</ul>
</section>
<section id="marginal-probability">
<h2><strong>Marginal Probability</strong><a class="headerlink" href="#marginal-probability" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_probability.html"><span class="doc std std-doc">Probability Concepts</span></a>: probability that considers only one event occurring, the probability of <span class="math notranslate nohighlight">\(A\)</span>,</p>
<div class="math notranslate nohighlight">
\[
P(A)
\]</div>
<p>marginal probabilities may be calculated from joint probabilities through the process of marginalization,</p>
<div class="math notranslate nohighlight">
\[
P(A) = \int_{-\infty}^{\infty} P(A,B) dB
\]</div>
<p>where we integrate over all cases of the other event, <span class="math notranslate nohighlight">\(B\)</span>, to remove its influence. Given discrete possible cases of event <span class="math notranslate nohighlight">\(B\)</span> we can simply sum the probabilities over all possible cases of <span class="math notranslate nohighlight">\(B\)</span>,</p>
<div class="math notranslate nohighlight">
\[
P(A) = \sum_{i=1}^{k_B} P(A,B) dB
\]</div>
</section>
<section id="minor-direction-variogram">
<h2><strong>Minor Direction</strong> (variogram)<a class="headerlink" href="#minor-direction-variogram" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_variogram_calculation.html"><span class="doc std std-doc">Variogram Calculation</span></a>: when calculating an experimental variogram, the direction with the smallest variogram range, that must be orthogonal to the <strong>major direction</strong> (a limitation of our <strong>geometric anisotropy</strong> model)</p>
<ul class="simple">
<li><p>commonly the major and minor directions describe spatial continuity for 2D phenomenon or in 3D the horizontal (or stratigraphically aligned) coordinates are augmented with a vertical (orthogonal to major and minor) direction</p></li>
</ul>
</section>
<section id="model-checking">
<h2><strong>Model Checking</strong><a class="headerlink" href="#model-checking" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_model_checking.html"><span class="doc std std-doc">Model Checking</span></a>: is a critical last step for any spatial modeling workflow. Here are the critical aspects of model checking,</p>
<ol class="arabic simple">
<li><p><em>Model Inputs</em> - data and statistics integration</p></li>
</ol>
<ul class="simple">
<li><p>check the model to ensure the model inputs are honored in the models, generally checked over all the realizations, for example, the output histograms and matches the input histogram over the realizations</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p><em>Accurate Spatial Estimates</em> - ability of the model to accurately predict away from the available sample data, over a variety of configurations, with accuracy</p></li>
</ol>
<ul class="simple">
<li><p>by cross validation, withholding some of the data, check the model’s ability to predict</p></li>
<li><p>generally, summarized with a truth vs. predicted cross plot and measures such as mean square error</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
MSE = \frac{1}{n} \sum_{\alpha = 1}^{n} \left(z^{*}(\bf{u}_{\alpha}) - z(\bf{u}_{\alpha}) \right)^2
\]</div>
<ol class="arabic simple" start="3">
<li><p><em>Accurate and Precise Uncertainty Models</em> - uncertainty model is fair given the amount of information available and various sources of uncertainty</p></li>
</ol>
<ul class="simple">
<li><p>also checked through cross validation, withholding some of the data, but by checking the proportion of the data in specific probability intervals</p></li>
<li><p>summarized with a proportion of withheld data in interval vs. the probability interval</p></li>
<li><p>points on the 45 degree line indicate accurate and precise uncertainty model</p></li>
<li><p>points above the 45 degree line indicate accurate and imprecise uncertainty model, uncertainty is too wide</p></li>
<li><p>points below the 45 degree line indicate inaccurate uncertainty model, uncertainty is too narrow or model is biased</p></li>
</ul>
</section>
<section id="monte-carlo-simulation-mcs">
<h2><strong>Monte Carlo Simulation (MCS)</strong><a class="headerlink" href="#monte-carlo-simulation-mcs" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_transformations.html"><span class="doc std std-doc">Distribution Transformations</span></a>: a random sample from a statistical distribution, random variable. The steps for MCS are:</p>
<ol class="arabic simple">
<li><p>model the feature cumulative distribution function, <span class="math notranslate nohighlight">\(F_x(x)\)</span></p></li>
<li><p>draw random value from a uniform [0,1] distribution, this is a random cumulative probability value, known as a p-value, <span class="math notranslate nohighlight">\(p^{\ell}\)</span></p></li>
<li><p>apply the inverse of the cumulative distribution function to calculate the associated realization</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
x^{\ell} = F_x^{-1} (p^{\ell})
\]</div>
<ol class="arabic simple" start="4">
<li><p>repeat to calculate enough realizations for the subsequent analysis</p></li>
</ol>
<p>Monte Carlo simulation is the basic building block of stochastic simulation workflows, for example,</p>
<ul class="simple">
<li><p><em>Monte Carlo simulation workflows</em> - apply Monte Carlo simulation many over all features to the transfer function to calculate a realization of the decision criteria, repeated for many realizations, to propogate uncertainty through a transfer function</p></li>
<li><p><em>Bootstrap</em> - applies Monte Carlo simulation to aquire realizations of the data to calculate uncertainty in sample statistics or ensembles of prediction models for ensemble-based machine learning</p></li>
<li><p><em>Monte Carlo methods</em> - applies Monte Carlo simulation to speed up an expensive calculation with a limited random sample that converges on the solution as the number of random samples increases</p></li>
</ul>
</section>
<section id="monte-carlo-simulation-workflow">
<h2><strong>Monte Carlo Simulation Workflow</strong><a class="headerlink" href="#monte-carlo-simulation-workflow" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_transformations.html"><span class="doc std std-doc">Distribution Transformations</span></a>: a convenient stochastic workflow for propagating uncertainty through a transfer function through sampling with Monte Carlo Simulation (MCS). The workflow includes the following steps,</p>
<ol class="arabic simple">
<li><p>Model all the input features’ distributions, cumulative distribution functions,</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
F_{x_1}(x_1), \quad F_{x_2}(x_2), \quad \dots \quad , F_{x_m}(x_m) 
\]</div>
<ol class="arabic simple" start="2">
<li><p>Monte Carlo simulate a realizations for all the inputs,</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
x_1^{\ell}, \quad x_2^{\ell}, \quad \ldots \quad , x_m^{\ell}
\]</div>
<ol class="arabic simple" start="3">
<li><p>Apply to the transfer function to get a realization of the transfer function output, often the <strong>decision criteria</strong></p></li>
</ol>
<div class="math notranslate nohighlight">
\[
y^{\ell} = f \left(x_1^{\ell},x_2^{\ell}, \quad \ldots \quad, x_m^{\ell} \right)
\]</div>
<ol class="arabic simple" start="4">
<li><p>Repeat steps 1-3 to calculate enough realizations to model the transfer function output distribution.</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
F_y(y)
\]</div>
</section>
<section id="multiplication-rule-probability">
<h2><strong>Multiplication Rule</strong> (probability)<a class="headerlink" href="#multiplication-rule-probability" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_probability.html"><span class="doc std std-doc">Probability Concepts</span></a>: we can calculate the joint probablity of <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> as the product of the conditional probability of <span class="math notranslate nohighlight">\(B\)</span> given <span class="math notranslate nohighlight">\(A\)</span> with the marginal probability of <span class="math notranslate nohighlight">\(A\)</span>,</p>
<div class="math notranslate nohighlight">
\[
P(A \cup B) = P(A,B) = P(B|A) \cdot P(A)
\]</div>
<p>The multiplication rule is derived as a simple manipulation of the definition of conditional probability, in this case,</p>
<div class="math notranslate nohighlight">
\[
P(B|A) = \frac{P(A,B)}{P(A)}
\]</div>
</section>
<section id="mutually-exclusive-events-probability">
<h2><strong>Mutually Exclusive Events</strong> (probability)<a class="headerlink" href="#mutually-exclusive-events-probability" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_probability.html"><span class="doc std std-doc">Probability Concepts</span></a>: the events do not intersect, i.e., do not have any common outcomes. We represent this as,</p>
<ul class="simple">
<li><p>using set notation, we state events <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> are mutually exclusive as,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
A \cap B = \{x: x \in A \text{ and } x \in B \} = \emptyset
\]</div>
<ul class="simple">
<li><p>and the probability for mutually exclusive as,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
P(A,B) = 0.0
\]</div>
</section>
<section id="normalized-histogram">
<h2><strong>Normalized Histogram</strong><a class="headerlink" href="#normalized-histogram" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_univariate_distributions.html"><span class="doc std std-doc">Univariate Distributions</span></a>: is a representation of the univariate statistical distribution with a plot of probability over an exhaustive set of bins over the range of possible values. These are the steps to build a normalized histogram,</p>
<ol class="arabic simple">
<li><p>Divide the continuous feature range of possible values into <span class="math notranslate nohighlight">\(K\)</span> equal size bins, <span class="math notranslate nohighlight">\(\delta x\)</span>:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
\Delta x = \left( \frac{x_{max} - x_{min}}{K} \right)
\]</div>
<p>or use available categories for categorical features.</p>
<ol class="arabic simple" start="2">
<li><p>Count the number of samples (frequency) in each bin, <span class="math notranslate nohighlight">\(n_k\)</span>, <span class="math notranslate nohighlight">\(\forall k=1,\ldots,K\)</span> and divide each by the total number of data, <span class="math notranslate nohighlight">\(n\)</span>, to calculate the probability of each bin,</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
p_k = \frac{n_k}{n}, \forall \quad k = 1,\ldots,L
\]</div>
<ol class="arabic simple" start="4">
<li><p>Plot the probability vs. the bin label (use bin centroid if continuous)</p></li>
</ol>
<p>Note, normalized histograms are typically plotted as a bar chart.</p>
</section>
<section id="nugget-effect-variogram">
<h2><strong>Nugget Effect</strong> (variogram)<a class="headerlink" href="#nugget-effect-variogram" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_variogram_calculation.html"><span class="doc std std-doc">Variogram Calculation</span></a>: discontinuity in the variogram at distances less than the minimum data spacing</p>
<ul class="simple">
<li><p>often communicated as the ratio, nugget effect divided by the sill, known as the relative nugget effect, for example, copper spatial continuity model includes 20% relative nugget effect</p></li>
<li><p>measurement error will cause apparent nugget effect.</p></li>
</ul>
</section>
<section id="order-relations-correction-indicator-kriging">
<h2>Order Relations Correction** (indicator kriging)<a class="headerlink" href="#order-relations-correction-indicator-kriging" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_categorical_indictor_kriging.html"><span class="doc std std-doc">Indicator Kriging</span></a>: correction applied to local <strong>cumulative distribution function</strong>s estimated by indictor kriging. Due to the separate estimation of each cumulative probability over each threshold the cumulative distribution may not be valid, for example,</p>
<ul class="simple">
<li><p>nonmonotonic behavior for continuous features</p></li>
<li><p>sum of categorical probabilities not equal to one (fail to honor <strong>probability closure</strong>)</p></li>
</ul>
<p>For categorical features the order relations correction is the same as the L1 normalizer (machine learning feature transformations),</p>
<div class="math notranslate nohighlight">
\[
i(\bf{u}_{\alpha};z_k)^{\prime} = \frac{i(\bf{u}_{\alpha};z_k)}{\sum_{i=1}^K i(\bf{u}_{\alpha};z_i)}
\]</div>
<ul class="simple">
<li><p>cumulative probability for each threshold <span class="math notranslate nohighlight">\(i(\bf{u}_{\alpha};z_k)\)</span> are divided by the sum of all the cumulative probabilities, <span class="math notranslate nohighlight">\(\sum_{i=1}^K i(\bf{u}_{\alpha};z_i)\)</span> to ensure they sum to 1.0</p></li>
</ul>
<p>For continuous features this involves a two pass calculation that results in two possible cumulative distribution functions that are monotonic increasing that are then averaged to get the corrected result (see my lecture, <a class="reference external" href="https://youtu.be/6mCfgbh7f2g?si=gcbW0V0zvP1UfNxu">Indicator Methods</a>).</p>
</section>
<section id="parameters-statistics">
<h2><strong>Parameters</strong> (statistics)<a class="headerlink" href="#parameters-statistics" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: a summary measure of a population</p>
<ul class="simple">
<li><p>for example, population mean, population standard deviation</p></li>
</ul>
<p>We very rarely have access to actual population parameters, in general we infer population parameters with available sample statistics</p>
</section>
<section id="parameters-machine-learning">
<h2><strong>Parameters</strong> (machine learning)<a class="headerlink" href="#parameters-machine-learning" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: trainable coefficients for a machine learning model that control the fit to the training data</p>
<ul class="simple">
<li><p>model parameters are calculated by optimization to minimize error over the training data through, analytical solution, or iterative solution, e.g., gradient descent optimization</p></li>
</ul>
</section>
<section id="polygonal-declustering">
<h2><strong>Polygonal Declustering</strong><a class="headerlink" href="#polygonal-declustering" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_declustering.html"><span class="doc std std-doc">Declustering to Correct Sampling Bias</span></a>: a declustering method to assign weights to spatial samples based on local sampling density, such that the weighted statistics are likely more representative of the population. Data weights are assigned so that,</p>
<ul class="simple">
<li><p>samples in densely sampled areas receive less weight</p></li>
<li><p>samples in sparsely sampled areas receive more weight</p></li>
</ul>
<p>Polygonal declustering proceeds as follows:</p>
<ol class="arabic simple">
<li><p>Split up the area of interest with Voronoi polygons. These are constructed by intersected perpendicular bisectors between adjacent data points. The polygons group the area of interest by nearest data point</p></li>
<li><p>Assign weight to each datum proportional to the area of the associated Voronoi polygon</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
w(\bf{u}_j) = n \cdot \frac{A_j}{\sum_{j=1}^n}
\]</div>
<p>where <span class="math notranslate nohighlight">\(w(\bf{u}_j)\)</span> is the weight for the <span class="math notranslate nohighlight">\(j\)</span> data. Note, the sum of the weights is <span class="math notranslate nohighlight">\(n\)</span>; therefore, <span class="math notranslate nohighlight">\(w(\bf{u}_j)\)</span> is nominal weight of 1.0, sample density if the data were equally spaced over the area of interest.</p>
<p>Here are some highlights for polygonal declustering,</p>
<ul class="simple">
<li><p>polygonal declustering is sensitive to the boundaries of the area of interest; therefore, the weights assigned to the data near the boundary of the area of interest may change radically as the area of interest is expanded or contracted</p></li>
<li><p>polygonal declustering is the same as the Theissen polygon method for calculation of precipitation averages developed by Afred H. Thiessen in 1911, <span id="id2">[<a class="reference internal" href="references.html#id11" title="A.H. Thiessen. Precipitation Averages for Large Areas. Monthly Weather Review, 1911.">Thi11</a>]</span></p></li>
</ul>
</section>
<section id="population">
<h2><strong>Population</strong><a class="headerlink" href="#population" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: exhaustive, finite list of property of interest over area of interest.</p>
<ul class="simple">
<li><p>for example, exhaustive set of porosity measures at every location within a reservoir</p></li>
</ul>
<p>Generally, the entire population is not generally accessible and we use a limited sample to make inference concerning the population</p>
</section>
<section id="power-law-averaging">
<h2><strong>Power Law Averaging</strong><a class="headerlink" href="#power-law-averaging" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_volume_variance.html"><span class="doc std std-doc">Volume Variance</span></a>: a flexible approach for scale-up via averaging the values at smaller volume <span class="math notranslate nohighlight">\(z_v\)</span> within larger volume <span class="math notranslate nohighlight">\(z_V\)</span> to calculate an effective value representative of the entire volume, <span class="math notranslate nohighlight">\(V\)</span>. The equation is,</p>
<div class="math notranslate nohighlight">
\[
z_V = \left[ \frac{1}{n} \sum z_v^{\omega} \right] ^{\frac{1}{\omega}}
\]</div>
<p>where <span class="math notranslate nohighlight">\(\omega\)</span> is the power of averaging. For example:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\omega = 1\)</span> is a regular linear, arithmetic averaging</p></li>
<li><p><span class="math notranslate nohighlight">\(\omega = -1\)</span> is a harmonic averaging</p></li>
<li><p><span class="math notranslate nohighlight">\(\omega = 0\)</span> is a geometric averaging (this is proved in the limit as <span class="math notranslate nohighlight">\(\omega \rightarrow 0\)</span>)</p></li>
</ul>
<p>For the case of permeability arithmetic averaging occurs for flow along beds, harmonic averaging occurs for flow orthogonal to beds and near-geometric for flow oblique to beds.</p>
</section>
<section id="prediction-predictive-statistics">
<h2><strong>Prediction, Predictive Statistics</strong><a class="headerlink" href="#prediction-predictive-statistics" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: estimate the next sample(s) given assumptions about or a model of the population</p>
<ul class="simple">
<li><p>for example, given our model of the reservoir, predict the next well (pre-drill assessment) sample, e.g., porosity, permeability, production rate, etc.</p></li>
</ul>
</section>
<section id="predictor-feature">
<h2><strong>Predictor Feature</strong><a class="headerlink" href="#predictor-feature" title="Permalink to this heading">#</a></h2>
<p>the input feature for a predictive machine learning model. We can generalize a predictive machine learning model as,</p>
<div class="math notranslate nohighlight">
\[
y = \hat{f}(x_1,\ldots,x_m) + \epsilon
\]</div>
<p>where the response feature is <span class="math notranslate nohighlight">\(y\)</span>, the predictor features are <span class="math notranslate nohighlight">\(x_1,\ldots,x_m\)</span>, and <span class="math notranslate nohighlight">\(\epsilon\)</span> is model error</p>
<ul class="simple">
<li><p>traditional statistics uses the term independent variable</p></li>
</ul>
</section>
<section id="primary-data">
<h2><strong>Primary Data</strong><a class="headerlink" href="#primary-data" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: data samples for the feature of interest, the target feature for building a model, for example,</p>
<ul class="simple">
<li><p>porosity measures from cores and logs used to build a full 3D porosity model. Any samples of porosity are the primary data</p></li>
<li><p>as opposed to secondary feature, e.g., if we have facies data to help predict porosity, the facies data are secondary data</p></li>
</ul>
</section>
<section id="probability-density-function-pdf">
<h2><strong>Probability Density Function (PDF)</strong><a class="headerlink" href="#probability-density-function-pdf" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_univariate_distributions.html"><span class="doc std std-doc">Univariate Distributions</span></a>: a representation of a statistical distribution with a function, <span class="math notranslate nohighlight">\(f(x)\)</span>, of probability density over the range of all possible feature values, <span class="math notranslate nohighlight">\(x\)</span>. These are the concepts for PDFs,</p>
<ul class="simple">
<li><p>non-negativity constraint, the density cannot be negative,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
0.0 \le f(x)
\]</div>
<ul class="simple">
<li><p>for continuous features the density may be &gt; 1.0, because density is a measure of likelihood and not of probability</p></li>
<li><p>integrate density over a range of <span class="math notranslate nohighlight">\(x\)</span> to calculate probability,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
0 \le \int_a^b f(x) dx = P(a \le x \le b) \le 1.0
\]</div>
<ul class="simple">
<li><p>probability closure, the sum of the area under the PDF curve is equal to 1.0,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\int_{-infty}^{\infty} f(x) dx = 1.0
\]</div>
<p>Nonparametric PDFs are calculated with kernels (usual a small Gaussian distribution) that is summed over all data; therefore, there is an implicitly scale (smoothness) parameter when calculating a PDF.</p>
<ul class="simple">
<li><p>To large of kernels will smooth out important information about the univariate distribution</p></li>
<li><p>Too narrow will result in an overly noisy PDF that is difficult to interpret.</p></li>
</ul>
<p>This is analogous to the choice of bin size for a histogram or normalized histogram.</p>
<p>Parametric PDFs are possible but require model fitting to the data, the steps are,</p>
<ol class="arabic simple">
<li><p>Select a parametric distribution, e.g., Gaussian, log normal, etc.</p></li>
<li><p>Calculate the parameters for the parametric distribution based on the available data, by methods such as least squares or maximum likelihood.</p></li>
</ol>
</section>
<section id="probability-non-negativity-normalization">
<h2>Probability Non-negativity, Normalization<a class="headerlink" href="#probability-non-negativity-normalization" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_probability.html"><span class="doc std std-doc">Probability Concepts</span></a>: fundamental constraints on probability including,</p>
<ol class="arabic simple">
<li><p>Bounded, <span class="math notranslate nohighlight">\(0.0 \le P(A) \le 1.0\)</span></p></li>
<li><p>Closure, <span class="math notranslate nohighlight">\(P(\Omega) = 1.0\)</span></p></li>
<li><p>Null Sets, <span class="math notranslate nohighlight">\(P(\emptyset) = 0.0\)</span></p></li>
</ol>
</section>
<section id="probability-operators">
<h2><strong>Probability Operators</strong><a class="headerlink" href="#probability-operators" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_probability.html"><span class="doc std std-doc">Probability Concepts</span></a>: common probability operators that are essential to working with probability and uncertainty problems,</p>
<p><em>Union of Events</em> - the union of outcomes, the probability of <span class="math notranslate nohighlight">\(A\)</span> or <span class="math notranslate nohighlight">\(B\)</span> is calculated with the probability addition rule,</p>
<div class="math notranslate nohighlight">
\[
P(A \cup B) = P(A) + P(B) - P(A,B)
\]</div>
<p><em>Intersection of Events</em> - the intersection of outcomes, the probability of <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> is represented as,</p>
<div class="math notranslate nohighlight">
\[
P(A \cap B) = P(A,B)
\]</div>
<p>only under the assumption of independence of <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> can it be calculate from the probabilities of <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> as,</p>
<div class="math notranslate nohighlight">
\[
P(A,B) = P(A) \cdot P(B)
\]</div>
<p>if there is dependence between <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> then we need the conditional probability, <span class="math notranslate nohighlight">\(P(A|B)\)</span> instead of the marginal, <span class="math notranslate nohighlight">\(P(A)\)</span>,</p>
<div class="math notranslate nohighlight">
\[
P(A,B) = P(A|B) \cdot P(B)
\]</div>
<p><em>Complimentary Events</em> - is the NOT operator for probability, if we define <span class="math notranslate nohighlight">\(A\)</span> then <span class="math notranslate nohighlight">\(A\)</span> compliment, <span class="math notranslate nohighlight">\(A^c\)</span> is not <span class="math notranslate nohighlight">\(A\)</span> and we have this resulting closure relationship,</p>
<div class="math notranslate nohighlight">
\[
P(A) + P(A^c) = 1.0
\]</div>
<p>complimentary events may be considered for beyond univariate problems, for example consider this bivariate closure,</p>
<div class="math notranslate nohighlight">
\[
P(A|B) + P(A^c|B) = 1.0
\]</div>
<p>Note, the given term must be the same.</p>
<p><em>Mutually Exclusive Events</em> - the events that do not intersect or do not have any common outcomes. We represent this with set notation as,</p>
<div class="math notranslate nohighlight">
\[
\{x: x \in A \text{ and } x \in B \} = \emptyset
\]</div>
<p>and the joint probability of <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> as,</p>
<div class="math notranslate nohighlight">
\[
P(A \cap B) = P(A,B) = 0
\]</div>
</section>
<section id="probability-perspectives">
<h2><strong>Probability Perspectives</strong><a class="headerlink" href="#probability-perspectives" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_probability.html"><span class="doc std std-doc">Probability Concepts</span></a>: the 3 primary perspectives for calculating probability:</p>
<ol class="arabic simple">
<li><p><em>Long-term frequencies</em> - probability as ratio of outcomes, requires repeated observations of an experiment. The basis for <em>frequentist probability</em>.</p></li>
<li><p><em>Physical tendencies or propensities</em> - probability from knowledge about or modeling the system, e.g., we could know the probability of a heads outcome from a coin toss without the experiment.</p></li>
<li><p><em>Degrees of belief</em> - reflect our certainty about a result, very flexible, assign probability to anything, and updating with new information. The basis for <em>Bayesian probability</em>.</p></li>
</ol>
</section>
<section id="production-data">
<h2><strong>Production Data</strong><a class="headerlink" href="#production-data" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: includes bottom hole pressure, fluid production, rates, composition, temperatures, commingled over multiple wells, for a single well and even at times along the well bore of a single well. Some additional comments,</p>
<ul class="simple">
<li><p>production from a single well may be comingled over multiple producing intervals, unless production logging tool (PLT) results are available</p></li>
<li><p>important ground truth to be matched with a reservoir model forecasts through the geomodel inversion process called historical production matching</p></li>
</ul>
</section>
<section id="qualitative-features">
<h2><strong>Qualitative Features</strong><a class="headerlink" href="#qualitative-features" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: information about quantities that you cannot directly measure, require interpretation of measurement, and are described with words (not numbers), for example,</p>
<ul class="simple">
<li><p>rock type = sandstone</p></li>
<li><p>zonation = bornite-chalcopyrite-gold higher grade copper zone</p></li>
</ul>
</section>
<section id="quantitative-features">
<h2><strong>Quantitative Features</strong><a class="headerlink" href="#quantitative-features" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: features that can be measured and represented by numbers, for example,</p>
<ul class="simple">
<li><p>age = 10 Ma (millions of years)</p></li>
<li><p>porosity = 0.134 (fraction of volume is void space)</p></li>
<li><p>saturation = 80.5% (volume percentage)</p></li>
</ul>
<p>Like <em>qualitative features</em>, there is often the requirement for interpretation, for example, total porosity may be measured but should be converted to effective porosity through interpretation or a model</p>
</section>
<section id="random-function">
<h2><strong>Random Function</strong><a class="headerlink" href="#random-function" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_variogram_calculation.html"><span class="doc std std-doc">Variogram Calculation</span></a>: set of <em>random variables</em> correlated over space or time, we represent,</p>
<ul class="simple">
<li><p>a random varibles with an upper-case variable, e.g., <span class="math notranslate nohighlight">\(X\)</span></p></li>
<li><p>a random functions with an upper-case variable with location vectors, e.g., <span class="math notranslate nohighlight">\(X(\bf{u}_1), X(\bf{u}_2), \ldots, X(\bf{u}_n)\)</span></p></li>
<li><p>joint outcomes called <em>realizations</em>, or data samples are represented with lower case, e.g., <span class="math notranslate nohighlight">\(x(\bf{u}_1), x(\bf{u}_2), \ldots, x(\bf{u}_n)\)</span></p></li>
<li><p>realizations with the <span class="math notranslate nohighlight">\(\ell\)</span> notation, e.g. <span class="math notranslate nohighlight">\(x^{\ell}(\bf{u}_1), x^{\ell}(\bf{u}_2), \ldots, x^{\ell}(\bf{u}_n)\)</span> for <span class="math notranslate nohighlight">\(\ell = 1,\ldots,L\)</span> realizations.</p></li>
</ul>
</section>
<section id="random-variable">
<h2><strong>Random Variable</strong><a class="headerlink" href="#random-variable" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_univariate_distributions.html"><span class="doc std std-doc">Univariate Distributions</span></a>: we do not know the value of a feature at a location or time, it can take on a range of possible values, fully described with a statistical distribution, <em>probability density function</em> or <em>cumulative distribution function</em>.</p>
<ul class="simple">
<li><p>represented as an upper-case variable, e.g., <span class="math notranslate nohighlight">\(X\)</span>, while possible outcomes or data measures are represented with lower case, e.g., data as <span class="math notranslate nohighlight">\(x_{\alpha}\)</span>, or realization as <span class="math notranslate nohighlight">\(x^{\ell}\)</span></p></li>
</ul>
<p>For spatial phenomenon we add a location vector, <span class="math notranslate nohighlight">\(\bf{u}\)</span>, indexed over data or simulation locations, <span class="math notranslate nohighlight">\(\alpha = 1,\ldots,n\)</span>,</p>
<ul class="simple">
<li><p>a spatial random variable, e.g., <span class="math notranslate nohighlight">\(X(\bf{u}_{\alpha})\)</span></p></li>
<li><p>spatial data measures are represented with lower case, e.g., <span class="math notranslate nohighlight">\(x(\bf{u}_{\alpha})\)</span></p></li>
<li><p>spatial realizations, <span class="math notranslate nohighlight">\(x^{\ell}(\bf{u}_{\alpha})\)</span></p></li>
</ul>
</section>
<section id="range-variogram">
<h2><strong>Range</strong> (variogram)<a class="headerlink" href="#range-variogram" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_variogram_calculation.html"><span class="doc std std-doc">Variogram Calculation</span></a>: lag distance where the experimental variogram reaches the sill. Here’s some more details about the range,</p>
<ul class="simple">
<li><p>for lag distances less than the range there is information and correlation over distance</p></li>
<li><p>for lag distances at and beyond the range there is no information over distance</p></li>
<li><p>range is also a parameter applied to fit positive definite, permissible variogram models</p></li>
<li><p>when the range varies by direction this is called <em>geometric anisotropy</em></p></li>
</ul>
</section>
<section id="realization">
<h2><strong>Realization</strong><a class="headerlink" href="#realization" title="Permalink to this heading">#</a></h2>
<p><span class="xref myst">Geostatistical univariate_distributions</span>: an outcome from a <strong>random variable</strong> or a joint outcome from a <strong>random function</strong>.</p>
<ul class="simple">
<li><p>an outcome from a random variable, <span class="math notranslate nohighlight">\(X\)</span>, (or joint set of outcomes from a random function)</p></li>
<li><p>represented with lower case, e.g., <span class="math notranslate nohighlight">\(x\)</span></p></li>
<li><p>for spatial settings it is common to include a location vector, <span class="math notranslate nohighlight">\(\bf{u}\)</span>, to describe the location, e.g., <span class="math notranslate nohighlight">\(x(\bf{u})\)</span>, as <span class="math notranslate nohighlight">\(X(\bf{u})\)</span></p></li>
<li><p>resulting from simulation, e.g., Monte Carlo simulation, sequential Gaussian simulation, a method to sample (jointly) from the RV (RF)</p></li>
<li><p>in general, we assume all realizations are equiprobable, i.e., have the same probability of occurence</p></li>
</ul>
</section>
<section id="realizations-uncertainty">
<h2><strong>Realizations</strong> (uncertainty)<a class="headerlink" href="#realizations-uncertainty" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: multiple spatial, subsurface models calculated by stochastic simulation by holding input parameters and model choices constant and only changing the random number seed</p>
<ul class="simple">
<li><p>these models represent spatial uncertainty</p></li>
<li><p>for example, hold the porosity mean constant and observe changes in porosity away from the wells over multiple realizations</p></li>
</ul>
</section>
<section id="reservoir-modeling-workflow">
<h2><strong>Reservoir Modeling Workflow</strong><a class="headerlink" href="#reservoir-modeling-workflow" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: the following is the common geostatistical reservoir modeling workflow:</p>
<ol class="arabic simple">
<li><p>Integrate all available information to build multiple subsurface scenarios and realizations to sample the uncertainty space</p></li>
<li><p>Apply all the models to the transfer function to sample the decision criteria</p></li>
<li><p>Assemble the distribution of the decision criteria</p></li>
<li><p>Make the optimum reservoir development decisions accounting for this uncertainty model</p></li>
</ol>
</section>
<section id="response-feature">
<h2><strong>Response Feature</strong><a class="headerlink" href="#response-feature" title="Permalink to this heading">#</a></h2>
<p>output feature for a predictive machine learning model. We can generalize a predictive machine learning model as,</p>
<div class="math notranslate nohighlight">
\[
y = \hat{f}(x_1,\ldots,x_m) + \epsilon
\]</div>
<p>where the response feature is <span class="math notranslate nohighlight">\(y\)</span>, the predictor features are <span class="math notranslate nohighlight">\(x_1,\ldots,x_m\)</span>, and <span class="math notranslate nohighlight">\(\epsilon\)</span> is model error</p>
<ul class="simple">
<li><p>traditional statistics uses the term dependent variable</p></li>
</ul>
</section>
<section id="sample">
<h2><strong>Sample</strong><a class="headerlink" href="#sample" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: the set of values, locations that have been measured</p>
<ul class="simple">
<li><p>for example, 1,000 porosity measures from well-logs over the wells in the reservoir</p></li>
<li><p>or 1,000,000 acoustic impedance measurements over a 1000 x 1000 2D grid for a reservoir unit of interest</p></li>
</ul>
</section>
<section id="scenarios-uncertainty">
<h2><strong>Scenarios</strong> (uncertainty)<a class="headerlink" href="#scenarios-uncertainty" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: multiple spatial, subsurface models calculated by stochastic simulation by changing the input parameters or other modeling choices to represent the uncertainty due to inference of model parameters and model choices</p>
<ul class="simple">
<li><p>for example, model three porosity input distribution, porosity mean low, mid and high, and vary the input distribution to calculate new subsurface models</p></li>
</ul>
</section>
<section id="secondary-data">
<h2><strong>Secondary Data</strong><a class="headerlink" href="#secondary-data" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: data samples for another feature, not the feature of interest, the target feature for building a model, but are used to improve the prediction of the target feature.</p>
<ul class="simple">
<li><p>requires a model of the relationship between the primary and secondary data</p></li>
</ul>
<p>For example, samples in space of,</p>
<ul class="simple">
<li><p>acoustic impedance (secondary data) to support calculation of a model of porosity, the feature of interest</p></li>
<li><p>porosity (secondary data) to support calculation of a model of permeability, the feature of interest</p></li>
</ul>
</section>
<section id="seismic-data">
<h2><strong>Seismic Data</strong><a class="headerlink" href="#seismic-data" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: indirect measurement with remote sensing, reflection seismic applies acoustic source(s) and receivers (geophones) to map acoustic reflections with high coverage and generally low resolution. Some more details,</p>
<ul class="simple">
<li><p>seismic reflections (amplitude) data are inverted to rock properties, e.g., acoustic impedance, consistent with and positionally anchored with well sonic logs</p></li>
<li><p>provides framework, bounding surfaces for extents and shapes of reservoirs along with soft information on reservoir properties, e.g., porosity and facies.</p></li>
</ul>
</section>
<section id="sequential-gaussian-simulation">
<h2><strong>Sequential Gaussian Simulation</strong><a class="headerlink" href="#sequential-gaussian-simulation" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: a simulation method to calculate realizations for spatial models based on the following principles,</p>
<ul class="simple">
<li><p><strong>Sequential</strong> - adding the previously simulated values to the data to ensure the covariance is correct between the simulated values</p></li>
<li><p><strong>Gaussian</strong> - transformation to Gaussian space so that the local distributions of uncertainty are known given the kriging mean and kriging variance, and the global distribution is reproduced after back-transformation to the original distribution</p></li>
<li><p><strong>Simulation</strong> - with Monte Carlo simulation from the local distributions to add in the missing variance and to calculate multiple, equiprobable realizations. The random seed determines the individual Monte Carlo simulations along with the random path for the sequential simulation.</p></li>
</ul>
<p>Here are all the steps for sequential Gaussian simulation,</p>
<ol class="arabic simple">
<li><p>Establish grid network and coordinate system, flatten the system including flattening folds and restoring faults</p></li>
<li><p>Assign data to the grid (account for scale change from data to model grid cells)</p></li>
<li><p>Transform data to Gaussian space, Gaussian anamorphosis applied to original data distribution</p></li>
<li><p>Calculate and model the variogram of the Gaussian transformed data</p></li>
<li><p>Determine a random path through all of the grid nodes, at each node:</p>
<ul class="simple">
<li><p>find nearby data and previously simulated grid nodes</p></li>
<li><p>construct the conditional distribution by kriging, mean as kriging estimate and variance as kriging variance</p></li>
<li><p>Monte Carlo simulate a realization from the conditional distribution</p></li>
<li><p>assign the simulated value to the grid as data</p></li>
</ul>
</li>
<li><p>Check realization (could also check after back transform). Does the realization in Gaussian space honor,</p></li>
</ol>
<ul class="simple">
<li><p>data at the data locations?</p></li>
<li><p>honor the histogram, <span class="math notranslate nohighlight">\(N\left[0,1\right]\)</span> standard normal with a mean of zero and a variance of one?</p></li>
<li><p>and honor the variogram?</p></li>
</ul>
<ol class="arabic simple" start="7">
<li><p>Back-transform the simulated values from Gaussian space to the original data distribution</p></li>
<li><p>Restore to the original framework, including adding back the folds and faults</p></li>
<li><p>Check that the realization honors,</p></li>
</ol>
<ul class="simple">
<li><p>geological concepts?</p></li>
<li><p>geophysical data?</p></li>
<li><p>historical production data?</p></li>
</ul>
<ol class="arabic simple" start="10">
<li><p>Calculate multiple realizations by repeating steps 5 through 9</p></li>
</ol>
<p>Here are the critical steps of the sequential Gaussian simulation algorithm only,</p>
<ol class="arabic simple">
<li><p>Transform the data to Gaussian with a mean of 0.0 and variance of 1.0 (known as standard normal)</p></li>
<li><p>Assign a random path over the model grid, at each grid location sequentially simulation (apply kriging to calculate the local CDF, then Monte Carlo simulate a local realization, and assign the local realization to the data)</p></li>
<li><p>Back-transform the simulated values to the original data distribution</p></li>
</ol>
</section>
<section id="sequential-indicator-simulation">
<h2><strong>Sequential Indicator Simulation</strong><a class="headerlink" href="#sequential-indicator-simulation" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_categorical_indicator_simulation.html"><span class="doc std std-doc">Indicator Simulation</span></a>: a simulation method to calculate continuous or categorical feature realizations for spatial models based on the following principles,</p>
<ul class="simple">
<li><p><em>Sequential</em> - adding the previously simulated values to the data to ensure the covariance is correct between the simulated values.</p></li>
<li><p><em>Indicator</em> - <em>indicator transformation</em> applied to the data over a set of thresholds that allows for flexible probability encoding of hard and soft, continuous and categorical data and the direct estimation of the local <em>cumulative distribution function</em>s.</p></li>
<li><p><em>Simulation</em> with Monte Carlo simulation from the local distributions to add in the missing variance and construction of multiple, equiprobable realizations. The random seed determines the individual Monte Carlo simulations along with the random path for the sequential simulation.</p></li>
</ul>
<p>Here are all the steps for sequential indicator simulation,</p>
<ol class="arabic simple">
<li><p>Establish grid network and coordinate system, flatten the system, including flattening folds and restoring faults</p></li>
<li><p>Assign data to the grid (account for scale change)</p></li>
<li><p>Apply the indicator transform to all data for all thresholds, <span class="math notranslate nohighlight">\(k = 1,\ldots,K\)</span></p></li>
<li><p>Calculate and model the variogram of the indicator transform of the data for each thresholds, <span class="math notranslate nohighlight">\(k = 1,\ldots,K\)</span></p></li>
<li><p>Determine a random path through all of the grid nodes, at each node:</p>
<ul class="simple">
<li><p>find nearby data and previously simulated grid nodes</p></li>
<li><p>for each threshold, construct the local conditional cumulative distribution function by <em>indicator kriging</em></p></li>
<li><p>apply <em>order relations correction</em> to ensure the local <em>cumulative distribution function</em> is valid</p></li>
<li><p>Monte Carlo simulate a realization from the local conditional cumulative distribution function</p></li>
<li><p>assign the simulated value to the grid as data, apply the indicator transform to the simulated value</p></li>
</ul>
</li>
<li><p>Check realization. Does it honor data at the data locations? and honor the histogram, <span class="math notranslate nohighlight">\(N\left[0,1\right]\)</span> standard normal with a mean of zero and a variance of one? and honor the variogram?</p></li>
<li><p>Restore to the original framework, including adding back the folds and faults</p></li>
<li><p>Check honor concept of geology? geophysics and production data?</p></li>
<li><p>Calculate multiple realizations by repeating steps 5 through 8</p></li>
</ol>
</section>
<section id="sill-variogram">
<h2><strong>Sill</strong> (variogram)<a class="headerlink" href="#sill-variogram" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_variogram_calculation.html"><span class="doc std std-doc">Variogram Calculation</span></a>: the feature variance. We interpret spatial correlation relative to the variogram sill,</p>
<ul class="simple">
<li><p>at the distance that the experimental variogram reaches the sill there is no spatial correlation. This is called the range.</p></li>
<li><p>Experimental variogram points above the sill indicate negative correlation, although we do not model above the sill for kriging nor simulation. We model to the sill and assume no correlation beyond the range.</p></li>
<li><p>Experimental variogram that rise linearly above the sill indicates a spatial trend in the data.</p></li>
</ul>
</section>
<section id="simulation">
<h2><strong>Simulation</strong><a class="headerlink" href="#simulation" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: is process of obtaining one or more good values of a reservoir property at an unsampled location.</p>
<ul class="simple">
<li><p>global accuracy, matches the global statistics</p></li>
<li><p>simulation methods tend to produce more realistic feature spatial, univariate distributions.</p></li>
<li><p>for example, Monte Carlo simulation, sequential Gaussian simulation, indicator simulation, object-based simulation, etc.</p></li>
</ul>
<p>Use simulation when,</p>
<ul class="simple">
<li><p>we need to reproduce the distributions of features of interest, the extreme values matter</p></li>
<li><p>we need realistic models for flow simulation</p></li>
</ul>
</section>
<section id="simulation-post-processing">
<h2><strong>Simulation Post-processing</strong><a class="headerlink" href="#simulation-post-processing" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_simulation_postsim.html"><span class="doc std std-doc">Simulation Post-processing</span></a>: operations to calculate summaries over multiple realizations. These summaries calculate the local cumulative distribution function at each location, <span class="math notranslate nohighlight">\(\bf{u}_{\alpha}\)</span>, in the model based on pooling the local realizations, <span class="math notranslate nohighlight">\(\ell = 1, \ldots, L\)</span>.</p>
<div class="math notranslate nohighlight">
\[
F_x(\bf{u}_{\alpha})
\]</div>
<p>Here are common summaries and how they are used,</p>
<p><em>e-type</em> - is the local expectation (since each realization is assumed to be equiprobable, this is the same as the local average) over the realizations</p>
<div class="math notranslate nohighlight">
\[
e(\bf{u }_{\alpha}) = E \left[x^{\ell}(\bf{ u }_{\alpha}) \right], \quad \forall \quad \ell = 1., \ldots, L, \quad \alpha \in V
\]</div>
<ul class="simple">
<li><p>often calculated to visualize the trends after integration of all information sources</p></li>
</ul>
<p><em>conditional standard deviation</em> - is the local standard deviation over the realizations</p>
<div class="math notranslate nohighlight">
\[
\sigma(\bf{u }_{\alpha}) = \sqrt{E \left[ (x^{\ell}(\bf{u }_{\alpha})- e(\bf{u }_{\alpha}))^2 \right] }, \quad \forall \quad \ell = 1., \ldots, L, \quad \alpha \in V
\]</div>
<ul class="simple">
<li><p>often calculated to visualize the level of local uncertainty</p></li>
</ul>
<p><em>local percentile</em> - is the local percentile over the realizations</p>
<div class="math notranslate nohighlight">
\[
x^p(\bf{ u } _{\alpha}) = F^{-1}(p; \bf{u }_{\alpha}), \quad \alpha \in V
\]</div>
<ul class="simple">
<li><p>often calculated to show maps of local upper and lower bounds, for example, local P10 and P90 models</p></li>
</ul>
<p><em>local probability of exceedance</em> - of the specified threshold, <span class="math notranslate nohighlight">\(z_k\)</span>, the same as one minus the cumulative probability of the threshold at each location over the realizations</p>
<div class="math notranslate nohighlight">
\[
P \{X(\bf{ u } _{\alpha}) \le x_k \} = 1 - \frac{1}{L} \cdot \sum^{L}_{\ell=1} i^{\ell}(\bf{ u } _{\alpha}; z_k), \quad \alpha \in V
\]</div>
<ul class="simple">
<li><p>often calculated to communicate risk, for example the probability of locally exceeding an environmental threshold for a contaminant</p></li>
</ul>
<p>We need sufficient number of realizations, <span class="math notranslate nohighlight">\(L\)</span>, to calculate each,</p>
<ul class="simple">
<li><p>the expected value is the easiest to calculate is reliable with 20 or more realizations</p></li>
<li><p>the percentiles on the tails, e.g., P10 and P90, will require 100 or more realizations for reliable results</p></li>
</ul>
<p>more realizations result in more reliable simulation post-processing and decision support in general.</p>
</section>
<section id="soft-data">
<h2><strong>Soft Data</strong><a class="headerlink" href="#soft-data" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: data that has a high degree of uncertainty, such that data uncertainty must be integrated into the model</p>
<ul class="simple">
<li><p>for example, probability density function for local porosity calibrated from acoustic impedance</p></li>
</ul>
<p>Soft data integration requires workflows like <em>indicator kriging</em>, <em>indicator simulation</em> and <em>p-field simulation</em> or worklfows that randomize the data with standard simulation methods that assume hard data like <em>sequential Gaussian simulation</em>.</p>
<ul class="simple">
<li><p>soft data integration is an advanced topic and a focus of ongoing research, but is often to done with standard, subsurface modeling software packages</p></li>
</ul>
</section>
<section id="spatial-estimation">
<h2><strong>Spatial Estimation</strong><a class="headerlink" href="#spatial-estimation" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_trends.html"><span class="doc std std-doc">Trend Modeling</span></a>: is process of obtaining the single best value to represent a feature at an unsampled location, or time, <span class="math notranslate nohighlight">\(\bf{u}\)</span>.</p>
<p>Given spatial data, <span class="math notranslate nohighlight">\(𝑧(\bf{𝐮}_1), \dots, 𝑧(\bf{𝐮}_n)\)</span> we can estimate at unknown location <span class="math notranslate nohighlight">\(\bf{u}\)</span> with a linear combination of the data as,</p>
<div class="math notranslate nohighlight">
\[
z^{*}(\bf{u}) = \sum^{n}_{\alpha = 1} \lambda_{\alpha} z(\bf{u}_{\alpha})
\]</div>
<p>we add an unbiasedness constraint by assigning the remainder of the weight (one minus the sum of weights) to the global average; therefore, if we have no informative data we will estimate with the global average of the property of interest.</p>
<div class="math notranslate nohighlight">
\[
z^{*}(\bf{u}) = \sum^{n}_{\alpha = 1} \lambda_{\alpha} z(\bf{u}_{\alpha}) + \left(1-\sum^{n}_{\alpha = 1} \lambda_{\alpha} \right) \overline{z}
\]</div>
<p>Some additional concepts,</p>
<ul class="simple">
<li><p>local accuracy takes precedence over <strong>global accuracy</strong>, i.e., matching the histogram and variogram</p></li>
<li><p>spatial estimation maps and models have too little variance and too much spatial continuity, i.e., are too smooth; therefore, are not appropriate for any transfer function that is sensitive to heterogeneity and the distribution</p></li>
<li><p>there is no access to multiple realizations to apply to the transfer function to sample the distribution of the decision criteria, simulation instead of estimation methods are required for comprehensive uncertainty modeling for optimum decision making</p></li>
</ul>
<p>There are various methods for spatial estimation, for example,</p>
<ul class="simple">
<li><p>inverse distance</p></li>
<li><p>kriging</p></li>
</ul>
<p>also, there are various general methods for non-spatial estimation, e.g., many predictive machine learning models perform non-spatial estimation,</p>
<ul class="simple">
<li><p>k-nearest neighbours</p></li>
<li><p>decision tree</p></li>
<li><p>random forest</p></li>
</ul>
<p>that like spatial estimation methods focus on local accuracy instead of global accuracy.</p>
</section>
<section id="spatial-continuity">
<h2><strong>Spatial Continuity</strong><a class="headerlink" href="#spatial-continuity" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_variogram_calculation.html"><span class="doc std std-doc">Variogram Calculation</span></a>: correlation over distance for a feature or interest. Given the relationship between a correlogram, <span class="math notranslate nohighlight">\(\rho(\bf{h})\)</span>, and a variogram, <span class="math notranslate nohighlight">\(\gamma(\bf{h})\)</span>,</p>
<div class="math notranslate nohighlight">
\[
\rho(\bf{h}) = 1.0 - \frac{\gamma(\bf{h})}{\sigma^2} 
\]</div>
<p>and the correlogram is correlation over distance, the greater the distance between the variogram and the sill (the lower the variogram value), the greater the spatial continuity.</p>
<p>Spatial continuity may be considered,</p>
<ul class="simple">
<li><p>between sample data during the calculation of an experimental variogram</p></li>
<li><p>while infering a variogram model, selecting contributions and ranges of each nested structure</p></li>
<li><p>between simulated values during calculation of a simulation model</p></li>
</ul>
<p>How do we interpret spatial continuity?</p>
<ul class="simple">
<li><p><strong>no spatial continuity</strong> - indicates no correlation between spatial sample over distance, effectively random values at each location in space regardless of separation distance.</p></li>
<li><p><strong>homogenous phenomena</strong> - perfect spatial continuity since all values are the same (or very similar) they are correlated over all distances.</p></li>
</ul>
</section>
<section id="spatial-sampling-biased">
<h2><strong>Spatial Sampling</strong> (biased)<a class="headerlink" href="#spatial-sampling-biased" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_declustering.html"><span class="doc std std-doc">Declustering to Correct Sampling Bias</span></a>: sample such that the sample statistics are not representative of the population parameters. For example,</p>
<ul class="simple">
<li><p>the sample mean is not the same as the population mean</p></li>
<li><p>the sample variance is not the same as the population variance</p></li>
</ul>
<p>Of course, the population parameters are not accessible, so we cannot directly calculate sampling bias, i.e., the difference between the sample statistics and the population parameters. Methods we can use to check for biased sampling,</p>
<ul class="simple">
<li><p>evaluate the samples for preferential sampling, clustering, filtering, etc.</p></li>
<li><p>apply <em>declustering</em> and check the results for a major change in the summary statistics, this is using declustering diagnostically</p></li>
</ul>
</section>
<section id="spatial-sampling-clustered">
<h2><strong>Spatial Sampling</strong> (clustered)<a class="headerlink" href="#spatial-sampling-clustered" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_declustering.html"><span class="doc std std-doc">Declustering to Correct Sampling Bias</span></a>: spatial samples with locations preferentially selected, i.e., clustered, resulting in biased statistics,</p>
<ul class="simple">
<li><p>typically spatial samples are clustered in locations with higher value samples, e.g., high porosity and permeability, good quality shale for unconventional reservoirs, low acoustic impedance indicating higher porosity, etc.</p></li>
</ul>
<p>Of course, the population parameters are not accessible, so we cannot directly calculate sampling bias, i.e., the difference between the sample statistics and the population parameters. Methods we can use to check for biased sampling,</p>
<ul class="simple">
<li><p>evaluate the samples for preferential sampling, clustering, filtering, etc.</p></li>
<li><p>apply <em>declustering</em> and check the results for a major change in the summary statistics, this is using declustering diagnostically</p></li>
</ul>
</section>
<section id="spatial-sampling-common-practice">
<h2><strong>Spatial Sampling</strong> (common practice)<a class="headerlink" href="#spatial-sampling-common-practice" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_declustering.html"><span class="doc std std-doc">Declustering to Correct Sampling Bias</span></a>: sample locations are selected to,</p>
<p><em>Reduce uncertainty</em> - by answering questions, for example,</p>
<ul class="simple">
<li><p>how far does the contaminant plume extend? – sample peripheries</p></li>
<li><p>where is the fault? – drill based on seismic interpretation</p></li>
<li><p>what is the highest mineral grade? – sample the best part</p></li>
<li><p>who far does the reservoir extend? – offset drilling</p></li>
</ul>
<p><em>Directly maximize net present value</em> - while collecting information, for example,</p>
<ul class="simple">
<li><p>maximize production rates</p></li>
<li><p>maximize tonnage of mineral extracted</p></li>
</ul>
<p>In other words, often our samples are dual purpose, e.g., wells that are drilled for exploration and appraisal information are subsequently utilized for production.</p>
</section>
<section id="spatial-sampling-representative">
<h2><strong>Spatial Sampling</strong> (representative)<a class="headerlink" href="#spatial-sampling-representative" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_declustering.html"><span class="doc std std-doc">Declustering to Correct Sampling Bias</span></a>: if we are sampling for representativity, i.e., the sample set and resulting sample statistics are representative of the population, by sampling theory we have 2 options:</p>
<p><em>Random sampling</em>* - each potential sample from the population is equally likely to be sampled as samples are collected. This includes,</p>
<ul class="simple">
<li><p>selecting a specific location has no impact on the selection of subsequent locations.</p></li>
<li><p>assumption that the population size that is much larger than the sample size; therefore, significant correlation between samples is not imposed due to without replacement sampling (the constraint that you can only sample a location once). Note, generally this is not an issue for the subsurface due to the sparsely sampled massive populations</p></li>
</ul>
<p><em>Regular sampling</em> - sampling at equal space or time intervals. While random sampling is prefered, regular sampling is robust as long as,</p>
<ul class="simple">
<li><p>the regular sampling intervals do not align with natural periodicity in the data, e.g., the crests are systemally sampling resulting in biased high sample statistics</p></li>
</ul>
</section>
<section id="stationarity">
<h2><strong>Stationarity</strong><a class="headerlink" href="#stationarity" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_variogram_calculation.html"><span class="doc std std-doc">Variogram Calculation</span></a>: any statistic requires replicates, repeated sampling (e.g., air or water samples from a monitoring station).</p>
<ul class="simple">
<li><p>in our geospatial problems repeated samples are not available at a location in the subsurface</p></li>
<li><p>instead of time, we must pool samples over space to calculate our statistics.</p></li>
</ul>
<p>This decision to pool samples is the decision of stationarity, the decision that the subset of the subsurface is all the same stuff.</p>
<p>Why must we pool data? Ultimately it is all about making inferences about the population from a limited sample,</p>
<ul class="simple">
<li><p>to calculate statistics</p></li>
<li><p>to build models</p></li>
</ul>
<p>The decision of the stationary domain for sampling is an expert decision,</p>
<ul class="simple">
<li><p>without it we are stuck in the well bore or drill hole and we cannot calculate any statistics nor say anything about the behavior of the subsurface between the sample data</p></li>
</ul>
<p>An example geological definition of stationarity could be like this,</p>
<p><em>The rock over the stationary domain is sourced, deposited, preserved, and post-depositionally altered in a similar manner, the domain is map-able and may be used for local prediction or as information for analogous locations within the subsurface; therefore, it is useful to pool information over this expert mapped volume of the subsurface.</em></p>
<ul class="simple">
<li><p>this expert interpolation is applied to map a statistical definition of stationarity that is applied in modeling.</p></li>
</ul>
<p>There are 2 aspects of any decision of stationarity,</p>
<ol class="arabic simple">
<li><p><em>Import License</em> - choice to pool specific samples to evaluate a statistic</p></li>
<li><p><em>Export License</em> - choice of where in the subsurface this statistic is applicable</p></li>
</ol>
<p>To state a decision of stationarity we must include,</p>
<ol class="arabic simple">
<li><p>the statistic that is stationary, e.g., the mean, the variance, the CDF, etc.</p></li>
<li><p>the area or volume over which the statistic is stationary, e.g., the entire model, the sand facies, the proximal region, etc.</p></li>
</ol>
<p>An example statistical definitions of stationarity,</p>
<ul class="simple">
<li><p>stationary mean</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
E[ Z(\bf{u} ] = \overline{z}, \quad \forall \quad \bf{u} \in AOI
\]</div>
<ul class="simple">
<li><p>stationary CDF</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
F_z(\bf{u},z) = F_z(z), \quad \forall \quad \bf{u} \in AOI
\]</div>
<ul class="simple">
<li><p>stationary semivariogram</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\gamma_z(\bf{u},h) = \gamma_z(\bf{h})
\]</div>
<p>This may be extended to any statistic of interest including, facies proportions, bivariate distributions and multiple point statistics.</p>
<p>Here’s some additional considerations for stationarity,</p>
<ul class="simple">
<li><p><em>Stationarity is a decision, not a hypothesis</em> - therefore, it cannot be tested, although data may demonstrate that it is inappropriate.</p></li>
<li><p><em>The stationarity assessment depends on scale</em> - this choice of modeling scale(s) should be based on the specific problem and project needs.</p></li>
<li><p><em>We cannot avoid a decision of stationarity</em> - no stationarity decision and we cannot move beyond the data. Conversely, assuming broad stationarity over all the data and over large volumes of the earth is naïve.</p></li>
<li><p><em>Geomodeling stationarity is the decision</em> - (1) over what region to pool data (import license) and (2) over what region to use the resulting statistics (export license).</p></li>
<li><p><em>Nonstationary trends may be mapped</em> - the remaining stationary residual modelled stochastically. This is the <em>hybrid modeling</em> approach.</p></li>
</ul>
</section>
<section id="stochastic-model">
<h2><strong>Stochastic Model</strong><a class="headerlink" href="#stochastic-model" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: system or process that is uncertain and is represented by multiple models, <em>realizations</em> and <em>scenarios</em> constrained by statistics,</p>
<ul class="simple">
<li><p>for example, data-driven models that integrate uncertainty like geostistical simulation models</p></li>
</ul>
<p>Advantages:</p>
<ul class="simple">
<li><p>speed</p></li>
<li><p>uncertainty assessment</p></li>
<li><p>report significance, confidence / prediction intervals</p></li>
<li><p>honor many types of data</p></li>
<li><p>data-driven approaches</p></li>
</ul>
<p>Disadvantages:</p>
<ul class="simple">
<li><p>limited physics used</p></li>
<li><p>statistical model assumptions / simplification</p></li>
</ul>
<p>For the alternative to stochastic models see <em>deterministic models</em>.</p>
</section>
<section id="statistics-practice">
<h2><strong>Statistics</strong> (practice)<a class="headerlink" href="#statistics-practice" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: the theory and practice for collecting, organizing, and interpreting data, as well as drawing conclusions and making decisions.</p>
</section>
<section id="statistics-measurement">
<h2><strong>Statistics</strong> (measurement)<a class="headerlink" href="#statistics-measurement" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: summary measure of a sample, for example,</p>
<ul class="simple">
<li><p>sample mean - <span class="math notranslate nohighlight">\(\overline{x}\)</span></p></li>
<li><p>sample standard deviation - <span class="math notranslate nohighlight">\(s\)</span>,</p></li>
</ul>
<p>we use statistics as estimates of the model parameters that summarize the population (<em>inference</em>)</p>
</section>
<section id="statistical-distribution">
<h2><strong>Statistical Distribution</strong><a class="headerlink" href="#statistical-distribution" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_univariate_distributions.html"><span class="doc std std-doc">Univariate Distributions</span></a>: for a feature a description of the probability of occurrence over the range of possible values. We represent the univariate statistical distribution with,</p>
<ul class="simple">
<li><p><em>histogram</em></p></li>
<li><p><em>normalized histogram</em></p></li>
<li><p><em>probability density function</em> (PDF)</p></li>
<li><p><em>cumulative distribution function</em> (CDF)</p></li>
</ul>
<p>What do we learn from a statistical distribution? For example,</p>
<ul class="simple">
<li><p>what is the minimum and maximum?</p></li>
<li><p>do we have a lot of low values?</p></li>
<li><p>do we have a lot of high values?</p></li>
<li><p>do we have outliers, and any other values that don’t make sense and need explaining?</p></li>
</ul>
</section>
<section id="transfer-function-reservoir-modeling-workflow">
<h2><strong>Transfer Function</strong> (reservoir modeling workflow)<a class="headerlink" href="#transfer-function-reservoir-modeling-workflow" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: calculation applied to the spatial, subsurface model realizations and scenarios to calculate a decision criterion, a metric that is used to support decision making representing value, and health, environment and safety. Example transfer functions include,</p>
<ul class="simple">
<li><p><em>transport and bioattenuation</em> - numerical simulation to model soil contaminant concentrations over time during a pump and treat operation</p></li>
<li><p><em>volumetric calculation</em> - for total oil-in-place to calculate resource in place</p></li>
<li><p><em>heterogeneity metric</em> - as an indicator of recovery factor to estimate reserves from resources</p></li>
<li><p><em>flow simulation</em> - for pre-drill production forecast for a planned well</p></li>
<li><p><em>Whittle’s pit optimization</em> - to calculate mineral resources and ultimage pit shell</p></li>
</ul>
</section>
<section id="trend-data">
<h2><strong>Trend</strong> (data)<a class="headerlink" href="#trend-data" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_trends.html"><span class="doc std std-doc">Trend Modeling</span></a>: the spatial feature is nonstationary over space, i.e., changes systematical over the area of interest. For example,</p>
<ul class="simple">
<li><p>the porosity decreases with depth</p></li>
<li><p>the copper grade increases toward the highly faulted zone</p></li>
</ul>
<p>Trend is also used to describe a model of the nonstationarity in any statistic or metric of interest, as in <em>trend model</em></p>
</section>
<section id="trend-model">
<h2><strong>Trend</strong> (model)<a class="headerlink" href="#trend-model" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_trends.html"><span class="doc std std-doc">Trend Modeling</span></a>: a determistic model that represents the local change in a statistic that is applied as an input for a spatial simulation method, for example,</p>
<ul class="simple">
<li><p>a linear function for reduction in porosity with depth, based on local data and regional compaction trends</p></li>
<li><p>a moving window local average copper grade model to model the increase in copper grade toward the highly faulted zone</p></li>
</ul>
<p>This provides a local value of the statistic at all model grid cells, so the simulation can apply the trend model to relax the assumption of statistionarity in the statistic.</p>
<ul class="simple">
<li><p>a trend model may be calculated and applied to applied to any statistic used in the simulation model, e.g., mean, variogram range, variogram major direction, correlation coefficient, etc.</p></li>
</ul>
</section>
<section id="trend-variogram-model">
<h2><strong>Trend</strong> (variogram model)<a class="headerlink" href="#trend-variogram-model" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_variogram_calculation_and_modeling.html"><span class="doc std std-doc">Variogram Calculation and Modeling</span></a>: experimental variogram points rise approximately linearly above the sill.</p>
<ul class="simple">
<li><p>indicates a <em>trend</em> in the data, e.g., fining upward, increased compaction with depth, etc.</p></li>
<li><p>could be interpreted as a fractal, i.e., model without a finite variance or sill fit with a power law function. Note, variogram models above the sill are not permissible for simulation methods like sequential Gaussian simulation, we must model to the sill</p></li>
<li><p>common workflow is to remove the trend, work with the residual, if the trend is removed the residual variogram will plateau at the sill</p></li>
</ul>
</section>
<section id="trend-modeling">
<h2><strong>Trend Modeling</strong><a class="headerlink" href="#trend-modeling" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_trends.html"><span class="doc std std-doc">Trend Modeling</span></a>: modeling of local features, based on data and interpretation, that are deemed certain (known). The trend is subtracted from the data, leaving a residual that is modelled stochastically with uncertainty (treated as unknown). The following steps are applied:</p>
<ol class="arabic simple">
<li><p>model the nonstationary, spatial, deterministic trend for a feature of interest</p></li>
<li><p>subtract the trend from the data to calculate the residual</p></li>
<li><p>model the residual with geostatistical spatial estimation or simulation</p></li>
<li><p>add the deterministic trend to the geostatistical (deterministic if kriging or stochastic if simulation) residual</p></li>
<li><p>check the model</p></li>
</ol>
</section>
<section id="uncertainty-modeling">
<h2><strong>Uncertainty Modeling</strong><a class="headerlink" href="#uncertainty-modeling" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: calculation of the range of possible values for a feature at a location or jointly over many locations at the sample time. Some considerations,</p>
<ul class="simple">
<li><p>quantification of the limitation in the precision of our samples and model predictions</p></li>
<li><p>uncertainty is a model, there is no objective uncertainty</p></li>
<li><p>uncertainty is caused by our ignorance</p></li>
<li><p>uncertainty is caused by sparse sampling, measurement error and bias, and heterogeneity</p></li>
</ul>
<p>we represent uncertainty by multiple models, scenarios and realizations:</p>
<ul class="simple">
<li><p>Scenarios - multiple spatial, subsurface models calculated by stochastic simulation by changing the input parameters or other modeling choices to represent the uncertainty due to inference of model parameters and model choices</p></li>
<li><p>Realizations - multiple spatial, subsurface models calculated by stochastic simulation by holding input parameters and model choices constant and only changing the random number seed</p></li>
</ul>
</section>
<section id="union-of-events-probability">
<h2><strong>Union of Events</strong> (probability)<a class="headerlink" href="#union-of-events-probability" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_probability.html"><span class="doc std std-doc">Probability Concepts</span></a>: the union of outcomes, the probability of <span class="math notranslate nohighlight">\(A\)</span> or <span class="math notranslate nohighlight">\(B\)</span> is calculated with the probability addition rule,</p>
<div class="math notranslate nohighlight">
\[
P(A \cup B) = P(A) + P(B) - P(A,B)
\]</div>
</section>
<section id="unit-lag-distance-variogram">
<h2><strong>Unit Lag Distance</strong> (variogram)<a class="headerlink" href="#unit-lag-distance-variogram" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_variogram_calculation.html"><span class="doc std std-doc">Variogram Calculation</span></a>: the increments for lag distance applied to calculate an experimental variogram</p>
<ul class="simple">
<li><p>for example if the unit lag distance is 50 m and 5 lags are calculated, the experimental variogram will have points at lag distance = 50 m, 100 m, 150 m, 200 m, and 250 m</p></li>
<li><p>typically the unit lag distance is set as the nominal minimum data spacing in the specific direction. Don’t use the minimum lag distance as there would be only one pair available and the experimental variogram point would be unreliable for the first unit lag</p></li>
<li><p>nominal minimum data spacing indicates the smallest lag with enough pairs to calculate a reliable experimental variogram point</p></li>
</ul>
</section>
<section id="univariate-parameters">
<h2><strong>Univariate Parameters</strong><a class="headerlink" href="#univariate-parameters" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_univariate_distributions.html"><span class="doc std std-doc">Univariate Distributions</span></a>: summary measures based on one feature measured over the population</p>
</section>
<section id="univariate-statistics">
<h2><strong>Univariate Statistics</strong><a class="headerlink" href="#univariate-statistics" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_univariate_distributions.html"><span class="doc std std-doc">Univariate Distributions</span></a>: summary measures based on one feature measured over the samples</p>
</section>
<section id="variable-also-feature">
<h2><strong>Variable</strong> (also feature)<a class="headerlink" href="#variable-also-feature" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: any property measured or observed in a study, for example,</p>
<ul class="simple">
<li><p>porosity, permeability, mineral concentrations, saturations, contaminant concentration</p></li>
<li><p>in data mining / machine learning this is known as a <strong>feature</strong></p></li>
<li><p>measure often requires significant analysis, interpretation, etc.</p></li>
</ul>
</section>
<section id="variogram">
<h2><strong>Variogram</strong><a class="headerlink" href="#variogram" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_variogram_calculation.html"><span class="doc std std-doc">Variogram Calculation</span></a>: function of difference over distance.</p>
<ul class="simple">
<li><p>experimental variogram is calculated over integer multiples of the unit lag distance and then plotted as points, then permissible <em>variogram models</em> are fit to the experimental variogram while integrating other domain and local knowledge.</p></li>
<li><p>the variogram is calculated as one half the average squared difference over lag distance, 𝐡, over all possible pairs of data,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\gamma_z(\bf{h}) = \frac{1}{2 \cdot N(\bf{h})} \sum_{\alpha = 1}^{N(\bf{h})} \left( z(\bf{u}_{\alpha}) - z(\bf{u}_{\alpha} + \bf{h}) \right)^2  
\]</div>
<ul class="simple">
<li><p>the precise term is semivariogram (or variogram if you remove the \frac{1}{2} in the equation above), but in practice, the semivariogram is only used and the term variogram is always used for the semivariogram</p></li>
<li><p>the <span class="math notranslate nohighlight">\(\frac{1}{2}\)</span> term is added to the semivariogram so that the covariance function, <span class="math notranslate nohighlight">\(C_z(\bf{u})\)</span>, and variogram, <span class="math notranslate nohighlight">\(\gamma_z(\bf{h})\)</span>, may be related as:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
C_z(\bf{h}) = \sigma_z^2 - \gamma_z(\bf{h})
\]</div>
<p>Note the correlogram, <span class="math notranslate nohighlight">\(\rho_z(\bf{u})\)</span>, is related to the covariance function, <span class="math notranslate nohighlight">\(C_z(\bf{u})\)</span>, as:</p>
<div class="math notranslate nohighlight">
\[
\rho_z(\bf{u}) = \frac{C_z(\bf{h})}{\sigma_z^2}
\]</div>
<p>Here are some general observations about the variogram,</p>
<p><em>Often increasing</em> - as the lag distance, <span class="math notranslate nohighlight">\(\bf{h}\)</span>, increases, variability over the lag distance increase (in general).</p>
<p><em>Not a local measure</em> - the variogram is calculated with over all possible pairs separated by lag vector, <span class="math notranslate nohighlight">\(\bf{h}\)</span>.</p>
<p><em>Interpret relative to the sill</em> - we need to plot the sill on with the experimental variogram to know the degree of correlation.</p>
<ul class="simple">
<li><p>The sill is the variance, <span class="math notranslate nohighlight">\(\sigma^2\)</span>, given stationarity of the variance and variogram, \gamma_z(\bf{h})):</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
C_z(\bf{h}) = \sigma_z^2 - \gamma_z(\bf{h})
\]</div>
<ul class="simple">
<li><p>and given a standardized feature, <span class="math notranslate nohighlight">\(\sigma_z^2 = 1.0\)</span>,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\rho_z(\bf{u}) = \sigma_z^2 - \gamma_z(\bf{h})
\]</div>
<p>The distance from the sill to the experimental variogram is the correlation coefficient over the specific lag distance.</p>
<p><em>The Range</em> - the lag distance at which the variogram reaches the sill is know as the range.</p>
<ul class="simple">
<li><p>at the range, knowing the data value at the tail provides no information about a value at the head.</p></li>
</ul>
<p><em>Nugget Effect</em> - sometimes there is a discontinuity in the variogram at distances less than the minimum data spacing. This is known as nugget effect.</p>
<ul class="simple">
<li><p>the ratio of nugget divided by sill, is known as relative nugget effect, reported in percentage, e.g., 10% relative nugget effect</p></li>
<li><p>we model the nugget effect as a no correlation structure over all lags greater than an infinitesimal distance, <span class="math notranslate nohighlight">\(\bf{h} \gt \epsilon\)</span></p></li>
<li><p>measurement error, causes an apparent nugget effect, if this is suspected do not add nugget effect to the variogram model</p></li>
</ul>
</section>
<section id="variogram-map">
<h2><strong>Variogram Map</strong><a class="headerlink" href="#variogram-map" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_variogram_calculation.html"><span class="doc std std-doc">Variogram Calculation</span></a>: calculating the experimental variogram over all distances and directions at once.</p>
<ul class="simple">
<li><p>use a mesh template, cell size controls resolution like unit lag distance (assuming lag tolerance is <span class="math notranslate nohighlight">\(\frac{1}{2}\)</span> lag distance), number of cells controls the extent of calculation</p></li>
<li><p>can be useful to visualize and determine <em>major direction</em> and <em>minor direction</em>.</p></li>
<li><p>typically variogram maps require more data than regular isotropic and anisotropic experimental variograms and are not practical with sparse spatial data, i.e., with too few data they tend to be too noisy for reliable interpretation</p></li>
</ul>
</section>
<section id="variogram-model">
<h2><strong>Variogram Model</strong><a class="headerlink" href="#variogram-model" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_variogram_calculation_and_modeling.html"><span class="doc std std-doc">Variogram Calculation and Modeling</span></a>: the variogram model is fit based on the experimental variograms and expert interpretation. Here’s the reasons for variogram modeling:</p>
<p><em>Interpolate all distances and directions</em> - the variogram must be known for all possible <span class="math notranslate nohighlight">\(\bf{h}\)</span> lags, distances and directions, not just the limited lags calculated for the experimental variogram(s)</p>
<p><em>Integrate geological knowledge</em> - the variogram modeling process is an opportunity integrate our geological knowledge. For example, geometric anisotropy ratios from knowledge of the depositional setting.</p>
<p><em>Valid model of difference vs. offset</em> - the variogram model must be positive definite (a legitimate measure of distance), that is, the variance of any linear combination must be positive. The variogram modeling workflow with additive, nested structures ensures this.</p>
<p>Variogram modeling with nested structures are applied to describe variance (sill) components with the following steps,</p>
<ol class="arabic simple">
<li><p><em>Nugget effect</em> - assign as the single (lowest) isotropic nugget effect</p></li>
<li><p><em>Number of structures</em> - choose the same number of variogram structures for all directions based on the most complex direction</p></li>
<li><p><em>Contributions for each structure</em> - ensure that the same contribution parameter is used for each variogram structure in all directions and that the sum of all structures’ contributions is equal to the sill (variance). Model to the sill and not above the sill.</p></li>
<li><p><em>Apparent Nugget Effect</em> - for apparent nugget effect structures (nugget effect in only some directions) use 0.0 range in the apparent nugget effect directions.</p></li>
<li><p><em>Geometric anisotropy</em> - vary the range parameters in each direction (anisotropy ratios)</p></li>
<li><p><em>Zonal anisotropy</em> - if the variogram does not reach the sill in some directions, then assign a very large value for the range in those directions to represent zonal anisotropy</p></li>
</ol>
<p>Here are some additional comments to assist with variogram modeling.</p>
<ul class="simple">
<li><p>initial coordinate and data transformation may be required, e.g., if the lags cross folded beds then the range will likely be underestimated</p></li>
<li><p>focus on fundamental variogram interpretations including, trend, cyclicity, geometric anisotropy, and zonal anisotropy. If  trend is present, calculate a feature spatial trend model and then work with the residual model that does not have trend</p></li>
<li><p>often the short scale structure is most important as most estimates and simulated realizations are interpolating between data, i.e., the data themselves often control long scale spatial continuity</p></li>
<li><p>nugget effect due to measurement error should not be modelled, as it is not a feature of the geology. Nugget effect is very rare in oil and gas, but is more common in mining</p></li>
<li><p>vertical direction is typically better informed due to number of samples and spacing along near vertical wells, model vertical direction and then fit an anisotropy ratio to the limited horizontal experimental variogram points</p></li>
</ul>
</section>
<section id="variance-reduction-factor">
<h2><strong>Variance Reduction Factor</strong><a class="headerlink" href="#variance-reduction-factor" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_volume_variance.html"><span class="doc std std-doc">Volume Variance</span></a>: the ratio, <span class="math notranslate nohighlight">\(f\)</span>, of the variance at volume support, scale <span class="math notranslate nohighlight">\(v\)</span> to the variance at the data volume support, scale <span class="math notranslate nohighlight">\(\cdot\)</span>, i.e., the standard variance, <span class="math notranslate nohighlight">\(\sigma^2\)</span>,</p>
<div class="math notranslate nohighlight">
\[
f = 1 - \frac{\overline{\gamma}(v,v)}{\sigma^2}
\]</div>
<p>where <span class="math notranslate nohighlight">\(f\)</span> is variance reduction factor,</p>
<div class="math notranslate nohighlight">
\[
f = \frac{D^2(v,V)}{D^2(\cdot,V)} = \frac{D^2(v,V)}{\sigma^2}
\]</div>
<p>Variance reduction factor is applied as a simplified workflow to adjust a data <em>histogram</em> to the upscaled distribution at model scale, <span class="math notranslate nohighlight">\(v\)</span>. Note, if this is not done and the data scale distribution is used for the model the variance is too large.</p>
</section>
<section id="volume-variance-relations">
<h2><strong>Volume-Variance Relations</strong><a class="headerlink" href="#volume-variance-relations" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_volume_variance.html"><span class="doc std std-doc">Volume Variance</span></a>: as the <em>volume support</em> (scale) increases the variance reduces</p>
<p>Predicting volume-variance relations is central to handling multiple scales of data and models. Some general observations and assumptions,</p>
<ul class="simple">
<li><p>the mean does not change as the volume support, scale changes. Only the variance changes</p></li>
<li><p>there may be shape change (we will not tackle that here). Best practice is to check shape change empirically. It is common to assume no shape change (<em>affine correction</em>) or to use a shape change model (indirect lognormal correction).</p></li>
<li><p>the variance reduction in the distribution is inversely proportional to the range of spatial continuity. Variance reduces faster (over smaller volume increase) for shorter spatial continuity ranges.</p></li>
</ul>
<p>Over common changes in scale this impact may be significant; therefore, it is not appropriate to ignore volume-variance relations,</p>
<ul class="simple">
<li><p>we don’t do this scale up, change in volume support perfectly, and this is why it is still called the missing scale. We rarely have enough data to model this rigorously</p></li>
<li><p>we need a model to predict this change in variance with change in volume support</p></li>
</ul>
<p>There are some change in volume support, scale models,</p>
<p><em>Empirical</em> - build a small scale, high resolution model and scale it up numerically. For example, calculate a high resolution model of permeaiblity, apply flow simulation to calculate effective permeability over <span class="math notranslate nohighlight">\(v\)</span> scale blocks</p>
<p><em>Power Law Averaging</em> - there is a flexible approach known as power law averaging.</p>
<div class="math notranslate nohighlight">
\[
z_V = \left[ \frac{1}{n} \sum z_v^{\omega} \right] ^{\frac{1}{\omega}}
\]</div>
<p>where <span class="math notranslate nohighlight">\(\omega\)</span> is the power of averaging. For example:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\omega = 1\)</span> is a regular linear averaging</p></li>
<li><p><span class="math notranslate nohighlight">\(\omega = -1\)</span> is a harmonic averaging</p></li>
<li><p><span class="math notranslate nohighlight">\(\omega = 0\)</span> is a geometric averaging (this is proved in the limit as <span class="math notranslate nohighlight">\(\omega \rightarrow 0\)</span>)</p></li>
</ul>
<p>How to calculate <span class="math notranslate nohighlight">\(\omega\)</span>?</p>
<ul class="simple">
<li><p>for some cases we know from theory the correct <span class="math notranslate nohighlight">\(\omega\)</span> value, for example, for flow orthogonal to beds we select <span class="math notranslate nohighlight">\(\omega = -1.0\)</span> to scale up permeability</p></li>
<li><p>flow simulation may be applied to numerically scale up permeability and then to back-calculate a calibrated <span class="math notranslate nohighlight">\(\omega\)</span></p></li>
</ul>
<p><em>Model</em> - directly adjust the statistics for change in scale. For example, under the assumption of linear averaging and a stationary variogram and variance:</p>
<div class="math notranslate nohighlight">
\[
f = 1 - \frac{\overline{\gamma}(v,v)}{\sigma^2}
\]</div>
<p>where <span class="math notranslate nohighlight">\(f\)</span> is variance reduction factor,</p>
<div class="math notranslate nohighlight">
\[
f = \frac{D^2(v,V)}{D^2(\cdot,V)} = \frac{D^2(v,V)}{\sigma^2}
\]</div>
<p>in other words, <span class="math notranslate nohighlight">\(f\)</span> is the ratio of the variance at scale <span class="math notranslate nohighlight">\(v\)</span> to the variance at the original data point support scale based on,</p>
<ul class="simple">
<li><p>the variogram model</p></li>
<li><p>the scale of the data, <span class="math notranslate nohighlight">\(\cdot\)</span> and the scale of <span class="math notranslate nohighlight">\(v\)</span></p></li>
</ul>
</section>
<section id="venn-diagrams">
<h2><strong>Venn Diagrams</strong><a class="headerlink" href="#venn-diagrams" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_probability.html"><span class="doc std std-doc">Probability Concepts</span></a>: a plot, visual tool for communicating probability. What do we learn from a Venn diagram?</p>
<ul class="simple">
<li><p>size of regions <span class="math notranslate nohighlight">\(\propto\)</span> probability of occurrence</p></li>
<li><p>proportion of <span class="math notranslate nohighlight">\(\Omega\)</span>, all possible outcomes represented by a box, i.e., probability of <span class="math notranslate nohighlight">\(1.0\)</span></p></li>
<li><p>overlap <span class="math notranslate nohighlight">\(\propto\)</span> probability of joint occurrence</p></li>
</ul>
<p>Venn diagrams are an excellent tool to visualize marginal, joint and conditional probability.</p>
</section>
<section id="well-log-data">
<h2><strong>Well Log Data</strong><a class="headerlink" href="#well-log-data" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: as a much cheaper method to sample wells that does not interrupt drilling operations, well logs are very common over the wells. Often all wells have various well logs available. For example,</p>
<ul class="simple">
<li><p>gamma ray on pilot vertical wells to assess the locations and quality of shales for targetting (landing) horizontal wells</p></li>
<li><p>neutron porosity to assess location high porosity reservoir sands</p></li>
<li><p>gamma ray in drill holes to map thorium mineralization</p></li>
</ul>
<p>Well log data are critical to support subsurface resource interpretations. Once anchored by core data they provide the essential coverage and resolution to model the entire reservoir concept / framework for prediction, for example,</p>
<ul class="simple">
<li><p>well log data calibrated by core data collocated with well log data are used to map the critical stratigraphic layers, including reservoir and seal units</p></li>
<li><p>well logs are applied to depth correct features inverted from seismic that have location imprecision due to uncertainty in the rock velocity over the volume of interest</p></li>
</ul>
</section>
<section id="well-log-data-image-logs">
<h2><strong>Well Log Data, Image Logs</strong><a class="headerlink" href="#well-log-data-image-logs" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_concepts.html"><span class="doc std std-doc">Geostatistical Concepts</span></a>: a special case of <em>well logs</em> where the well logs are repeated at various azimuthal intervals within the well bore resulting in a 2D (unwrapped) image instead of a 1D line along the well bore. For example, Fullbore formation MicroImager (FMI) with:</p>
<ul class="simple">
<li><p>with 80% bore hole coverage</p></li>
<li><p>0.2 inch (0.5 cm) resolution vertical and horizontal</p></li>
<li><p>30 inch (79 cm) depth of investigation</p></li>
</ul>
<p>can be applied to observe lithology change, bed dips and sedimentary structures.</p>
</section>
<section id="zonal-anisotropy-variogram-model">
<h2><strong>Zonal Anisotropy</strong> (variogram model)<a class="headerlink" href="#zonal-anisotropy-variogram-model" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="GeostatsPy_variogram_calculation_and_modeling.html"><span class="doc std std-doc">Variogram Calculation and Modeling</span></a>: when the experimental variogram does not reach the sill in a direction, i.e., the experimental levels out below the sill. Zonal anisotropy is often caused by layering,</p>
<ul class="simple">
<li><p>over the direction aligned with layers</p></li>
<li><p>zonal anisotropy is often paired with cyclicity or trend in the other (orthogonal) direction, e.g., zonal anisotropy in the major direction and trend in the minor direction</p></li>
<li><p>the variance at which the variogram levels off is called an apparent sill</p></li>
</ul>
<p>We can actually use zonal anisotropy to understand the partitioning of variance over space,</p>
<ul class="simple">
<li><p>the variance component up to the apparent sill is the variance within the layers</p></li>
<li><p>the variance component from the apparent sill to the sill is the variance between the layers</p></li>
</ul>
</section>
<section id="comments">
<h2>Comments<a class="headerlink" href="#comments" title="Permalink to this heading">#</a></h2>
<p>This was a basic introduction to geostatistics. If you would like more on these fundamental concepts I recommend the Introduction, Modeling Principles and Modeling Prerequisites chapters from my text book, <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Geostatistical Reservoir Modeling</a>{cite}`pyrcz2014’.</p>
<p>I hope this is helpful,</p>
<p><em>Michael</em></p>
</section>
<section id="the-author">
<h2>The Author:<a class="headerlink" href="#the-author" title="Permalink to this heading">#</a></h2>
<p>Michael Pyrcz, Professor, The University of Texas at Austin
<em>Novel Data Analytics, Geostatistics and Machine Learning Subsurface Solutions</em></p>
<p>With over 17 years of experience in subsurface consulting, research and development, Michael has returned to academia driven by his passion for teaching and enthusiasm for enhancing engineers’ and geoscientists’ impact in subsurface resource development.</p>
<p>For more about Michael check out these links:</p>
<p><a class="reference external" href="https://twitter.com/geostatsguy">Twitter</a> | <a class="reference external" href="https://github.com/GeostatsGuy">GitHub</a> | <a class="reference external" href="http://michaelpyrcz.com">Website</a> | <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en&amp;oi=ao">GoogleScholar</a> | <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Geostatistics Book</a> | <a class="reference external" href="https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig">YouTube</a>  | <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostats in Python e-book</a> | <a class="reference external" href="https://geostatsguy.github.io/MachineLearningDemos_Book/">Applied Machine Learning in Python e-book</a> | <a class="reference external" href="https://www.linkedin.com/in/michael-pyrcz-61a648a1">LinkedIn</a></p>
</section>
<section id="want-to-work-together">
<h2>Want to Work Together?<a class="headerlink" href="#want-to-work-together" title="Permalink to this heading">#</a></h2>
<p>I hope this content is helpful to those that want to learn more about subsurface modeling, data analytics and machine learning. Students and working professionals are welcome to participate.</p>
<ul class="simple">
<li><p>Want to invite me to visit your company for training, mentoring, project review, workflow design and / or consulting? I’d be happy to drop by and work with you!</p></li>
<li><p>Interested in partnering, supporting my graduate student research or my Subsurface Data Analytics and Machine Learning consortium (co-PIs including Profs. Foster, Torres-Verdin and van Oort)? My research combines data analytics, stochastic modeling and machine learning theory with practice to develop novel methods and workflows to add value. We are solving challenging subsurface problems!</p></li>
<li><p>I can be reached at <a class="reference external" href="mailto:mpyrcz&#37;&#52;&#48;austin&#46;utexas&#46;edu">mpyrcz<span>&#64;</span>austin<span>&#46;</span>utexas<span>&#46;</span>edu</a>.</p></li>
</ul>
<p>I’m always happy to discuss,</p>
<p><em>Michael</em></p>
<p>Michael Pyrcz, Ph.D., P.Eng. Professor, Cockrell School of Engineering and The Jackson School of Geosciences, The University of Texas at Austin</p>
</section>
<section id="more-resources-available-at-twitter-github-website-googlescholar-geostatistics-book-youtube-applied-geostats-in-python-e-book-applied-machine-learning-in-python-e-book-linkedin">
<h2>More Resources Available at: <a class="reference external" href="https://twitter.com/geostatsguy">Twitter</a> | <a class="reference external" href="https://github.com/GeostatsGuy">GitHub</a> | <a class="reference external" href="http://michaelpyrcz.com">Website</a> | <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en&amp;oi=ao">GoogleScholar</a> | <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Geostatistics Book</a> | <a class="reference external" href="https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig">YouTube</a>  | <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostats in Python e-book</a> | <a class="reference external" href="https://geostatsguy.github.io/MachineLearningDemos_Book/">Applied Machine Learning in Python e-book</a> | <a class="reference external" href="https://www.linkedin.com/in/michael-pyrcz-61a648a1">LinkedIn</a><a class="headerlink" href="#more-resources-available-at-twitter-github-website-googlescholar-geostatistics-book-youtube-applied-geostats-in-python-e-book-applied-machine-learning-in-python-e-book-linkedin" title="Permalink to this heading">#</a></h2>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="conclusions.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">e-Book Conclusions</p>
      </div>
    </a>
    <a class="right-next"
       href="references.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">References</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#motivation-for-geostatistics-concepts">Motivation for Geostatistics Concepts</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#addition-rule-probability"><strong>Addition Rule</strong> (probability)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#affine-correction"><strong>Affine Correction</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#anisotropic-or-directional-variogram"><strong>Anisotropic or Directional</strong> (variogram)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#azimuth-tolerance-variogram"><strong>Azimuth Tolerance</strong> (variogram)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bandwidth-variogram"><strong>Bandwidth</strong> (variogram)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-probability"><strong>Bayesian Probability</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayes-theorem-probability"><strong>Bayes’ Theorem</strong> (probability)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#big-data"><strong>Big Data</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#big-data-analytics"><strong>Big Data Analytics</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bootstrap"><strong>Bootstrap</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#categorical-feature"><strong>Categorical Feature</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#categorical-nominal-feature"><strong>Categorical Nominal Feature</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#categorical-ordinal-feature"><strong>Categorical Ordinal Feature</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cell-based-declustering"><strong>Cell-based Declustering</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cloud-transform"><strong>Cloud Transform</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#continuous-feature"><strong>Continuous Feature</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#continuous-interval-feature"><strong>Continuous, Interval Feature</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#continuous-ratio-feature"><strong>Continuous, Ratio Feature</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cognitive-biases"><strong>Cognitive Biases</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cokriging"><strong>Cokriging</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#collocated-cokriging"><strong>Collocated Cokriging</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#complimentary-events-probability"><strong>Complimentary Events</strong> (probability)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-probability"><strong>Conditional Probability</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#core-data"><strong>Core Data</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#correlogram"><strong>Correlogram</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cosimulation"><strong>Cosimulation</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#covariance-function"><strong>Covariance Function</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cumulative-distribution-function-cdf"><strong>Cumulative Distribution Function (CDF)</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cyclicity-variogram-model"><strong>Cyclicity</strong> (variogram model)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-data-aspects"><strong>Data</strong> (data aspects)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-analytics"><strong>Data Analytics</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#debiasing-with-secondary-data"><strong>Debiasing with Secondary Data</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#decision-criteria"><strong>Decision Criteria</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#declustering"><strong>Declustering</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#declustering-statistics"><strong>Declustering</strong> (statistics)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deterministic-model"><strong>Deterministic Model</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#discrete-feature"><strong>Discrete Feature</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dispersion-variance"><strong>Dispersion Variance</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#distribution-transformations"><strong>Distribution Transformations</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ergodic-fluctuations"><strong>Ergodic Fluctuations</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimation"><strong>Estimation</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#facies"><strong>Facies</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#facies-simulation"><strong>Facies Simulation</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-also-variable"><strong>Feature</strong> (also variable)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#frequentist-probability"><strong>Frequentist Probability</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gamma-bar"><strong>Gamma Bar</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#geometric-anisotropy-variogram-interpretation"><strong>Geometric Anisotropy</strong> (variogram interpretation)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#geometric-anisotropy-variogram-model"><strong>Geometric Anisotropy</strong> (variogram model)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#geostatistics"><strong>Geostatistics</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#global-accuracy"><strong>Global Accuracy</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#global-measures"><strong>Global Measures</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hard-data"><strong>Hard Data</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#histogram"><strong>Histogram</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hybrid-model"><strong>Hybrid Model</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#independence-probability"><strong>Independence</strong> (probability)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#indicator-kriging"><strong>Indicator Kriging</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#indicator-transform"><strong>Indicator Transform</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#indicator-variogram"><strong>Indicator Variogram</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-inferential-statistics"><strong>Inference, Inferential Statistics</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#intersection-of-events-probability"><strong>Intersection of Events</strong> (probability)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#isotropic-or-omnidirectional-variogram"><strong>Isotropic or Omnidirectional</strong> (variogram)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#joint-probability"><strong>Joint Probability</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#local-accuracy"><strong>Local Accuracy</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#local-measures"><strong>Local Measures</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kriging"><strong>Kriging</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kriging-simple-vs-ordinary"><strong>Kriging</strong> (simple vs. ordinary)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kriging-variance"><strong>Kriging Variance</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kriging-based-declustering"><strong>Kriging-based Declustering</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kolmogorovs-3-probability-axioms"><strong>Kolmogorov’s 3 Probability Axioms</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lag-variogram"><strong>Lag</strong> (variogram)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lag-distance-variogram"><strong>Lag Distance</strong> (variogram)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lag-distance-tolerance-variogram"><strong>Lag Distance Tolerance</strong> (variogram)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#location-map"><strong>Location Map</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#major-direction-variogram"><strong>Major Direction</strong> (variogram)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#marginal-probability"><strong>Marginal Probability</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#minor-direction-variogram"><strong>Minor Direction</strong> (variogram)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-checking"><strong>Model Checking</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#monte-carlo-simulation-mcs"><strong>Monte Carlo Simulation (MCS)</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#monte-carlo-simulation-workflow"><strong>Monte Carlo Simulation Workflow</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multiplication-rule-probability"><strong>Multiplication Rule</strong> (probability)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mutually-exclusive-events-probability"><strong>Mutually Exclusive Events</strong> (probability)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#normalized-histogram"><strong>Normalized Histogram</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nugget-effect-variogram"><strong>Nugget Effect</strong> (variogram)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#order-relations-correction-indicator-kriging">Order Relations Correction** (indicator kriging)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#parameters-statistics"><strong>Parameters</strong> (statistics)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#parameters-machine-learning"><strong>Parameters</strong> (machine learning)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#polygonal-declustering"><strong>Polygonal Declustering</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#population"><strong>Population</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#power-law-averaging"><strong>Power Law Averaging</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prediction-predictive-statistics"><strong>Prediction, Predictive Statistics</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#predictor-feature"><strong>Predictor Feature</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#primary-data"><strong>Primary Data</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probability-density-function-pdf"><strong>Probability Density Function (PDF)</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probability-non-negativity-normalization">Probability Non-negativity, Normalization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probability-operators"><strong>Probability Operators</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probability-perspectives"><strong>Probability Perspectives</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#production-data"><strong>Production Data</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#qualitative-features"><strong>Qualitative Features</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quantitative-features"><strong>Quantitative Features</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#random-function"><strong>Random Function</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#random-variable"><strong>Random Variable</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#range-variogram"><strong>Range</strong> (variogram)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#realization"><strong>Realization</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#realizations-uncertainty"><strong>Realizations</strong> (uncertainty)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reservoir-modeling-workflow"><strong>Reservoir Modeling Workflow</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#response-feature"><strong>Response Feature</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sample"><strong>Sample</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#scenarios-uncertainty"><strong>Scenarios</strong> (uncertainty)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#secondary-data"><strong>Secondary Data</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#seismic-data"><strong>Seismic Data</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sequential-gaussian-simulation"><strong>Sequential Gaussian Simulation</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sequential-indicator-simulation"><strong>Sequential Indicator Simulation</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sill-variogram"><strong>Sill</strong> (variogram)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simulation"><strong>Simulation</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simulation-post-processing"><strong>Simulation Post-processing</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#soft-data"><strong>Soft Data</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spatial-estimation"><strong>Spatial Estimation</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spatial-continuity"><strong>Spatial Continuity</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spatial-sampling-biased"><strong>Spatial Sampling</strong> (biased)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spatial-sampling-clustered"><strong>Spatial Sampling</strong> (clustered)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spatial-sampling-common-practice"><strong>Spatial Sampling</strong> (common practice)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spatial-sampling-representative"><strong>Spatial Sampling</strong> (representative)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stationarity"><strong>Stationarity</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stochastic-model"><strong>Stochastic Model</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#statistics-practice"><strong>Statistics</strong> (practice)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#statistics-measurement"><strong>Statistics</strong> (measurement)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#statistical-distribution"><strong>Statistical Distribution</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#transfer-function-reservoir-modeling-workflow"><strong>Transfer Function</strong> (reservoir modeling workflow)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#trend-data"><strong>Trend</strong> (data)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#trend-model"><strong>Trend</strong> (model)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#trend-variogram-model"><strong>Trend</strong> (variogram model)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#trend-modeling"><strong>Trend Modeling</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#uncertainty-modeling"><strong>Uncertainty Modeling</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#union-of-events-probability"><strong>Union of Events</strong> (probability)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#unit-lag-distance-variogram"><strong>Unit Lag Distance</strong> (variogram)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#univariate-parameters"><strong>Univariate Parameters</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#univariate-statistics"><strong>Univariate Statistics</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#variable-also-feature"><strong>Variable</strong> (also feature)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#variogram"><strong>Variogram</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#variogram-map"><strong>Variogram Map</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#variogram-model"><strong>Variogram Model</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#variance-reduction-factor"><strong>Variance Reduction Factor</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#volume-variance-relations"><strong>Volume-Variance Relations</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#venn-diagrams"><strong>Venn Diagrams</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#well-log-data"><strong>Well Log Data</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#well-log-data-image-logs"><strong>Well Log Data, Image Logs</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zonal-anisotropy-variogram-model"><strong>Zonal Anisotropy</strong> (variogram model)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#comments">Comments</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-author">The Author:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#want-to-work-together">Want to Work Together?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#more-resources-available-at-twitter-github-website-googlescholar-geostatistics-book-youtube-applied-geostats-in-python-e-book-applied-machine-learning-in-python-e-book-linkedin">More Resources Available at: Twitter | GitHub | Website | GoogleScholar | Geostatistics Book | YouTube  | Applied Geostats in Python e-book | Applied Machine Learning in Python e-book | LinkedIn</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Michael J. Pyrcz
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>